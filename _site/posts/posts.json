[
  {
    "path": "posts/2021-04-22-tidymodels-opnieuw/",
    "title": "Tidymodels opnieuw",
    "description": "Blog van Rebecca Barter onder de titel 'Tidymodels: tidy machine learning in R'",
    "author": [
      {
        "name": "Rebecca Barter, bewerking Harrie Jonkman",
        "url": {}
      }
    ],
    "date": "2021-04-22",
    "categories": [],
    "contents": "\nTidymodels: een nette en consistente manier om met machine learning in R te werken\nTidyverse is misschien wel een van de grootste successen van R de laatste jaren. Het is een basispakket (een suite van pakketten) waarmee je heel veel statistiscche bewerkingen goed en betrekkelijk eenvoudig kunt uitvoeren. De laatste jaren is tidymodels ontwikkeld dat voor het modelleren van data het basispakket moet worden en het ontwikkelt zich vergelijkbaar de gereedschapskist van tidyverse maar dan op het gebied van machine learning.\nWaarom tidymodels? Nou, het blijkt dat R een consistentieprobleem heeft. Omdat alles rondom machine learning door verschillende mensen is gemaakt, allemaal met verschillende principes, heeft alles een net iets andere interface gekregenen. Om de boel in lijn te houden is onderhand een frustrerende bezigheid. Enkele jaren geleden ontwikkelde Max Kuhn (nu bij RStudio in dienst) het caret R-pakket, dat is zo’n uniforme interface voor een groot aantal machine learning-modellen die er in R zijn. Het programma caret bestaat nog steeds, was in veel opzichten geweldig en is nog steeds goed te gebruiken. Maar in andere opzichten is het beperkt. Zo kan het vrij traag zijn, zelfs bij gebuik van data in bescheiden omvang.\ncaret was een geweldig uitgangspunt, dus RStudio heeft Max Kuhn ingehuurd om te werken aan een tidy versie van caret. Hij en veel anderen ontwikkelden de afgelopen jaren tidymodels.tidymodels is al een paar jaar in ontwikkeling en delen ervan waren al eerder uitgebracht. Die volledige versie is in het voorjaar van 2020 gepresenteerd en Barter schreef vlak daarvoor deze tutoriol. Ondertussen is het voldoende ontwikkeld als je het wil leren! Terwijl caret niet verder ontwikkeld wordt (je kunt caret blijven gebruiken en je bestaande caret-code werkt nog steeds, het pakket wordt alleen niet onderhouden), zal tidymodels het uiteindelijk overbodig maken.\nDeze tutorial van Barter is gebaseerd op Alison Hill’s dia’s van Introduction to Machine Learning with the Tidyverse, die alle dia’s bevat voor de cursus die ze met Garrett Grolemund voor RStudio heeft voorbereid::conf(2020), en Edgar Ruiz’s Gentle introduction to tidymodels op de website van RStudio. In deze tutorial gaat zij ervan uit dat de gebruiker bepaalde basiskennis heeft, voornamelijk omgaan met dplyr (b.v. piping %>% en een functie zoals mutate()).\nWat is tidymodels?\nNet als tidyverse, dat uit verschillende pakketten bestaat zoals ggplot2 en dplyr, zitten er ook in tidymodels enkele kernpakketten, zoals\nrsample: voor het uit elkaar halen van een datasample (b.v. train/test of cross-validatie);\nrecipes: voor pre-procesfuncties;\nparsnip: voor het specificeren van het model;\nyardstick: voor het evalueren van van het model;\ntune: voor het afstemmen van parameters;\nworkflow: om alles samen te brengen.\nNet zoals je de hele suite aan pakketten van tidyverse kunt binnenhalen door library(tidyverse) in te tikken. tidymodels bestaat dus uit verschillende pakketten en soms zal ik hieronder individuele pakketten noemen.\nEerst maar eens de boel klaarzetten\nAls je deze pakketten nog niet hebt geïnstalleerd, moet je dat wel eerst doen (slechts één keer) door install.packages(\"tidymodels\") te gebruiken. Vervolgens laad je bepaalde bibliotheken: tidymodels en tidyverse.\n\n\n\n\nRows: 768\nColumns: 9\n$ pregnant <dbl> 6, 1, 8, 1, 0, 5, 3, 10, 2, 8, 4, 10, 10, 1, 5, 7, …\n$ glucose  <dbl> 148, 85, 183, 89, 137, 116, 78, 115, 197, 125, 110,…\n$ pressure <dbl> 72, 66, 64, 66, 40, 74, 50, 0, 70, 96, 92, 74, 80, …\n$ triceps  <dbl> 35, 29, 0, 23, 35, 0, 32, 0, 45, 0, 0, 0, 0, 23, 19…\n$ insulin  <dbl> 0, 0, 0, 94, 168, 0, 88, 0, 543, 0, 0, 0, 0, 846, 1…\n$ mass     <dbl> 33.6, 26.6, 23.3, 28.1, 43.1, 25.6, 31.0, 35.3, 30.…\n$ pedigree <dbl> 0.627, 0.351, 0.672, 0.167, 2.288, 0.201, 0.248, 0.…\n$ age      <dbl> 50, 31, 32, 21, 33, 30, 26, 29, 53, 54, 30, 34, 57,…\n$ diabetes <fct> pos, neg, pos, neg, pos, neg, pos, neg, pos, pos, n…\n\nWe zullen gebruik maken van de Pima Indian Women’s diabetes-dataset dat informatie bevat over de diabetes status van 768 Pima Indian vrouwen(diabetes). In de dataset zitten daarnaast enkele predictoren zoals het aantal zwangerschappen (pregnant), concentratie glucose (glucose), diastolische bloeddruk (pressure), triceps huidplooidikte (triceps), 2 uur serum insuline (insuline), BMI (mass), diabetes stamboom functie (pedigree) en hun leeftijd (age). Voor het geval je het je afvraagt, de Pima Indianen zijn een groep indianen die leven in een gebied dat bestaat uit wat nu centraal en zuidelijk Arizona is. De korte naam “Pima” zou afkomstig zijn van een zinsnede die “ik weet het niet” betekent, die ze herhaaldelijk gebruikten in hun eerste ontmoetingen met Spaanse kolonisten. Wikipedia bedankt!\n\n\n\n\n    pregnant glucose pressure triceps insulin mass pedigree age\n1          6     148       72      35       0 33.6    0.627  50\n2          1      85       66      29       0 26.6    0.351  31\n3          8     183       64       0       0 23.3    0.672  32\n4          1      89       66      23      94 28.1    0.167  21\n5          0     137       40      35     168 43.1    2.288  33\n6          5     116       74       0       0 25.6    0.201  30\n7          3      78       50      32      88 31.0    0.248  26\n8         10     115        0       0       0 35.3    0.134  29\n9          2     197       70      45     543 30.5    0.158  53\n10         8     125       96       0       0  0.0    0.232  54\n11         4     110       92       0       0 37.6    0.191  30\n12        10     168       74       0       0 38.0    0.537  34\n13        10     139       80       0       0 27.1    1.441  57\n14         1     189       60      23     846 30.1    0.398  59\n15         5     166       72      19     175 25.8    0.587  51\n16         7     100        0       0       0 30.0    0.484  32\n17         0     118       84      47     230 45.8    0.551  31\n18         7     107       74       0       0 29.6    0.254  31\n19         1     103       30      38      83 43.3    0.183  33\n20         1     115       70      30      96 34.6    0.529  32\n21         3     126       88      41     235 39.3    0.704  27\n22         8      99       84       0       0 35.4    0.388  50\n23         7     196       90       0       0 39.8    0.451  41\n24         9     119       80      35       0 29.0    0.263  29\n25        11     143       94      33     146 36.6    0.254  51\n26        10     125       70      26     115 31.1    0.205  41\n27         7     147       76       0       0 39.4    0.257  43\n28         1      97       66      15     140 23.2    0.487  22\n29        13     145       82      19     110 22.2    0.245  57\n30         5     117       92       0       0 34.1    0.337  38\n31         5     109       75      26       0 36.0    0.546  60\n32         3     158       76      36     245 31.6    0.851  28\n33         3      88       58      11      54 24.8    0.267  22\n34         6      92       92       0       0 19.9    0.188  28\n35        10     122       78      31       0 27.6    0.512  45\n36         4     103       60      33     192 24.0    0.966  33\n37        11     138       76       0       0 33.2    0.420  35\n38         9     102       76      37       0 32.9    0.665  46\n39         2      90       68      42       0 38.2    0.503  27\n40         4     111       72      47     207 37.1    1.390  56\n41         3     180       64      25      70 34.0    0.271  26\n42         7     133       84       0       0 40.2    0.696  37\n43         7     106       92      18       0 22.7    0.235  48\n44         9     171      110      24     240 45.4    0.721  54\n45         7     159       64       0       0 27.4    0.294  40\n46         0     180       66      39       0 42.0    1.893  25\n47         1     146       56       0       0 29.7    0.564  29\n48         2      71       70      27       0 28.0    0.586  22\n49         7     103       66      32       0 39.1    0.344  31\n50         7     105        0       0       0  0.0    0.305  24\n51         1     103       80      11      82 19.4    0.491  22\n52         1     101       50      15      36 24.2    0.526  26\n53         5      88       66      21      23 24.4    0.342  30\n54         8     176       90      34     300 33.7    0.467  58\n55         7     150       66      42     342 34.7    0.718  42\n56         1      73       50      10       0 23.0    0.248  21\n57         7     187       68      39     304 37.7    0.254  41\n58         0     100       88      60     110 46.8    0.962  31\n59         0     146       82       0       0 40.5    1.781  44\n60         0     105       64      41     142 41.5    0.173  22\n61         2      84        0       0       0  0.0    0.304  21\n62         8     133       72       0       0 32.9    0.270  39\n63         5      44       62       0       0 25.0    0.587  36\n64         2     141       58      34     128 25.4    0.699  24\n65         7     114       66       0       0 32.8    0.258  42\n66         5      99       74      27       0 29.0    0.203  32\n67         0     109       88      30       0 32.5    0.855  38\n68         2     109       92       0       0 42.7    0.845  54\n69         1      95       66      13      38 19.6    0.334  25\n70         4     146       85      27     100 28.9    0.189  27\n71         2     100       66      20      90 32.9    0.867  28\n72         5     139       64      35     140 28.6    0.411  26\n73        13     126       90       0       0 43.4    0.583  42\n74         4     129       86      20     270 35.1    0.231  23\n75         1      79       75      30       0 32.0    0.396  22\n76         1       0       48      20       0 24.7    0.140  22\n77         7      62       78       0       0 32.6    0.391  41\n78         5      95       72      33       0 37.7    0.370  27\n79         0     131        0       0       0 43.2    0.270  26\n80         2     112       66      22       0 25.0    0.307  24\n81         3     113       44      13       0 22.4    0.140  22\n82         2      74        0       0       0  0.0    0.102  22\n83         7      83       78      26      71 29.3    0.767  36\n84         0     101       65      28       0 24.6    0.237  22\n85         5     137      108       0       0 48.8    0.227  37\n86         2     110       74      29     125 32.4    0.698  27\n87        13     106       72      54       0 36.6    0.178  45\n88         2     100       68      25      71 38.5    0.324  26\n89        15     136       70      32     110 37.1    0.153  43\n90         1     107       68      19       0 26.5    0.165  24\n91         1      80       55       0       0 19.1    0.258  21\n92         4     123       80      15     176 32.0    0.443  34\n93         7      81       78      40      48 46.7    0.261  42\n94         4     134       72       0       0 23.8    0.277  60\n95         2     142       82      18      64 24.7    0.761  21\n96         6     144       72      27     228 33.9    0.255  40\n97         2      92       62      28       0 31.6    0.130  24\n98         1      71       48      18      76 20.4    0.323  22\n99         6      93       50      30      64 28.7    0.356  23\n100        1     122       90      51     220 49.7    0.325  31\n101        1     163       72       0       0 39.0    1.222  33\n102        1     151       60       0       0 26.1    0.179  22\n103        0     125       96       0       0 22.5    0.262  21\n104        1      81       72      18      40 26.6    0.283  24\n105        2      85       65       0       0 39.6    0.930  27\n106        1     126       56      29     152 28.7    0.801  21\n107        1      96      122       0       0 22.4    0.207  27\n108        4     144       58      28     140 29.5    0.287  37\n109        3      83       58      31      18 34.3    0.336  25\n110        0      95       85      25      36 37.4    0.247  24\n111        3     171       72      33     135 33.3    0.199  24\n112        8     155       62      26     495 34.0    0.543  46\n113        1      89       76      34      37 31.2    0.192  23\n114        4      76       62       0       0 34.0    0.391  25\n115        7     160       54      32     175 30.5    0.588  39\n116        4     146       92       0       0 31.2    0.539  61\n117        5     124       74       0       0 34.0    0.220  38\n118        5      78       48       0       0 33.7    0.654  25\n119        4      97       60      23       0 28.2    0.443  22\n120        4      99       76      15      51 23.2    0.223  21\n121        0     162       76      56     100 53.2    0.759  25\n122        6     111       64      39       0 34.2    0.260  24\n123        2     107       74      30     100 33.6    0.404  23\n124        5     132       80       0       0 26.8    0.186  69\n125        0     113       76       0       0 33.3    0.278  23\n126        1      88       30      42      99 55.0    0.496  26\n127        3     120       70      30     135 42.9    0.452  30\n128        1     118       58      36      94 33.3    0.261  23\n129        1     117       88      24     145 34.5    0.403  40\n130        0     105       84       0       0 27.9    0.741  62\n131        4     173       70      14     168 29.7    0.361  33\n132        9     122       56       0       0 33.3    1.114  33\n133        3     170       64      37     225 34.5    0.356  30\n134        8      84       74      31       0 38.3    0.457  39\n135        2      96       68      13      49 21.1    0.647  26\n136        2     125       60      20     140 33.8    0.088  31\n137        0     100       70      26      50 30.8    0.597  21\n138        0      93       60      25      92 28.7    0.532  22\n139        0     129       80       0       0 31.2    0.703  29\n140        5     105       72      29     325 36.9    0.159  28\n141        3     128       78       0       0 21.1    0.268  55\n142        5     106       82      30       0 39.5    0.286  38\n143        2     108       52      26      63 32.5    0.318  22\n144       10     108       66       0       0 32.4    0.272  42\n145        4     154       62      31     284 32.8    0.237  23\n146        0     102       75      23       0  0.0    0.572  21\n147        9      57       80      37       0 32.8    0.096  41\n148        2     106       64      35     119 30.5    1.400  34\n149        5     147       78       0       0 33.7    0.218  65\n150        2      90       70      17       0 27.3    0.085  22\n151        1     136       74      50     204 37.4    0.399  24\n152        4     114       65       0       0 21.9    0.432  37\n153        9     156       86      28     155 34.3    1.189  42\n154        1     153       82      42     485 40.6    0.687  23\n155        8     188       78       0       0 47.9    0.137  43\n156        7     152       88      44       0 50.0    0.337  36\n157        2      99       52      15      94 24.6    0.637  21\n158        1     109       56      21     135 25.2    0.833  23\n159        2      88       74      19      53 29.0    0.229  22\n160       17     163       72      41     114 40.9    0.817  47\n161        4     151       90      38       0 29.7    0.294  36\n162        7     102       74      40     105 37.2    0.204  45\n163        0     114       80      34     285 44.2    0.167  27\n164        2     100       64      23       0 29.7    0.368  21\n165        0     131       88       0       0 31.6    0.743  32\n166        6     104       74      18     156 29.9    0.722  41\n167        3     148       66      25       0 32.5    0.256  22\n168        4     120       68       0       0 29.6    0.709  34\n169        4     110       66       0       0 31.9    0.471  29\n170        3     111       90      12      78 28.4    0.495  29\n171        6     102       82       0       0 30.8    0.180  36\n172        6     134       70      23     130 35.4    0.542  29\n173        2      87        0      23       0 28.9    0.773  25\n174        1      79       60      42      48 43.5    0.678  23\n175        2      75       64      24      55 29.7    0.370  33\n176        8     179       72      42     130 32.7    0.719  36\n177        6      85       78       0       0 31.2    0.382  42\n178        0     129      110      46     130 67.1    0.319  26\n179        5     143       78       0       0 45.0    0.190  47\n180        5     130       82       0       0 39.1    0.956  37\n181        6      87       80       0       0 23.2    0.084  32\n182        0     119       64      18      92 34.9    0.725  23\n183        1       0       74      20      23 27.7    0.299  21\n184        5      73       60       0       0 26.8    0.268  27\n185        4     141       74       0       0 27.6    0.244  40\n186        7     194       68      28       0 35.9    0.745  41\n187        8     181       68      36     495 30.1    0.615  60\n188        1     128       98      41      58 32.0    1.321  33\n189        8     109       76      39     114 27.9    0.640  31\n190        5     139       80      35     160 31.6    0.361  25\n191        3     111       62       0       0 22.6    0.142  21\n192        9     123       70      44      94 33.1    0.374  40\n193        7     159       66       0       0 30.4    0.383  36\n194       11     135        0       0       0 52.3    0.578  40\n195        8      85       55      20       0 24.4    0.136  42\n196        5     158       84      41     210 39.4    0.395  29\n197        1     105       58       0       0 24.3    0.187  21\n198        3     107       62      13      48 22.9    0.678  23\n199        4     109       64      44      99 34.8    0.905  26\n200        4     148       60      27     318 30.9    0.150  29\n201        0     113       80      16       0 31.0    0.874  21\n202        1     138       82       0       0 40.1    0.236  28\n203        0     108       68      20       0 27.3    0.787  32\n204        2      99       70      16      44 20.4    0.235  27\n205        6     103       72      32     190 37.7    0.324  55\n206        5     111       72      28       0 23.9    0.407  27\n207        8     196       76      29     280 37.5    0.605  57\n208        5     162      104       0       0 37.7    0.151  52\n209        1      96       64      27      87 33.2    0.289  21\n210        7     184       84      33       0 35.5    0.355  41\n211        2      81       60      22       0 27.7    0.290  25\n212        0     147       85      54       0 42.8    0.375  24\n213        7     179       95      31       0 34.2    0.164  60\n214        0     140       65      26     130 42.6    0.431  24\n215        9     112       82      32     175 34.2    0.260  36\n216       12     151       70      40     271 41.8    0.742  38\n217        5     109       62      41     129 35.8    0.514  25\n218        6     125       68      30     120 30.0    0.464  32\n219        5      85       74      22       0 29.0    1.224  32\n220        5     112       66       0       0 37.8    0.261  41\n221        0     177       60      29     478 34.6    1.072  21\n222        2     158       90       0       0 31.6    0.805  66\n223        7     119        0       0       0 25.2    0.209  37\n224        7     142       60      33     190 28.8    0.687  61\n225        1     100       66      15      56 23.6    0.666  26\n226        1      87       78      27      32 34.6    0.101  22\n227        0     101       76       0       0 35.7    0.198  26\n228        3     162       52      38       0 37.2    0.652  24\n229        4     197       70      39     744 36.7    2.329  31\n230        0     117       80      31      53 45.2    0.089  24\n231        4     142       86       0       0 44.0    0.645  22\n232        6     134       80      37     370 46.2    0.238  46\n233        1      79       80      25      37 25.4    0.583  22\n234        4     122       68       0       0 35.0    0.394  29\n235        3      74       68      28      45 29.7    0.293  23\n236        4     171       72       0       0 43.6    0.479  26\n237        7     181       84      21     192 35.9    0.586  51\n238        0     179       90      27       0 44.1    0.686  23\n239        9     164       84      21       0 30.8    0.831  32\n240        0     104       76       0       0 18.4    0.582  27\n241        1      91       64      24       0 29.2    0.192  21\n242        4      91       70      32      88 33.1    0.446  22\n243        3     139       54       0       0 25.6    0.402  22\n244        6     119       50      22     176 27.1    1.318  33\n245        2     146       76      35     194 38.2    0.329  29\n246        9     184       85      15       0 30.0    1.213  49\n247       10     122       68       0       0 31.2    0.258  41\n248        0     165       90      33     680 52.3    0.427  23\n249        9     124       70      33     402 35.4    0.282  34\n250        1     111       86      19       0 30.1    0.143  23\n251        9     106       52       0       0 31.2    0.380  42\n252        2     129       84       0       0 28.0    0.284  27\n253        2      90       80      14      55 24.4    0.249  24\n254        0      86       68      32       0 35.8    0.238  25\n255       12      92       62       7     258 27.6    0.926  44\n256        1     113       64      35       0 33.6    0.543  21\n257        3     111       56      39       0 30.1    0.557  30\n258        2     114       68      22       0 28.7    0.092  25\n259        1     193       50      16     375 25.9    0.655  24\n260       11     155       76      28     150 33.3    1.353  51\n261        3     191       68      15     130 30.9    0.299  34\n262        3     141        0       0       0 30.0    0.761  27\n263        4      95       70      32       0 32.1    0.612  24\n264        3     142       80      15       0 32.4    0.200  63\n265        4     123       62       0       0 32.0    0.226  35\n266        5      96       74      18      67 33.6    0.997  43\n267        0     138        0       0       0 36.3    0.933  25\n268        2     128       64      42       0 40.0    1.101  24\n269        0     102       52       0       0 25.1    0.078  21\n270        2     146        0       0       0 27.5    0.240  28\n271       10     101       86      37       0 45.6    1.136  38\n272        2     108       62      32      56 25.2    0.128  21\n273        3     122       78       0       0 23.0    0.254  40\n274        1      71       78      50      45 33.2    0.422  21\n275       13     106       70       0       0 34.2    0.251  52\n276        2     100       70      52      57 40.5    0.677  25\n277        7     106       60      24       0 26.5    0.296  29\n278        0     104       64      23     116 27.8    0.454  23\n279        5     114       74       0       0 24.9    0.744  57\n280        2     108       62      10     278 25.3    0.881  22\n281        0     146       70       0       0 37.9    0.334  28\n282       10     129       76      28     122 35.9    0.280  39\n283        7     133       88      15     155 32.4    0.262  37\n284        7     161       86       0       0 30.4    0.165  47\n285        2     108       80       0       0 27.0    0.259  52\n286        7     136       74      26     135 26.0    0.647  51\n287        5     155       84      44     545 38.7    0.619  34\n288        1     119       86      39     220 45.6    0.808  29\n289        4      96       56      17      49 20.8    0.340  26\n290        5     108       72      43      75 36.1    0.263  33\n291        0      78       88      29      40 36.9    0.434  21\n292        0     107       62      30      74 36.6    0.757  25\n293        2     128       78      37     182 43.3    1.224  31\n294        1     128       48      45     194 40.5    0.613  24\n295        0     161       50       0       0 21.9    0.254  65\n296        6     151       62      31     120 35.5    0.692  28\n297        2     146       70      38     360 28.0    0.337  29\n298        0     126       84      29     215 30.7    0.520  24\n299       14     100       78      25     184 36.6    0.412  46\n300        8     112       72       0       0 23.6    0.840  58\n301        0     167        0       0       0 32.3    0.839  30\n302        2     144       58      33     135 31.6    0.422  25\n303        5      77       82      41      42 35.8    0.156  35\n304        5     115       98       0       0 52.9    0.209  28\n305        3     150       76       0       0 21.0    0.207  37\n306        2     120       76      37     105 39.7    0.215  29\n307       10     161       68      23     132 25.5    0.326  47\n308        0     137       68      14     148 24.8    0.143  21\n309        0     128       68      19     180 30.5    1.391  25\n310        2     124       68      28     205 32.9    0.875  30\n311        6      80       66      30       0 26.2    0.313  41\n312        0     106       70      37     148 39.4    0.605  22\n313        2     155       74      17      96 26.6    0.433  27\n314        3     113       50      10      85 29.5    0.626  25\n315        7     109       80      31       0 35.9    1.127  43\n316        2     112       68      22      94 34.1    0.315  26\n317        3      99       80      11      64 19.3    0.284  30\n318        3     182       74       0       0 30.5    0.345  29\n319        3     115       66      39     140 38.1    0.150  28\n320        6     194       78       0       0 23.5    0.129  59\n321        4     129       60      12     231 27.5    0.527  31\n322        3     112       74      30       0 31.6    0.197  25\n323        0     124       70      20       0 27.4    0.254  36\n324       13     152       90      33      29 26.8    0.731  43\n325        2     112       75      32       0 35.7    0.148  21\n326        1     157       72      21     168 25.6    0.123  24\n327        1     122       64      32     156 35.1    0.692  30\n328       10     179       70       0       0 35.1    0.200  37\n329        2     102       86      36     120 45.5    0.127  23\n330        6     105       70      32      68 30.8    0.122  37\n331        8     118       72      19       0 23.1    1.476  46\n332        2      87       58      16      52 32.7    0.166  25\n333        1     180        0       0       0 43.3    0.282  41\n334       12     106       80       0       0 23.6    0.137  44\n335        1      95       60      18      58 23.9    0.260  22\n336        0     165       76      43     255 47.9    0.259  26\n337        0     117        0       0       0 33.8    0.932  44\n338        5     115       76       0       0 31.2    0.343  44\n339        9     152       78      34     171 34.2    0.893  33\n340        7     178       84       0       0 39.9    0.331  41\n341        1     130       70      13     105 25.9    0.472  22\n342        1      95       74      21      73 25.9    0.673  36\n343        1       0       68      35       0 32.0    0.389  22\n344        5     122       86       0       0 34.7    0.290  33\n345        8      95       72       0       0 36.8    0.485  57\n346        8     126       88      36     108 38.5    0.349  49\n347        1     139       46      19      83 28.7    0.654  22\n348        3     116        0       0       0 23.5    0.187  23\n349        3      99       62      19      74 21.8    0.279  26\n350        5       0       80      32       0 41.0    0.346  37\n351        4      92       80       0       0 42.2    0.237  29\n352        4     137       84       0       0 31.2    0.252  30\n353        3      61       82      28       0 34.4    0.243  46\n354        1      90       62      12      43 27.2    0.580  24\n355        3      90       78       0       0 42.7    0.559  21\n356        9     165       88       0       0 30.4    0.302  49\n357        1     125       50      40     167 33.3    0.962  28\n358       13     129        0      30       0 39.9    0.569  44\n359       12      88       74      40      54 35.3    0.378  48\n360        1     196       76      36     249 36.5    0.875  29\n361        5     189       64      33     325 31.2    0.583  29\n362        5     158       70       0       0 29.8    0.207  63\n363        5     103      108      37       0 39.2    0.305  65\n364        4     146       78       0       0 38.5    0.520  67\n365        4     147       74      25     293 34.9    0.385  30\n366        5      99       54      28      83 34.0    0.499  30\n367        6     124       72       0       0 27.6    0.368  29\n368        0     101       64      17       0 21.0    0.252  21\n369        3      81       86      16      66 27.5    0.306  22\n370        1     133      102      28     140 32.8    0.234  45\n371        3     173       82      48     465 38.4    2.137  25\n372        0     118       64      23      89  0.0    1.731  21\n373        0      84       64      22      66 35.8    0.545  21\n374        2     105       58      40      94 34.9    0.225  25\n375        2     122       52      43     158 36.2    0.816  28\n376       12     140       82      43     325 39.2    0.528  58\n377        0      98       82      15      84 25.2    0.299  22\n378        1      87       60      37      75 37.2    0.509  22\n379        4     156       75       0       0 48.3    0.238  32\n380        0      93      100      39      72 43.4    1.021  35\n381        1     107       72      30      82 30.8    0.821  24\n382        0     105       68      22       0 20.0    0.236  22\n383        1     109       60       8     182 25.4    0.947  21\n384        1      90       62      18      59 25.1    1.268  25\n385        1     125       70      24     110 24.3    0.221  25\n386        1     119       54      13      50 22.3    0.205  24\n387        5     116       74      29       0 32.3    0.660  35\n388        8     105      100      36       0 43.3    0.239  45\n389        5     144       82      26     285 32.0    0.452  58\n390        3     100       68      23      81 31.6    0.949  28\n391        1     100       66      29     196 32.0    0.444  42\n392        5     166       76       0       0 45.7    0.340  27\n393        1     131       64      14     415 23.7    0.389  21\n394        4     116       72      12      87 22.1    0.463  37\n395        4     158       78       0       0 32.9    0.803  31\n396        2     127       58      24     275 27.7    1.600  25\n397        3      96       56      34     115 24.7    0.944  39\n398        0     131       66      40       0 34.3    0.196  22\n399        3      82       70       0       0 21.1    0.389  25\n400        3     193       70      31       0 34.9    0.241  25\n401        4      95       64       0       0 32.0    0.161  31\n402        6     137       61       0       0 24.2    0.151  55\n403        5     136       84      41      88 35.0    0.286  35\n404        9      72       78      25       0 31.6    0.280  38\n405        5     168       64       0       0 32.9    0.135  41\n406        2     123       48      32     165 42.1    0.520  26\n407        4     115       72       0       0 28.9    0.376  46\n408        0     101       62       0       0 21.9    0.336  25\n409        8     197       74       0       0 25.9    1.191  39\n410        1     172       68      49     579 42.4    0.702  28\n411        6     102       90      39       0 35.7    0.674  28\n412        1     112       72      30     176 34.4    0.528  25\n413        1     143       84      23     310 42.4    1.076  22\n414        1     143       74      22      61 26.2    0.256  21\n415        0     138       60      35     167 34.6    0.534  21\n416        3     173       84      33     474 35.7    0.258  22\n417        1      97       68      21       0 27.2    1.095  22\n418        4     144       82      32       0 38.5    0.554  37\n419        1      83       68       0       0 18.2    0.624  27\n420        3     129       64      29     115 26.4    0.219  28\n421        1     119       88      41     170 45.3    0.507  26\n422        2      94       68      18      76 26.0    0.561  21\n423        0     102       64      46      78 40.6    0.496  21\n424        2     115       64      22       0 30.8    0.421  21\n425        8     151       78      32     210 42.9    0.516  36\n426        4     184       78      39     277 37.0    0.264  31\n427        0      94        0       0       0  0.0    0.256  25\n428        1     181       64      30     180 34.1    0.328  38\n429        0     135       94      46     145 40.6    0.284  26\n430        1      95       82      25     180 35.0    0.233  43\n431        2      99        0       0       0 22.2    0.108  23\n432        3      89       74      16      85 30.4    0.551  38\n433        1      80       74      11      60 30.0    0.527  22\n434        2     139       75       0       0 25.6    0.167  29\n435        1      90       68       8       0 24.5    1.138  36\n436        0     141        0       0       0 42.4    0.205  29\n437       12     140       85      33       0 37.4    0.244  41\n438        5     147       75       0       0 29.9    0.434  28\n439        1      97       70      15       0 18.2    0.147  21\n440        6     107       88       0       0 36.8    0.727  31\n441        0     189      104      25       0 34.3    0.435  41\n442        2      83       66      23      50 32.2    0.497  22\n443        4     117       64      27     120 33.2    0.230  24\n444        8     108       70       0       0 30.5    0.955  33\n445        4     117       62      12       0 29.7    0.380  30\n446        0     180       78      63      14 59.4    2.420  25\n447        1     100       72      12      70 25.3    0.658  28\n448        0      95       80      45      92 36.5    0.330  26\n449        0     104       64      37      64 33.6    0.510  22\n450        0     120       74      18      63 30.5    0.285  26\n451        1      82       64      13      95 21.2    0.415  23\n452        2     134       70       0       0 28.9    0.542  23\n453        0      91       68      32     210 39.9    0.381  25\n454        2     119        0       0       0 19.6    0.832  72\n455        2     100       54      28     105 37.8    0.498  24\n456       14     175       62      30       0 33.6    0.212  38\n457        1     135       54       0       0 26.7    0.687  62\n458        5      86       68      28      71 30.2    0.364  24\n459       10     148       84      48     237 37.6    1.001  51\n460        9     134       74      33      60 25.9    0.460  81\n461        9     120       72      22      56 20.8    0.733  48\n462        1      71       62       0       0 21.8    0.416  26\n463        8      74       70      40      49 35.3    0.705  39\n464        5      88       78      30       0 27.6    0.258  37\n465       10     115       98       0       0 24.0    1.022  34\n466        0     124       56      13     105 21.8    0.452  21\n467        0      74       52      10      36 27.8    0.269  22\n468        0      97       64      36     100 36.8    0.600  25\n469        8     120        0       0       0 30.0    0.183  38\n470        6     154       78      41     140 46.1    0.571  27\n471        1     144       82      40       0 41.3    0.607  28\n472        0     137       70      38       0 33.2    0.170  22\n473        0     119       66      27       0 38.8    0.259  22\n474        7     136       90       0       0 29.9    0.210  50\n475        4     114       64       0       0 28.9    0.126  24\n476        0     137       84      27       0 27.3    0.231  59\n477        2     105       80      45     191 33.7    0.711  29\n478        7     114       76      17     110 23.8    0.466  31\n479        8     126       74      38      75 25.9    0.162  39\n480        4     132       86      31       0 28.0    0.419  63\n481        3     158       70      30     328 35.5    0.344  35\n482        0     123       88      37       0 35.2    0.197  29\n483        4      85       58      22      49 27.8    0.306  28\n484        0      84       82      31     125 38.2    0.233  23\n485        0     145        0       0       0 44.2    0.630  31\n486        0     135       68      42     250 42.3    0.365  24\n487        1     139       62      41     480 40.7    0.536  21\n488        0     173       78      32     265 46.5    1.159  58\n489        4      99       72      17       0 25.6    0.294  28\n490        8     194       80       0       0 26.1    0.551  67\n491        2      83       65      28      66 36.8    0.629  24\n492        2      89       90      30       0 33.5    0.292  42\n493        4      99       68      38       0 32.8    0.145  33\n494        4     125       70      18     122 28.9    1.144  45\n495        3      80        0       0       0  0.0    0.174  22\n496        6     166       74       0       0 26.6    0.304  66\n497        5     110       68       0       0 26.0    0.292  30\n498        2      81       72      15      76 30.1    0.547  25\n499        7     195       70      33     145 25.1    0.163  55\n500        6     154       74      32     193 29.3    0.839  39\n501        2     117       90      19      71 25.2    0.313  21\n502        3      84       72      32       0 37.2    0.267  28\n503        6       0       68      41       0 39.0    0.727  41\n504        7      94       64      25      79 33.3    0.738  41\n505        3      96       78      39       0 37.3    0.238  40\n506       10      75       82       0       0 33.3    0.263  38\n507        0     180       90      26      90 36.5    0.314  35\n508        1     130       60      23     170 28.6    0.692  21\n509        2      84       50      23      76 30.4    0.968  21\n510        8     120       78       0       0 25.0    0.409  64\n511       12      84       72      31       0 29.7    0.297  46\n512        0     139       62      17     210 22.1    0.207  21\n513        9      91       68       0       0 24.2    0.200  58\n514        2      91       62       0       0 27.3    0.525  22\n515        3      99       54      19      86 25.6    0.154  24\n516        3     163       70      18     105 31.6    0.268  28\n517        9     145       88      34     165 30.3    0.771  53\n518        7     125       86       0       0 37.6    0.304  51\n519       13      76       60       0       0 32.8    0.180  41\n520        6     129       90       7     326 19.6    0.582  60\n521        2      68       70      32      66 25.0    0.187  25\n522        3     124       80      33     130 33.2    0.305  26\n523        6     114        0       0       0  0.0    0.189  26\n524        9     130       70       0       0 34.2    0.652  45\n525        3     125       58       0       0 31.6    0.151  24\n526        3      87       60      18       0 21.8    0.444  21\n527        1      97       64      19      82 18.2    0.299  21\n528        3     116       74      15     105 26.3    0.107  24\n529        0     117       66      31     188 30.8    0.493  22\n530        0     111       65       0       0 24.6    0.660  31\n531        2     122       60      18     106 29.8    0.717  22\n532        0     107       76       0       0 45.3    0.686  24\n533        1      86       66      52      65 41.3    0.917  29\n534        6      91        0       0       0 29.8    0.501  31\n535        1      77       56      30      56 33.3    1.251  24\n536        4     132        0       0       0 32.9    0.302  23\n537        0     105       90       0       0 29.6    0.197  46\n538        0      57       60       0       0 21.7    0.735  67\n539        0     127       80      37     210 36.3    0.804  23\n540        3     129       92      49     155 36.4    0.968  32\n541        8     100       74      40     215 39.4    0.661  43\n542        3     128       72      25     190 32.4    0.549  27\n543       10      90       85      32       0 34.9    0.825  56\n544        4      84       90      23      56 39.5    0.159  25\n545        1      88       78      29      76 32.0    0.365  29\n546        8     186       90      35     225 34.5    0.423  37\n547        5     187       76      27     207 43.6    1.034  53\n548        4     131       68      21     166 33.1    0.160  28\n549        1     164       82      43      67 32.8    0.341  50\n550        4     189      110      31       0 28.5    0.680  37\n551        1     116       70      28       0 27.4    0.204  21\n552        3      84       68      30     106 31.9    0.591  25\n553        6     114       88       0       0 27.8    0.247  66\n554        1      88       62      24      44 29.9    0.422  23\n555        1      84       64      23     115 36.9    0.471  28\n556        7     124       70      33     215 25.5    0.161  37\n557        1      97       70      40       0 38.1    0.218  30\n558        8     110       76       0       0 27.8    0.237  58\n559       11     103       68      40       0 46.2    0.126  42\n560       11      85       74       0       0 30.1    0.300  35\n561        6     125       76       0       0 33.8    0.121  54\n562        0     198       66      32     274 41.3    0.502  28\n563        1      87       68      34      77 37.6    0.401  24\n564        6      99       60      19      54 26.9    0.497  32\n565        0      91       80       0       0 32.4    0.601  27\n566        2      95       54      14      88 26.1    0.748  22\n567        1      99       72      30      18 38.6    0.412  21\n568        6      92       62      32     126 32.0    0.085  46\n569        4     154       72      29     126 31.3    0.338  37\n570        0     121       66      30     165 34.3    0.203  33\n571        3      78       70       0       0 32.5    0.270  39\n572        2     130       96       0       0 22.6    0.268  21\n573        3     111       58      31      44 29.5    0.430  22\n574        2      98       60      17     120 34.7    0.198  22\n575        1     143       86      30     330 30.1    0.892  23\n576        1     119       44      47      63 35.5    0.280  25\n577        6     108       44      20     130 24.0    0.813  35\n578        2     118       80       0       0 42.9    0.693  21\n579       10     133       68       0       0 27.0    0.245  36\n580        2     197       70      99       0 34.7    0.575  62\n581        0     151       90      46       0 42.1    0.371  21\n582        6     109       60      27       0 25.0    0.206  27\n583       12     121       78      17       0 26.5    0.259  62\n584        8     100       76       0       0 38.7    0.190  42\n585        8     124       76      24     600 28.7    0.687  52\n586        1      93       56      11       0 22.5    0.417  22\n587        8     143       66       0       0 34.9    0.129  41\n588        6     103       66       0       0 24.3    0.249  29\n589        3     176       86      27     156 33.3    1.154  52\n590        0      73        0       0       0 21.1    0.342  25\n591       11     111       84      40       0 46.8    0.925  45\n592        2     112       78      50     140 39.4    0.175  24\n593        3     132       80       0       0 34.4    0.402  44\n594        2      82       52      22     115 28.5    1.699  25\n595        6     123       72      45     230 33.6    0.733  34\n596        0     188       82      14     185 32.0    0.682  22\n597        0      67       76       0       0 45.3    0.194  46\n598        1      89       24      19      25 27.8    0.559  21\n599        1     173       74       0       0 36.8    0.088  38\n600        1     109       38      18     120 23.1    0.407  26\n601        1     108       88      19       0 27.1    0.400  24\n602        6      96        0       0       0 23.7    0.190  28\n603        1     124       74      36       0 27.8    0.100  30\n604        7     150       78      29     126 35.2    0.692  54\n605        4     183        0       0       0 28.4    0.212  36\n606        1     124       60      32       0 35.8    0.514  21\n607        1     181       78      42     293 40.0    1.258  22\n608        1      92       62      25      41 19.5    0.482  25\n609        0     152       82      39     272 41.5    0.270  27\n610        1     111       62      13     182 24.0    0.138  23\n611        3     106       54      21     158 30.9    0.292  24\n612        3     174       58      22     194 32.9    0.593  36\n613        7     168       88      42     321 38.2    0.787  40\n614        6     105       80      28       0 32.5    0.878  26\n615       11     138       74      26     144 36.1    0.557  50\n616        3     106       72       0       0 25.8    0.207  27\n617        6     117       96       0       0 28.7    0.157  30\n618        2      68       62      13      15 20.1    0.257  23\n619        9     112       82      24       0 28.2    1.282  50\n620        0     119        0       0       0 32.4    0.141  24\n621        2     112       86      42     160 38.4    0.246  28\n622        2      92       76      20       0 24.2    1.698  28\n623        6     183       94       0       0 40.8    1.461  45\n624        0      94       70      27     115 43.5    0.347  21\n625        2     108       64       0       0 30.8    0.158  21\n626        4      90       88      47      54 37.7    0.362  29\n627        0     125       68       0       0 24.7    0.206  21\n628        0     132       78       0       0 32.4    0.393  21\n629        5     128       80       0       0 34.6    0.144  45\n630        4      94       65      22       0 24.7    0.148  21\n631        7     114       64       0       0 27.4    0.732  34\n632        0     102       78      40      90 34.5    0.238  24\n633        2     111       60       0       0 26.2    0.343  23\n634        1     128       82      17     183 27.5    0.115  22\n635       10      92       62       0       0 25.9    0.167  31\n636       13     104       72       0       0 31.2    0.465  38\n637        5     104       74       0       0 28.8    0.153  48\n638        2      94       76      18      66 31.6    0.649  23\n639        7      97       76      32      91 40.9    0.871  32\n640        1     100       74      12      46 19.5    0.149  28\n641        0     102       86      17     105 29.3    0.695  27\n642        4     128       70       0       0 34.3    0.303  24\n643        6     147       80       0       0 29.5    0.178  50\n644        4      90        0       0       0 28.0    0.610  31\n645        3     103       72      30     152 27.6    0.730  27\n646        2     157       74      35     440 39.4    0.134  30\n647        1     167       74      17     144 23.4    0.447  33\n648        0     179       50      36     159 37.8    0.455  22\n649       11     136       84      35     130 28.3    0.260  42\n650        0     107       60      25       0 26.4    0.133  23\n651        1      91       54      25     100 25.2    0.234  23\n652        1     117       60      23     106 33.8    0.466  27\n653        5     123       74      40      77 34.1    0.269  28\n654        2     120       54       0       0 26.8    0.455  27\n655        1     106       70      28     135 34.2    0.142  22\n656        2     155       52      27     540 38.7    0.240  25\n657        2     101       58      35      90 21.8    0.155  22\n658        1     120       80      48     200 38.9    1.162  41\n659       11     127      106       0       0 39.0    0.190  51\n660        3      80       82      31      70 34.2    1.292  27\n661       10     162       84       0       0 27.7    0.182  54\n662        1     199       76      43       0 42.9    1.394  22\n663        8     167      106      46     231 37.6    0.165  43\n664        9     145       80      46     130 37.9    0.637  40\n665        6     115       60      39       0 33.7    0.245  40\n666        1     112       80      45     132 34.8    0.217  24\n667        4     145       82      18       0 32.5    0.235  70\n668       10     111       70      27       0 27.5    0.141  40\n669        6      98       58      33     190 34.0    0.430  43\n670        9     154       78      30     100 30.9    0.164  45\n671        6     165       68      26     168 33.6    0.631  49\n672        1      99       58      10       0 25.4    0.551  21\n673       10      68      106      23      49 35.5    0.285  47\n674        3     123      100      35     240 57.3    0.880  22\n675        8      91       82       0       0 35.6    0.587  68\n676        6     195       70       0       0 30.9    0.328  31\n677        9     156       86       0       0 24.8    0.230  53\n678        0      93       60       0       0 35.3    0.263  25\n679        3     121       52       0       0 36.0    0.127  25\n680        2     101       58      17     265 24.2    0.614  23\n681        2      56       56      28      45 24.2    0.332  22\n682        0     162       76      36       0 49.6    0.364  26\n683        0      95       64      39     105 44.6    0.366  22\n684        4     125       80       0       0 32.3    0.536  27\n685        5     136       82       0       0  0.0    0.640  69\n686        2     129       74      26     205 33.2    0.591  25\n687        3     130       64       0       0 23.1    0.314  22\n688        1     107       50      19       0 28.3    0.181  29\n689        1     140       74      26     180 24.1    0.828  23\n690        1     144       82      46     180 46.1    0.335  46\n691        8     107       80       0       0 24.6    0.856  34\n692       13     158      114       0       0 42.3    0.257  44\n693        2     121       70      32      95 39.1    0.886  23\n694        7     129       68      49     125 38.5    0.439  43\n695        2      90       60       0       0 23.5    0.191  25\n696        7     142       90      24     480 30.4    0.128  43\n697        3     169       74      19     125 29.9    0.268  31\n698        0      99        0       0       0 25.0    0.253  22\n699        4     127       88      11     155 34.5    0.598  28\n700        4     118       70       0       0 44.5    0.904  26\n701        2     122       76      27     200 35.9    0.483  26\n702        6     125       78      31       0 27.6    0.565  49\n703        1     168       88      29       0 35.0    0.905  52\n704        2     129        0       0       0 38.5    0.304  41\n705        4     110       76      20     100 28.4    0.118  27\n706        6      80       80      36       0 39.8    0.177  28\n707       10     115        0       0       0  0.0    0.261  30\n708        2     127       46      21     335 34.4    0.176  22\n709        9     164       78       0       0 32.8    0.148  45\n710        2      93       64      32     160 38.0    0.674  23\n711        3     158       64      13     387 31.2    0.295  24\n712        5     126       78      27      22 29.6    0.439  40\n713       10     129       62      36       0 41.2    0.441  38\n714        0     134       58      20     291 26.4    0.352  21\n715        3     102       74       0       0 29.5    0.121  32\n716        7     187       50      33     392 33.9    0.826  34\n717        3     173       78      39     185 33.8    0.970  31\n718       10      94       72      18       0 23.1    0.595  56\n719        1     108       60      46     178 35.5    0.415  24\n720        5      97       76      27       0 35.6    0.378  52\n721        4      83       86      19       0 29.3    0.317  34\n722        1     114       66      36     200 38.1    0.289  21\n723        1     149       68      29     127 29.3    0.349  42\n724        5     117       86      30     105 39.1    0.251  42\n725        1     111       94       0       0 32.8    0.265  45\n726        4     112       78      40       0 39.4    0.236  38\n727        1     116       78      29     180 36.1    0.496  25\n728        0     141       84      26       0 32.4    0.433  22\n729        2     175       88       0       0 22.9    0.326  22\n730        2      92       52       0       0 30.1    0.141  22\n731        3     130       78      23      79 28.4    0.323  34\n732        8     120       86       0       0 28.4    0.259  22\n733        2     174       88      37     120 44.5    0.646  24\n734        2     106       56      27     165 29.0    0.426  22\n735        2     105       75       0       0 23.3    0.560  53\n736        4      95       60      32       0 35.4    0.284  28\n737        0     126       86      27     120 27.4    0.515  21\n738        8      65       72      23       0 32.0    0.600  42\n739        2      99       60      17     160 36.6    0.453  21\n740        1     102       74       0       0 39.5    0.293  42\n741       11     120       80      37     150 42.3    0.785  48\n742        3     102       44      20      94 30.8    0.400  26\n743        1     109       58      18     116 28.5    0.219  22\n744        9     140       94       0       0 32.7    0.734  45\n745       13     153       88      37     140 40.6    1.174  39\n746       12     100       84      33     105 30.0    0.488  46\n747        1     147       94      41       0 49.3    0.358  27\n748        1      81       74      41      57 46.3    1.096  32\n749        3     187       70      22     200 36.4    0.408  36\n750        6     162       62       0       0 24.3    0.178  50\n751        4     136       70       0       0 31.2    1.182  22\n752        1     121       78      39      74 39.0    0.261  28\n753        3     108       62      24       0 26.0    0.223  25\n754        0     181       88      44     510 43.3    0.222  26\n755        8     154       78      32       0 32.4    0.443  45\n756        1     128       88      39     110 36.5    1.057  37\n757        7     137       90      41       0 32.0    0.391  39\n758        0     123       72       0       0 36.3    0.258  52\n759        1     106       76       0       0 37.5    0.197  26\n760        6     190       92       0       0 35.5    0.278  66\n761        2      88       58      26      16 28.4    0.766  22\n762        9     170       74      31       0 44.0    0.403  43\n763        9      89       62       0       0 22.5    0.142  33\n764       10     101       76      48     180 32.9    0.171  63\n765        2     122       70      27       0 36.8    0.340  27\n766        5     121       72      23     112 26.2    0.245  30\n767        1     126       60       0       0 30.1    0.349  47\n768        1      93       70      31       0 30.4    0.315  23\n    diabetes\n1        pos\n2        neg\n3        pos\n4        neg\n5        pos\n6        neg\n7        pos\n8        neg\n9        pos\n10       pos\n11       neg\n12       pos\n13       neg\n14       pos\n15       pos\n16       pos\n17       pos\n18       pos\n19       neg\n20       pos\n21       neg\n22       neg\n23       pos\n24       pos\n25       pos\n26       pos\n27       pos\n28       neg\n29       neg\n30       neg\n31       neg\n32       pos\n33       neg\n34       neg\n35       neg\n36       neg\n37       neg\n38       pos\n39       pos\n40       pos\n41       neg\n42       neg\n43       neg\n44       pos\n45       neg\n46       pos\n47       neg\n48       neg\n49       pos\n50       neg\n51       neg\n52       neg\n53       neg\n54       pos\n55       neg\n56       neg\n57       pos\n58       neg\n59       neg\n60       neg\n61       neg\n62       pos\n63       neg\n64       neg\n65       pos\n66       neg\n67       pos\n68       neg\n69       neg\n70       neg\n71       pos\n72       neg\n73       pos\n74       neg\n75       neg\n76       neg\n77       neg\n78       neg\n79       pos\n80       neg\n81       neg\n82       neg\n83       neg\n84       neg\n85       pos\n86       neg\n87       neg\n88       neg\n89       pos\n90       neg\n91       neg\n92       neg\n93       neg\n94       pos\n95       neg\n96       neg\n97       neg\n98       neg\n99       neg\n100      pos\n101      pos\n102      neg\n103      neg\n104      neg\n105      neg\n106      neg\n107      neg\n108      neg\n109      neg\n110      pos\n111      pos\n112      pos\n113      neg\n114      neg\n115      pos\n116      pos\n117      pos\n118      neg\n119      neg\n120      neg\n121      pos\n122      neg\n123      neg\n124      neg\n125      pos\n126      pos\n127      neg\n128      neg\n129      pos\n130      pos\n131      pos\n132      pos\n133      pos\n134      neg\n135      neg\n136      neg\n137      neg\n138      neg\n139      neg\n140      neg\n141      neg\n142      neg\n143      neg\n144      pos\n145      neg\n146      neg\n147      neg\n148      neg\n149      neg\n150      neg\n151      neg\n152      neg\n153      pos\n154      neg\n155      pos\n156      pos\n157      neg\n158      neg\n159      neg\n160      pos\n161      neg\n162      neg\n163      neg\n164      neg\n165      pos\n166      pos\n167      neg\n168      neg\n169      neg\n170      neg\n171      pos\n172      pos\n173      neg\n174      neg\n175      neg\n176      pos\n177      neg\n178      pos\n179      neg\n180      pos\n181      neg\n182      neg\n183      neg\n184      neg\n185      neg\n186      pos\n187      pos\n188      pos\n189      pos\n190      pos\n191      neg\n192      neg\n193      pos\n194      pos\n195      neg\n196      pos\n197      neg\n198      pos\n199      pos\n200      pos\n201      neg\n202      neg\n203      neg\n204      neg\n205      neg\n206      neg\n207      pos\n208      pos\n209      neg\n210      pos\n211      neg\n212      neg\n213      neg\n214      pos\n215      pos\n216      pos\n217      pos\n218      neg\n219      pos\n220      pos\n221      pos\n222      pos\n223      neg\n224      neg\n225      neg\n226      neg\n227      neg\n228      pos\n229      neg\n230      neg\n231      pos\n232      pos\n233      neg\n234      neg\n235      neg\n236      pos\n237      pos\n238      pos\n239      pos\n240      neg\n241      neg\n242      neg\n243      pos\n244      pos\n245      neg\n246      pos\n247      neg\n248      neg\n249      neg\n250      neg\n251      neg\n252      neg\n253      neg\n254      neg\n255      pos\n256      pos\n257      neg\n258      neg\n259      neg\n260      pos\n261      neg\n262      pos\n263      neg\n264      neg\n265      pos\n266      neg\n267      pos\n268      neg\n269      neg\n270      pos\n271      pos\n272      neg\n273      neg\n274      neg\n275      neg\n276      neg\n277      pos\n278      neg\n279      neg\n280      neg\n281      pos\n282      neg\n283      neg\n284      pos\n285      pos\n286      neg\n287      neg\n288      pos\n289      neg\n290      neg\n291      neg\n292      pos\n293      pos\n294      pos\n295      neg\n296      neg\n297      pos\n298      neg\n299      pos\n300      neg\n301      pos\n302      pos\n303      neg\n304      pos\n305      neg\n306      neg\n307      pos\n308      neg\n309      pos\n310      pos\n311      neg\n312      neg\n313      pos\n314      neg\n315      pos\n316      neg\n317      neg\n318      pos\n319      neg\n320      pos\n321      neg\n322      pos\n323      pos\n324      pos\n325      neg\n326      neg\n327      pos\n328      neg\n329      pos\n330      neg\n331      neg\n332      neg\n333      pos\n334      neg\n335      neg\n336      neg\n337      neg\n338      pos\n339      pos\n340      pos\n341      neg\n342      neg\n343      neg\n344      neg\n345      neg\n346      neg\n347      neg\n348      neg\n349      neg\n350      pos\n351      neg\n352      neg\n353      neg\n354      neg\n355      neg\n356      pos\n357      pos\n358      pos\n359      neg\n360      pos\n361      pos\n362      neg\n363      neg\n364      pos\n365      neg\n366      neg\n367      pos\n368      neg\n369      neg\n370      pos\n371      pos\n372      neg\n373      neg\n374      neg\n375      neg\n376      pos\n377      neg\n378      neg\n379      pos\n380      neg\n381      neg\n382      neg\n383      neg\n384      neg\n385      neg\n386      neg\n387      pos\n388      pos\n389      pos\n390      neg\n391      neg\n392      pos\n393      neg\n394      neg\n395      pos\n396      neg\n397      neg\n398      pos\n399      neg\n400      pos\n401      pos\n402      neg\n403      pos\n404      neg\n405      pos\n406      neg\n407      pos\n408      neg\n409      pos\n410      pos\n411      neg\n412      neg\n413      neg\n414      neg\n415      pos\n416      pos\n417      neg\n418      pos\n419      neg\n420      pos\n421      neg\n422      neg\n423      neg\n424      neg\n425      pos\n426      pos\n427      neg\n428      pos\n429      neg\n430      pos\n431      neg\n432      neg\n433      neg\n434      neg\n435      neg\n436      pos\n437      neg\n438      neg\n439      neg\n440      neg\n441      pos\n442      neg\n443      neg\n444      pos\n445      pos\n446      pos\n447      neg\n448      neg\n449      pos\n450      neg\n451      neg\n452      pos\n453      neg\n454      neg\n455      neg\n456      pos\n457      neg\n458      neg\n459      pos\n460      neg\n461      neg\n462      neg\n463      neg\n464      neg\n465      neg\n466      neg\n467      neg\n468      neg\n469      pos\n470      neg\n471      neg\n472      neg\n473      neg\n474      neg\n475      neg\n476      neg\n477      pos\n478      neg\n479      neg\n480      neg\n481      pos\n482      neg\n483      neg\n484      neg\n485      pos\n486      pos\n487      neg\n488      neg\n489      neg\n490      neg\n491      neg\n492      neg\n493      neg\n494      pos\n495      neg\n496      neg\n497      neg\n498      neg\n499      pos\n500      neg\n501      neg\n502      neg\n503      pos\n504      neg\n505      neg\n506      neg\n507      pos\n508      neg\n509      neg\n510      neg\n511      pos\n512      neg\n513      neg\n514      neg\n515      neg\n516      pos\n517      pos\n518      neg\n519      neg\n520      neg\n521      neg\n522      neg\n523      neg\n524      pos\n525      neg\n526      neg\n527      neg\n528      neg\n529      neg\n530      neg\n531      neg\n532      neg\n533      neg\n534      neg\n535      neg\n536      pos\n537      neg\n538      neg\n539      neg\n540      pos\n541      pos\n542      pos\n543      pos\n544      neg\n545      neg\n546      pos\n547      pos\n548      neg\n549      neg\n550      neg\n551      neg\n552      neg\n553      neg\n554      neg\n555      neg\n556      neg\n557      neg\n558      neg\n559      neg\n560      neg\n561      pos\n562      pos\n563      neg\n564      neg\n565      neg\n566      neg\n567      neg\n568      neg\n569      neg\n570      pos\n571      neg\n572      neg\n573      neg\n574      neg\n575      neg\n576      neg\n577      neg\n578      pos\n579      neg\n580      pos\n581      pos\n582      neg\n583      neg\n584      neg\n585      pos\n586      neg\n587      pos\n588      neg\n589      pos\n590      neg\n591      pos\n592      neg\n593      pos\n594      neg\n595      neg\n596      pos\n597      neg\n598      neg\n599      pos\n600      neg\n601      neg\n602      neg\n603      neg\n604      pos\n605      pos\n606      neg\n607      pos\n608      neg\n609      neg\n610      neg\n611      neg\n612      pos\n613      pos\n614      neg\n615      pos\n616      neg\n617      neg\n618      neg\n619      pos\n620      pos\n621      neg\n622      neg\n623      neg\n624      neg\n625      neg\n626      neg\n627      neg\n628      neg\n629      neg\n630      neg\n631      pos\n632      neg\n633      neg\n634      neg\n635      neg\n636      pos\n637      neg\n638      neg\n639      pos\n640      neg\n641      neg\n642      neg\n643      pos\n644      neg\n645      neg\n646      neg\n647      pos\n648      pos\n649      pos\n650      neg\n651      neg\n652      neg\n653      neg\n654      neg\n655      neg\n656      pos\n657      neg\n658      neg\n659      neg\n660      pos\n661      neg\n662      pos\n663      pos\n664      pos\n665      pos\n666      neg\n667      pos\n668      pos\n669      neg\n670      neg\n671      neg\n672      neg\n673      neg\n674      neg\n675      neg\n676      pos\n677      pos\n678      neg\n679      pos\n680      neg\n681      neg\n682      pos\n683      neg\n684      pos\n685      neg\n686      neg\n687      neg\n688      neg\n689      neg\n690      pos\n691      neg\n692      pos\n693      neg\n694      pos\n695      neg\n696      pos\n697      pos\n698      neg\n699      neg\n700      neg\n701      neg\n702      pos\n703      pos\n704      neg\n705      neg\n706      neg\n707      pos\n708      neg\n709      pos\n710      pos\n711      neg\n712      neg\n713      pos\n714      neg\n715      neg\n716      pos\n717      pos\n718      neg\n719      neg\n720      pos\n721      neg\n722      neg\n723      pos\n724      neg\n725      neg\n726      neg\n727      neg\n728      neg\n729      neg\n730      neg\n731      pos\n732      pos\n733      pos\n734      neg\n735      neg\n736      neg\n737      neg\n738      neg\n739      neg\n740      pos\n741      pos\n742      neg\n743      neg\n744      pos\n745      neg\n746      neg\n747      pos\n748      neg\n749      pos\n750      pos\n751      pos\n752      neg\n753      neg\n754      pos\n755      pos\n756      pos\n757      neg\n758      pos\n759      neg\n760      pos\n761      neg\n762      pos\n763      neg\n764      neg\n765      neg\n766      neg\n767      pos\n768      neg\n\nEen snelle verkenning van de dataset toont aan dat er meer nullen in de gegevens zitten dan verwacht (vooral omdat een BMI of tricep huiddikte van 0 onmogelijk is), wat betekent dat ontbrekende waarden als nullen worden geregistreerd. Zie bijvoorbeeld het histogram van de tricep huidplooidikte, waar de nullen voor dikte opvallen.\n\n\n\nDit fenomeen is ook te zien in de glucose-, druk-, insuline- en massavariabelen. We zetten eerst de 0-scores in alle variabelen (behalve “zwanger”) over naar NA (missende waarde). Daarvoor gebruiken we de mutate_at()functie (die binnenkort wordt vervangen door mutate() met across()) om aan te geven op welke variabelen we onze muterende functie willen toepassen. We gebruiken de if_else()functie om aan te geven waar we de waarde mee moeten vervangen als de voorwaarde waar of onwaar is.\n\n\n\nOnze gegevens zijn klaar. Laten we beginnen met het maken van een aantal tidymodels!\nHaal train/test sets uit elkaar\nLaten we onze data verdelen in trainings- en testdata. De trainingsdata worden gebruikt om ons model te vinden en de parameters in te stellen (tune). De testdata gebruiken we alleen om de werking van het finale model vast te stellen. Dat splitten kunnen we doen door de inital_split() functie (van het rsample pakket). Dat creëert een speciaal “split” object.\n\n<Analysis/Assess/Total>\n<576/192/768>\n\ndiabetes_split, ons gesplitste object, vertelt ons hoeveel waarnemingen we hebben in de trainingsset, de testset en de gehele dataset: <train/test/totaal> (576/192/768).\nDe trainings- en testsets kunnen uit het “split”-object worden gehaald met behulp van de training() en testing() functies. Hoewel we deze objecten niet echt zullen gebruiken in de pipeline (daarvoor zullen we het diabetes_split-object zelf gebruiken).\n\n\n\nOp een gegeven moment zullen we de parameters hiervan wat willen tuenen (afstemmen). Dat doen we met cross-validatie. Zo ontstaat er met vfold_cv() een cross-validatie versie van de trainingsset waar we zo op terugkomen.\n\n\n\nDefineeer een recipe\nMet het pakket recipes kun je de variabelen een rol geven, als uitkomst of voorspellende variabele (gebruik een “formule”) b.v.. Maar met recipe kun je ook andere voorbereidingsstappen zetten die je nodig acht (zoals standaardiseren, imputeren, PCA, etc). Een recipe voer je uit in delen (gelaagd op elkaar door pipes %>% te gebruiken):\nSpecificeer de formule (recipe()): specificeer eerst wat is de uitkomstvariabele en wat zijn de predictoren;\nSpecificeer pre-processing steps (step_zzz()): defineer voorbereidingsstappen, zoals imputatie, creëren van dummy variabelen, schalen en wat al niet meer\nZo kunnen we bijvoorbeeld de volgende recipe maken.\n\n\n\nAls je ooit eerder formules hebt gezien (bijvoorbeeld met behulp van de lm() functie in R), dan weet je misschien dat we onze formule veel efficiënter hadden kunnen schrijven met behulp van een shortcut, waarbij de . alle variabelen in de gegevens vertegenwoordigt: outcome ~ .\nDe volledige lijst van beschikbare voorbewerkingsstappen is hier te vinden. In de bovenstaande chunck hebben we de functies all_numeric() en all_predictors() gebruikt als argumenten van voorbereiding. Deze worden “rolselecties” genoemd en geven aan dat we de stap willen toepassen op “alle numerieke” variabelen of “alle predictoren”. De lijst van alle potentiële rolselectoren kan worden gevonden door ?selectis in je console te typen.\nMerk op dat we het originele diabetes_clean data-object hebben gebruikt (we stellen recipe(..., data = diabetes_clean)), in plaats van het diabetes_train-object of het diabetes_split-object. Het blijkt dat we deze allemaal hadden kunnen gebruiken. Alle recipes die op dit punt uit het dataobject worden gehaald zijn de namen en rollen van de uitkomst en de voorspellende variabelen. We zullen deze recipe later toepassen op specifieke datasets. Dit betekent dat voor grote datasets een kleinere dataset gebruikt wordt om tijd en geheugen te besparen.\nInderdaad, als we een samenvatting van het diabetes_recipe object printen, dan laat het ons gewoon zien hoeveel voorspellingsvariabelen we hebben gespecificeerd en welke stappen we hebben gespecificeerd (maar het implementeert ze eigenlijk nog niet!).\n\nData Recipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor          8\n\nOperations:\n\nCentering and scaling for all_numeric()\nK-nearest neighbor imputation for all_predictors()\n\nAls je de voorbewerkte dataset zelf wilt extraheren, kunt je eerst prep() het recept voor een specifieke dataset en juice() het voorbewerkte recept om de voorbewerkte gegevens te extraheren. Het blijkt dat het extraheren van de voorbewerkte data eigenlijk niet nodig is voor de pipeline, omdat dit onder de motorkap gebeurt als het model geschikt is. Soms is het toch nuttig.\n\n# A tibble: 576 x 9\n   pregnant glucose pressure triceps insulin   mass pedigree     age\n      <dbl>   <dbl>    <dbl>   <dbl>   <dbl>  <dbl>    <dbl>   <dbl>\n 1   0.673   0.837   -0.0581  0.616   0.328   0.187    0.531  1.37  \n 2  -0.824  -1.21    -0.537   0.0354 -0.770  -0.831   -0.359 -0.205 \n 3   1.27    1.98    -0.697   0.229   1.33   -1.31     0.676 -0.122 \n 4  -1.12    0.478   -2.61    0.616   0.0669  1.57     5.89  -0.0396\n 5   0.374  -0.205    0.102  -0.700  -0.404  -0.977   -0.843 -0.287 \n 6   1.87   -0.238    0.229   0.229   0.558   0.435   -1.06  -0.370 \n 7  -0.525   2.43    -0.218   1.58    3.15   -0.264   -0.982  1.61  \n 8   1.27    0.0877   1.86   -0.178   0.863   0.318   -0.743  1.70  \n 9   0.0743 -0.401    1.54    0.674   0.139   0.769   -0.875 -0.287 \n10   1.87    0.544    0.581  -0.448   0.666  -0.758    3.16   1.94  \n# … with 566 more rows, and 1 more variable: diabetes <fct>\n\nSpecificeer het model\nTot nu toe hebben we onze data verdeeld in training en test-sets en onze pre-proces stappen gespecificeerd door een recipe te gebruiken. Nu willen we ons model definiëren en daarvoor gebruiken we het parsnip pakket dat in tidymodels zit.\nParsnip biedt een uniforme interface voor de enorme verscheidenheid aan modellen die er in R bestaan. Dit betekent dat je slechts één manier hoeft te leren om een model te specificeren en dan kun je dit gebruiken voor allerlei verschillende modellen, vaak met enkele coderegel.\nEr zijn een paar primaire componenten in de modelspecificatie opgeslagen:\nHet model type: wat voor soort model wil je gebruiken, zoals rand_forest() voor het random forest-model, logistic_reg() voor het logistisch regressie-model, svm_poly() voor een polynomiaal SVM-model, enz. De volledige lijst van modellen die beschikbaar zijn via parsnip kan [hier] (link naar website) vinden.\nDe arguments: de model parameter waarden (de benaming is consistent over verschillende modellen), door het gebruik van set_args().\nDe engine: het onderliggende pakket waar het model van wegkomt (bv. “ranger” voor implementatie van Random Forest), door het gebuik van set_engine().\nDe mode: het type voorspelling - omdat verschillende pakketten zowel classificatie (binaire/categoriale voorspelling) en regressie (continue voorspelling) kunnen uitvoeren, door het gebruik van set_mode().\nAls we bijvoorbeeld een random forest model willen gebruiken, zoals dat in het ranger pakket zit, met als doel classificatie en we willen de try parameter tunen (het afstemmen van het aantal willekeurig gekozen variabelen dat bij elke splitsing in aanmerking moet worden genomen), dan moeten we de volgende modelspecificatie definiëren:\n\n\n\nAls je later het variabele belang van jouw uiteindelijke model wilt kunnen onderzoeken, moet je het engine argument opnieuw instellen. De volgende code specificeert bijvoorbeeld een logistisch regressiemodel uit het glm pakket.\n\n\n\nDeze code draait niet het model. Net als de recipe, is het veel meer een beschrijving van het model. Echter, wanneer je een parameter op tune() zet wordt het later gestemd in de stemfase van de pipeline (bv. om de waarde vast te stellen van de parameter die de beste performance geeft). Je kunt ook zelf een bepaalde waarde aan de parameter geven wanneer je het niet wilt afstemmen, bv door set_args(mtry = 4) te gebruiken. Een ander ding om op te merken is dat niets wat deze modelspecificatie betreft specifiek is voor de diabetes-dataset.\nAlles in een workflow samenbrengen\nWe zijn klaar om het model en de recipes in een workflow te plaatsen. Een workflow zet je op door het gebruik van workflow() (van het workflows pakket) en dan kun je een recipe en een model toevoegen.\n\n\n\nMerk op dat we de voorbewerkingsstappen nog niet in de recipe hebben geïmplementeerd noch dat we het model hebben gepast. We hebben alleen maar het raamwerk geschreven. Pas als we de parameters hebben afgestemd of in het model hebben gepast, worden het recept en het model daadwerkelijk geïmplementeerd.\nAfstemmen van de parameters\nOmdat er een parameter is ontwikkeld om af te stemmen (mtry), moeten we dat daar voor gebruiken (bv. de waarde kiezen die de beste performance laat zien) voordat we het model passen. Als je geen parameters hebt om af te stemmen, kun je dit deel overslaan.\nDat afstemmen doen we door een cross-validation object (diabetes_cv) te kiezen. Om dat te doen specificeren we de range van mtry waarden die we willen gebruiken en dan voegen we een stemmingslaag toe aan onze workflow door tune_grid() te gebruiken (van het tune pakket). We richten ons op twee maten: accuracy en roc_auc (van het yardstick pakket). Die vertellen ons welke maten we het beste kunnen gebruiken.\n\n\n\nJe kunt verschillende parameters afstemmen door verschillende parameters aan de expand.grid() functie toe te voegen, bv. expand.grid(mtry = c(3, 4, 5), trees = c(100, 500)).\nHet is altijd goed om de resultaten van de cross-validatie goed te onderzoeken. collect_metrics() is echt een handige functie die in verschillende omstandigheden kan worden gebruikt om te vergelijken die zijn berekend in het object dat is gebruikt. In dit geval komen de maten van de cross-validatie performance over de verschillende waarden van de performance.\n\n# A tibble: 6 x 7\n   mtry .metric  .estimator  mean     n std_err .config             \n  <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1     3 accuracy binary     0.750    10  0.0225 Preprocessor1_Model1\n2     3 roc_auc  binary     0.829    10  0.0154 Preprocessor1_Model1\n3     4 accuracy binary     0.758    10  0.0226 Preprocessor1_Model2\n4     4 roc_auc  binary     0.828    10  0.0149 Preprocessor1_Model2\n5     5 accuracy binary     0.753    10  0.0232 Preprocessor1_Model3\n6     5 roc_auc  binary     0.826    10  0.0153 Preprocessor1_Model3\n\nTen opzichte van accuracy en AUC laat mtry = 4 de beste performance zien (hoogste gemiddelde waarden).\nAfronden van de workflow\nWe willen een laag aan onze workflow toevoegen die overeenkomt met de afgestemde parameter, d.w.z. dat we mtry instellen als de waarde die de beste resultaten opleverde. Als je geen parameters hebt afgestemd, kun je deze stap overslaan.\nWe kunnen de beste waarde voor de nauwkeurigheidsmetriek extraheren door de select_best()functie toe te passen op het afstemmingsobject.\n\n# A tibble: 1 x 2\n   mtry .config             \n  <dbl> <chr>               \n1     4 Preprocessor1_Model2\n\nDan kunnen we deze parameter aan de workflow toevoegen door de finalize_workflow() functie te gebruiken.\n\n\n\nEvalueren van het model op de test set\nNu we ons recipe en ons model hebben gedefinieerd en de parameters van het model hebben getuned, zijn we klaar om daadwerkelijk het uiteindelijke model te draaien. Aangezien al deze informatie in het workflow-object zit, zullen we de last_fit() functie toepassen op onze workflow en ons train/test-splitsingsobject. Dit zal automatisch het door de workflow gespecificeerde model trainen met behulp van de trainingsgegevens en evaluaties produceren op basis van de testset.\n\n\n\nMerk op dat het object dat wordt gecreëerd een data-frame-achtig object is; het is een tibble met listkolommen.\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 x 6\n  splits      id        .metrics    .notes    .predictions   .workflow\n  <list>      <chr>     <list>      <list>    <list>         <list>   \n1 <rsplit [5… train/te… <tibble [2… <tibble … <tibble [192 … <workflo…\n\nDit is echt een aardige eigenschap van tidymodels (en ook waarom je zo goed kunt werken met tidyverse) omdat je al je nette handelingen op het modelobject kunt uitvoeren.\nAangezien we het trainings/testobject al hebben geleverd op het moment dat we in de workflow werken, worden de maten geëvalueerd op de testset. Wanneer we nu de collect_metrics() functie gebruiken (herinner ons dat we deze hebben gebruikt bij het afstemmen van onze parameters), haalt deze de prestaties van het uiteindelijke model (aangezien rf_fit nu bestaat uit een enkel definitief model) toegepast op de test set.\n\n# A tibble: 2 x 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.745 Preprocessor1_Model1\n2 roc_auc  binary         0.831 Preprocessor1_Model1\n\nOverall is de performance heel goed, met een accuracy van 0.74 en een AUC van 0.82. Maar deze waarden zijn vaak lager dan in de trainingsset.\nJe kunt de test set voorspellingen zelf gebruiken met de collect_predictions() functie. Let op dat er 192 rijen in het voorspellingsobject zitten dat overeenkomt met de test set observaties (juist om jou te laten zien dat deze gebaseerd zijn op de testset meer dan op de trainingsset).\n\n# A tibble: 192 x 7\n   id        .pred_neg .pred_pos  .row .pred_class diabetes .config   \n   <chr>         <dbl>     <dbl> <int> <fct>       <fct>    <chr>     \n 1 train/te…    1.00     0.00045     4 neg         neg      Preproces…\n 2 train/te…    0.967    0.0330      7 neg         pos      Preproces…\n 3 train/te…    0.0393   0.961      12 pos         pos      Preproces…\n 4 train/te…    0.708    0.292      19 neg         neg      Preproces…\n 5 train/te…    0.636    0.364      21 neg         neg      Preproces…\n 6 train/te…    0.541    0.459      25 neg         pos      Preproces…\n 7 train/te…    0.482    0.518      27 pos         pos      Preproces…\n 8 train/te…    0.692    0.308      29 neg         neg      Preproces…\n 9 train/te…    0.951    0.0493     34 neg         neg      Preproces…\n10 train/te…    0.369    0.631      35 pos         neg      Preproces…\n# … with 182 more rows\n\nOmndat dit een normaal data frame/tibble object is, kunnen we de samenvattingen genereren en een confusie matrix plotten.\n\n          Truth\nPrediction neg pos\n       neg 106  33\n       pos  16  37\n\nWe kunnen ook de voorspelde kansverdelingen voor elke klasse in kaart brengen.\n\n\n\nDe voorspellingen kun je ook als volgt laten zien:\n\n[[1]]\n# A tibble: 192 x 6\n   .pred_neg .pred_pos  .row .pred_class diabetes .config             \n       <dbl>     <dbl> <int> <fct>       <fct>    <chr>               \n 1    1.00     0.00045     4 neg         neg      Preprocessor1_Model1\n 2    0.967    0.0330      7 neg         pos      Preprocessor1_Model1\n 3    0.0393   0.961      12 pos         pos      Preprocessor1_Model1\n 4    0.708    0.292      19 neg         neg      Preprocessor1_Model1\n 5    0.636    0.364      21 neg         neg      Preprocessor1_Model1\n 6    0.541    0.459      25 neg         pos      Preprocessor1_Model1\n 7    0.482    0.518      27 pos         pos      Preprocessor1_Model1\n 8    0.692    0.308      29 neg         neg      Preprocessor1_Model1\n 9    0.951    0.0493     34 neg         neg      Preprocessor1_Model1\n10    0.369    0.631      35 pos         neg      Preprocessor1_Model1\n# … with 182 more rows\n\nHet laatste model\nIn de vorige paragraaf is het model dat is getraind op de trainingsgegevens geëvalueerd aan de hand van de testgegevens. Maar als je eenmaal jouw definitieve model hebt bepaald, wil je het vaak trainen op je volledige dataset en het dan gebruiken om de respons voor nieuwe gegevens te voorspellen.\nAls je jouw model wilt gebruiken om de respons voor nieuwe waarnemingen te voorspellen, moet je de fit()functie op jouw workflow gebruiken en de dataset waarop je het uiteindelijke model wilt laten passen (bijvoorbeeld de volledige training + testdataset).\n\n\n\nHet final_model object bevat een aantal zaken, waaronder het ranger-object dat getraind is met de parameters die via de workflow in rf_workflow zijn vastgelegd op basis van de gegevens in diabetes_clean (de gecombineerde trainings- en testgegevens).\n\n══ Workflow [trained] ════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ──────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_normalize()\n• step_knnimpute()\n\n── Model ─────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~4,      x), importance = ~\"impurity\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  500 \nSample size:                      768 \nNumber of independent variables:  8 \nMtry:                             4 \nTarget node size:                 10 \nVariable importance mode:         impurity \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.1576627 \n\nAls we de diabetes status van een nieuwe vrouw willen voorspellen, kunnen we de predict() functie gebruiken.\nBijvoorbeeld, definieren we de data voor een nieuwe vrouw.\n\n# A tibble: 1 x 8\n  pregnant glucose pressure triceps insulin  mass pedigree   age\n     <dbl>   <dbl>    <dbl>   <dbl>   <dbl> <dbl>    <dbl> <dbl>\n1        2      95       70      31     102  28.2     0.67    47\n\nDe voorspelde diabetes status van deze nieuwe vrouw is “negatief”.\n\n# A tibble: 1 x 1\n  .pred_class\n  <fct>      \n1 neg        \n\nVariabele belang\nAls je de belangrijkheid van een variabele uit je model wilt vaststellen, voor zover je dat kan zien, moet je het modelobject uit het fit() object halen (dat voor ons final_model heet). De functie die het model extraheert is pull_workflow_fit() en dan moet je het fit-object pakken dat de output bevat.\n\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~4,      x), importance = ~\"impurity\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  500 \nSample size:                      768 \nNumber of independent variables:  8 \nMtry:                             4 \nTarget node size:                 10 \nVariable importance mode:         impurity \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.1576627 \n\nVervolgens kun je het belang van de variabele uit het ranger-object zelf halen (variable.importance is een specifiek object in de ranger-output - dit zal moeten worden aangepast voor het specifieke objecttype van andere modellen).\n\npregnant  glucose pressure  triceps  insulin     mass pedigree \n16.33289 80.62800 17.08757 21.43870 51.76331 42.41799 30.79204 \n     age \n34.36002 \n\n\n\n\n",
    "preview": "posts/2021-04-22-tidymodels-opnieuw/tidymodels-opnieuw_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2021-07-18T08:48:45+02:00",
    "input_file": "tidymodels-opnieuw.knit.md"
  },
  {
    "path": "posts/2021-03-10-machine-learning/",
    "title": "Machine Learning met Tidymodels",
    "description": "Enkele blogs zal ik aan Machine Learning besteden. Ik zal enkele tutorials bewerken die mij veel geleerd hebben. Lisa Lendway, van wie ik al twee keer eerder materiaal gebruikte, schreef een goede blog over tidymodels. Zie hieronder.",
    "author": [
      {
        "name": "Lisa Lendway, vertaling Harrie Jonkman",
        "url": {}
      }
    ],
    "date": "2021-03-11",
    "categories": [],
    "contents": "\nLaad tidyverse, tidymodels en enkele andere pakketten en zet theme (optioneel) voor een bepaalde vormgeving van de figuren.\n\n\n\nLees de King County Housing-data in en kijk eens naar de eerste vijf rijen.\n\n# A tibble: 5 x 21\n  id         date        price bedrooms bathrooms sqft_living sqft_lot\n  <chr>      <date>      <dbl>    <int>     <dbl>       <int>    <int>\n1 7129300520 2014-10-13 221900        3      1           1180     5650\n2 6414100192 2014-12-09 538000        3      2.25        2570     7242\n3 5631500400 2015-02-25 180000        2      1            770    10000\n4 2487200875 2014-12-09 604000        4      3           1960     5000\n5 1954400510 2015-02-18 510000        3      2           1680     8080\n# … with 14 more variables: floors <dbl>, waterfront <lgl>,\n#   view <int>, condition <fct>, grade <fct>, sqft_above <int>,\n#   sqft_basement <int>, yr_built <int>, yr_renovated <int>,\n#   zipcode <fct>, lat <dbl>, long <dbl>, sqft_living15 <int>,\n#   sqft_lot15 <int>\n\nOver de house_prices data lezen we het volgende:\n\n“Deze dataset bevat huizenverkoopprijzen voor King County, waar Seattle deel van uitmaakt. Het omvat huizen verkocht tussen mei 2014 en mei 2015. Deze dataset is verkregen via Kaggle.com.” De beschrijving van de variabelen in de dataset in de documentatie lijkt niet helemaal te kloppen. Een meer accurate beschrijving is hieronder te vinden. In ieder geval willen we hier de prijs van woningen modelleren.\n\n\nExploratie\nKijk eerst eens naar de verdelingen van alle variabelen om te zien of er iets onregelmatigs aan de hand is.\nKwantitatieve variabelen:\n\n\n\nDingen die opvielen en eerste gedachten over het opstartproces: * ‘Right-skewness’ in de variabele price en alle variabelen betreffende vierkante meters –> log transformeren indien lineaire regressie wordt gebruikt. * Veel 0’s in sqft_basement, view, en yr_renovated –> maak indicator variabelen van het hebben van dat kenmerk vs. niet hebben , dat wil zeggen een variabele genaamd basement waar een 0 aangeeft geen kelder (sqft_basement = 0) en wel een kelder bij (sqft_basement > 0).\n* Leeftijd van huis is misschien een betere, interpreteerbare variabele dan bouwjaar –> age_at_sale = year(date) - yr_built.\n\n\n\nData splitsen (in train- en test-sets)\nEerst splitsen we de gegevens op in training- en test-datasets. We gebruiken de trainingsgegevens om verschillende soorten modellen te proberen en de parameters van die modellen zo nodig aan te passen. De testdataset wordt bewaard voor het allerlaatst om een kleine subset van modellen te vergelijken. De initial_split() functie uit de rsample bibliotheek (onderdeel van tidymodels) wordt gebruikt om tot deze splitsing te komen. We splitsen deze dataset random, maar er zijn andere mogelijkheden om tot gestratificeerde steekproeven te komen. Daarna gebruiken we training() en testing() om de twee datasets, house_training en house_testing, te extraheren.\n\n<Analysis/Assess/Total>\n<16210/5403/21613>\n\nLater zullen we 5-voudige cross-validatie gebruiken om het model te evalueren en de modelparameters aan te passen. We zetten de vijfvoud van de trainingsdata op met de vfold_cv() functie. We zullen dit later in meer detail uitleggen.\n\n\n\nData voorspel: recipe() en step_xxx()\nWe gebruiken de recipe()-functie om de uitkomstvariabele en de predictoren te definiëren.\nEen verscheidenheid van step_xxx() functies kan worden gebruikt om data te bewerken/transformeren. Vind ze allemaal hier. Ik heb er een paar gebruikt, met korte beschrijvingen in de code. Ik heb ook een aantal selectiefuncties gebruikt, zoals all_predictors() en all_nominal() om de juiste variabelen te selecteren.\nWe gebruiken ook update_roles() om de rollen van sommige variabelen te veranderen. Voor ons zijn dit variabelen die we misschien willen meenemen voor evaluatiedoeleinden, maar die niet gebruikt zullen worden bij het bouwen van het model. Ik heb gekozen voor de rol evaluative, maar je kunt die rol elke naam geven die je maar wilt, bijvoorbeeld id, extra, junk (misschien een slecht idee?).\n\n\n\nPas het toe op de trainings-dataset, gewoon om te zien wat er gebeurt. Let op de namen van de variabelen.\n\n# A tibble: 16,210 x 36\n   id        date       bedrooms bathrooms sqft_living sqft_lot floors\n   <fct>     <date>        <int>     <dbl>       <dbl>    <dbl>  <dbl>\n 1 71293005… 2014-10-13        3      1           3.07     3.75      1\n 2 64141001… 2014-12-09        3      2.25        3.41     3.86      2\n 3 56315004… 2015-02-25        2      1           2.89     4         1\n 4 24872008… 2014-12-09        4      3           3.29     3.70      1\n 5 19544005… 2015-02-18        3      2           3.23     3.91      1\n 6 72375503… 2014-05-12        4      4.5         3.73     5.01      1\n 7 13214000… 2014-06-27        3      2.25        3.23     3.83      2\n 8 20080002… 2015-01-15        3      1.5         3.03     3.99      1\n 9 24146001… 2015-04-15        3      1           3.25     3.87      1\n10 37935001… 2015-03-12        3      2.5         3.28     3.82      2\n# … with 16,200 more rows, and 29 more variables: waterfront <dbl>,\n#   view <dbl>, sqft_above <dbl>, zipcode <fct>, lat <dbl>,\n#   long <dbl>, price <dbl>, basement <dbl>, renovated <dbl>,\n#   age_at_sale <dbl>, condition_X2 <dbl>, condition_X3 <dbl>,\n#   condition_X4 <dbl>, condition_X5 <dbl>, grade_X7 <dbl>,\n#   grade_X8 <dbl>, grade_X9 <dbl>, grade_high <dbl>,\n#   date_month_Feb <dbl>, date_month_Mar <dbl>, date_month_Apr <dbl>,\n#   date_month_May <dbl>, date_month_Jun <dbl>, date_month_Jul <dbl>,\n#   date_month_Aug <dbl>, date_month_Sep <dbl>, date_month_Oct <dbl>,\n#   date_month_Nov <dbl>, date_month_Dec <dbl>\n\nHet model definiëren en workflows creëren\nNu we de gegevens hebben opgesplitst en voorbewerkt, zijn we klaar om te modelleren! Eerst zullen we price (die nu eigenlijk log(price) is) modelleren met eenvoudige lineaire regressie.\nWe zullen dit doen met behulp van enkele modelleringsfuncties uit het parsnip pakket. Vind alle beschikbare functies hier. Hier is lineaire regressie meer in detail.\nOm ons model te definiëren, moeten we de volgende stappen zetten:\nBepaal het modeltype, dat is het algemene moeltype dat u wilt draaien.\nStel de motor in, die het pakket/de functie bepaalt die zal worden gebruikt om het model te draaien.\nStel de modus in, die ofwel “regressie” is voor continue uitkomstvariabelen of “classificatie” voor binaire/categorische uitkomstvariabelen. (Merk op dat voor lineaire regressie, het alleen “regressie” kan zijn, dus we hebben deze stap in dit geval niet NODIG).\n(OPTIONEEL) Stel argumenten in om af te stemmen (‘tunen’). We zullen hier later een voorbeeld van zien.\n\n\n\nDit is slechts het opzetten van het proces. We hebben het model nog niet aan de gegevens aangepast en er is nog één stap voordat we dat doen - een workflow maken! Hier wordt de voorbewerking en de stappen in het model gecombineerd.\n\n══ Workflow ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ──────────────────────────────────────────────────────\n6 Recipe Steps\n\n● step_rm()\n● step_log()\n● step_mutate()\n● step_rm()\n● step_date()\n● step_dummy()\n\n── Model ─────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\nModelleren en evalueren\nNu zijn we eindelijk klaar om het model te draaien! Na al dat werk, lijkt dit deel eenvoudig. We gebruiken eerst de fit() functie om het model te fitten, door te vertellen op welke dataset we het model willen draaien. Daarna gebruiken we enkele andere functies om de resultaten mooi weer te geven.\n\n# A tibble: 31 x 5\n   term        estimate std.error statistic p.value\n   <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)    4.01      0.048     83.4        0\n 2 bedrooms      -0.018     0.002    -11.2        0\n 3 bathrooms      0.036     0.003     14.3        0\n 4 sqft_living    0.294     0.025     11.7        0\n 5 sqft_lot      -0.038     0.003    -11.0        0\n 6 floors         0.021     0.003      6.87       0\n 7 waterfront     0.194     0.013     15.0        0\n 8 view          -0.061     0.004    -15.6        0\n 9 sqft_above     0.149     0.025      5.99       0\n10 basement      -0.042     0.005     -9.14       0\n# … with 21 more rows\n\nOm het model te evalueren, gebruiken we crossvalidatie (CV), specifiek de 5-voudige CV. (Ik veronderstel dat we niet zowel de vorige stap van het passen van een model op de trainingsgegevens EN deze stap moeten doen, maar ik kon er niet achter komen hoe we het uiteindelijke model uit de CV-gegevens kunnen halen … dus dit was mijn oplossing voor nu). We passen het model dus aan met de 5-voudige dataset die we in het begin hebben gemaakt. Voor een diepere discussie over crossvalidatie, raad ik Bradley Boehmke’s Resampling sectie van Hands on Machine Learning with R aan.\n\n# A tibble: 10 x 5\n   id    .metric .estimator .estimate .config             \n   <chr> <chr>   <chr>          <dbl> <chr>               \n 1 Fold1 rmse    standard       0.135 Preprocessor1_Model1\n 2 Fold1 rsq     standard       0.662 Preprocessor1_Model1\n 3 Fold2 rmse    standard       0.137 Preprocessor1_Model1\n 4 Fold2 rsq     standard       0.644 Preprocessor1_Model1\n 5 Fold3 rmse    standard       0.137 Preprocessor1_Model1\n 6 Fold3 rsq     standard       0.638 Preprocessor1_Model1\n 7 Fold4 rmse    standard       0.133 Preprocessor1_Model1\n 8 Fold4 rsq     standard       0.655 Preprocessor1_Model1\n 9 Fold5 rmse    standard       0.135 Preprocessor1_Model1\n10 Fold5 rsq     standard       0.642 Preprocessor1_Model1\n# A tibble: 2 x 6\n  .metric .estimator  mean     n  std_err .config             \n  <chr>   <chr>      <dbl> <int>    <dbl> <chr>               \n1 rmse    standard   0.135     5 0.000668 Preprocessor1_Model1\n2 rsq     standard   0.648     5 0.00437  Preprocessor1_Model1\n# A tibble: 2 x 5\n# Groups:   .metric [2]\n  .metric .estimator  mean     n  std_err\n  <chr>   <chr>      <dbl> <int>    <dbl>\n1 rmse    standard   0.135     5 0.000668\n2 rsq     standard   0.648     5 0.00437 \n\nVoorspellen en evalueren van testgegevens\nIn dit eenvoudige scenario zijn we wellicht geïnteresseerd in hoe het model presteert op de testgegevens die werden weggelaten. De onderstaande code past het model toe op de trainingsgegevens en past het toe op de testgegevens. Er zijn andere manieren waarop we dit hadden kunnen doen, maar de manier waarop we het hier doen zal nuttig zijn wanneer we complexere modellen gaan gebruiken waarbij we de modelparameters moeten afstellen.\nNadat het model is aangepast en toegepast, verzamelen we de prestatiecijfers en geven we ze weer en tonen we de voorspellingen van de testgegevens.\n\n# A tibble: 2 x 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard       0.135 Preprocessor1_Model1\n2 rsq     standard       0.655 Preprocessor1_Model1\n# A tibble: 5,403 x 5\n   id               .pred  .row price .config             \n   <chr>            <dbl> <int> <dbl> <chr>               \n 1 train/test split  5.58    12  5.67 Preprocessor1_Model1\n 2 train/test split  5.53    17  5.60 Preprocessor1_Model1\n 3 train/test split  5.90    27  5.97 Preprocessor1_Model1\n 4 train/test split  5.58    29  5.64 Preprocessor1_Model1\n 5 train/test split  5.67    31  5.76 Preprocessor1_Model1\n 6 train/test split  5.88    38  5.81 Preprocessor1_Model1\n 7 train/test split  5.69    40  5.78 Preprocessor1_Model1\n 8 train/test split  5.79    41  5.80 Preprocessor1_Model1\n 9 train/test split  5.77    42  5.89 Preprocessor1_Model1\n10 train/test split  5.66    44  5.84 Preprocessor1_Model1\n# … with 5,393 more rows\n\nDe onderstaande code maakt een eenvoudige plot om de voorspelde vs. de werkelijke prijs van de huisgegevens te onderzoeken.\n\n\n\n\n\n\nHoe zal het model worden gebruikt?\nWanneer we modellen creëren is het belangrijk na te denken over hoe het model zal worden gebruikt en met name hoe het model schade zou kunnen berokkenen. Wat opvalt in de bovenstaande grafieken is dat de prijs van woningen met een lagere prijs gemiddeld wordt overschat, terwijl de prijs van woningen met een hogere prijs gemiddeld wordt onderschat.\nWat als dit model werd gebruikt om de prijs van woningen te bepalen voor de onroerendgoedbelasting? Dan zouden lager geprijsde huizen te zwaar worden belast en hoger geprijsde huizen te weinig.\nMer complexe modellen met tuning parameters\nNu gaan we de Least Absolute Shrinkage and Selection Operator (LASSO) regressie proberen. Deze methode krimpt sommige coëfficiënten tot 0 op basis van een strafterm. We zullen crossvalidatie gebruiken om ons te helpen de beste strafterm te vinden.\nHet model opzetten\nWe zetten het model op zoals we het lineaire model hebben opgezet, maar voegen nu een set_args() functie toe. We vertellen het model dat we de penalty parameter later gaan aanpassen.\n\n\n\nDe workflow updaten\nEn dan creëren we een LASSO workflow.\n\n══ Workflow ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ──────────────────────────────────────────────────────\n6 Recipe Steps\n\n● step_rm()\n● step_log()\n● step_mutate()\n● step_rm()\n● step_date()\n● step_dummy()\n\n── Model ─────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\nAfstemmen van de strafparameter\nWe gebruiken de grid_regular() functie uit de dials bibliotheek om een aantal waarden van de penalty parameter voor ons te kiezen. Als alternatief kunnen we ook een vector van waarden opgeven die we willen proberen.\n\n# A tibble: 20 x 1\n    penalty\n      <dbl>\n 1 1.00e-10\n 2 3.36e-10\n 3 1.13e- 9\n 4 3.79e- 9\n 5 1.27e- 8\n 6 4.28e- 8\n 7 1.44e- 7\n 8 4.83e- 7\n 9 1.62e- 6\n10 5.46e- 6\n11 1.83e- 5\n12 6.16e- 5\n13 2.07e- 4\n14 6.95e- 4\n15 2.34e- 3\n16 7.85e- 3\n17 2.64e- 2\n18 8.86e- 2\n19 2.98e- 1\n20 1.00e+ 0\n\nGebruik de tune_grid() functie om het model te draaien met behulp van crossvalidatie voor alle penalty_grid waarden en evalueer op alle vouwen.\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 x 4\n  splits                id    .metrics          .notes          \n  <list>                <chr> <list>            <list>          \n1 <rsplit [12968/3242]> Fold1 <tibble [40 × 5]> <tibble [2 × 1]>\n2 <rsplit [12968/3242]> Fold2 <tibble [40 × 5]> <tibble [2 × 1]>\n3 <rsplit [12968/3242]> Fold3 <tibble [40 × 5]> <tibble [2 × 1]>\n4 <rsplit [12968/3242]> Fold4 <tibble [40 × 5]> <tibble [2 × 1]>\n5 <rsplit [12968/3242]> Fold5 <tibble [40 × 5]> <tibble [2 × 1]>\n\nBekijk de resultaten van de cross-validatie.\n\n# A tibble: 100 x 6\n   id     penalty .metric .estimator .estimate .config              \n   <chr>    <dbl> <chr>   <chr>          <dbl> <chr>                \n 1 Fold1 1.00e-10 rmse    standard       0.135 Preprocessor1_Model01\n 2 Fold1 3.36e-10 rmse    standard       0.135 Preprocessor1_Model02\n 3 Fold1 1.13e- 9 rmse    standard       0.135 Preprocessor1_Model03\n 4 Fold1 3.79e- 9 rmse    standard       0.135 Preprocessor1_Model04\n 5 Fold1 1.27e- 8 rmse    standard       0.135 Preprocessor1_Model05\n 6 Fold1 4.28e- 8 rmse    standard       0.135 Preprocessor1_Model06\n 7 Fold1 1.44e- 7 rmse    standard       0.135 Preprocessor1_Model07\n 8 Fold1 4.83e- 7 rmse    standard       0.135 Preprocessor1_Model08\n 9 Fold1 1.62e- 6 rmse    standard       0.135 Preprocessor1_Model09\n10 Fold1 5.46e- 6 rmse    standard       0.135 Preprocessor1_Model10\n# … with 90 more rows\n# A tibble: 20 x 7\n    penalty .metric .estimator  mean     n  std_err .config           \n      <dbl> <chr>   <chr>      <dbl> <int>    <dbl> <chr>             \n 1 1.00e-10 rmse    standard   0.135     5 0.000644 Preprocessor1_Mod…\n 2 3.36e-10 rmse    standard   0.135     5 0.000644 Preprocessor1_Mod…\n 3 1.13e- 9 rmse    standard   0.135     5 0.000644 Preprocessor1_Mod…\n 4 3.79e- 9 rmse    standard   0.135     5 0.000644 Preprocessor1_Mod…\n 5 1.27e- 8 rmse    standard   0.135     5 0.000644 Preprocessor1_Mod…\n 6 4.28e- 8 rmse    standard   0.135     5 0.000644 Preprocessor1_Mod…\n 7 1.44e- 7 rmse    standard   0.135     5 0.000644 Preprocessor1_Mod…\n 8 4.83e- 7 rmse    standard   0.135     5 0.000644 Preprocessor1_Mod…\n 9 1.62e- 6 rmse    standard   0.135     5 0.000644 Preprocessor1_Mod…\n10 5.46e- 6 rmse    standard   0.135     5 0.000644 Preprocessor1_Mod…\n11 1.83e- 5 rmse    standard   0.135     5 0.000644 Preprocessor1_Mod…\n12 6.16e- 5 rmse    standard   0.135     5 0.000640 Preprocessor1_Mod…\n13 2.07e- 4 rmse    standard   0.135     5 0.000623 Preprocessor1_Mod…\n14 6.95e- 4 rmse    standard   0.135     5 0.000591 Preprocessor1_Mod…\n15 2.34e- 3 rmse    standard   0.136     5 0.000522 Preprocessor1_Mod…\n16 7.85e- 3 rmse    standard   0.142     5 0.000513 Preprocessor1_Mod…\n17 2.64e- 2 rmse    standard   0.161     5 0.000515 Preprocessor1_Mod…\n18 8.86e- 2 rmse    standard   0.191     5 0.000896 Preprocessor1_Mod…\n19 2.98e- 1 rmse    standard   0.228     5 0.000960 Preprocessor1_Mod…\n20 1.00e+ 0 rmse    standard   0.228     5 0.000960 Preprocessor1_Mod…\n\n# A tibble: 1 x 2\n   penalty .config              \n     <dbl> <chr>                \n1 0.000207 Preprocessor1_Model13\n\nUpdate de workflow voor best afgestemde parameter\nPas de workflow aan om de beste afstemparameter (kleinste rmse, met select_best() in vorige stap) in het model op te nemen. Er zijn andere manieren om modellen te selecteren, zoals select_by_one_std_error() die “het meest eenvoudige model selecteert dat binnen één standaardfout van de numeriek optimale resultaten ligt”.\n\n══ Workflow ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ──────────────────────────────────────────────────────\n6 Recipe Steps\n\n● step_rm()\n● step_log()\n● step_mutate()\n● step_rm()\n● step_date()\n● step_dummy()\n\n── Model ─────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 0.000206913808111479\n  mixture = 1\n\nComputational engine: glmnet \n\nPas de beste afstelling toe op de trainingsgegevens\nNu kunnen we dit toepassen op de trainingsgegevens en het resulterende model bekijken. De uitvoer van het model was niet wat ik verwachtte. Volgens Julia Silge’s antwoord op mijn vraag hier, zou dit verholpen moeten zijn als je parsnip installeert vanaf GitHub] met devtools::install_github(\"tidymodels/parsnip\") van de devtools bibliotheek.\n\n══ Workflow [trained] ════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ──────────────────────────────────────────────────────\n6 Recipe Steps\n\n● step_rm()\n● step_log()\n● step_mutate()\n● step_rm()\n● step_date()\n● step_dummy()\n\n── Model ─────────────────────────────────────────────────────────────\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev   Lambda\n1   0  0.00 0.153800\n2   1  7.71 0.140200\n3   1 14.11 0.127700\n4   1 19.42 0.116400\n5   1 23.83 0.106000\n6   1 27.49 0.096610\n7   1 30.53 0.088030\n8   1 33.06 0.080210\n9   1 35.15 0.073080\n10  2 37.42 0.066590\n11  2 39.41 0.060670\n12  2 41.06 0.055280\n13  2 42.43 0.050370\n14  3 43.93 0.045900\n15  3 45.24 0.041820\n16  3 46.32 0.038100\n17  4 47.48 0.034720\n18  5 48.59 0.031640\n19  6 49.53 0.028830\n20  7 50.48 0.026260\n21  7 51.84 0.023930\n22  8 52.98 0.021810\n23  8 54.00 0.019870\n24  9 54.93 0.018100\n25 11 56.10 0.016490\n26 10 57.40 0.015030\n27 11 58.29 0.013690\n28 11 59.06 0.012480\n29 12 59.70 0.011370\n30 12 60.25 0.010360\n31 13 60.71 0.009439\n32 13 61.10 0.008600\n33 13 61.43 0.007836\n34 13 61.71 0.007140\n35 14 61.95 0.006506\n36 15 62.18 0.005928\n37 15 62.40 0.005401\n38 16 62.57 0.004921\n39 17 62.96 0.004484\n40 18 63.28 0.004086\n41 18 63.56 0.003723\n42 20 63.80 0.003392\n43 20 64.00 0.003091\n44 20 64.16 0.002816\n45 20 64.30 0.002566\n46 21 64.42 0.002338\n\n...\nand 32 more lines.\n# A tibble: 31 x 3\n   term        estimate  penalty\n   <chr>          <dbl>    <dbl>\n 1 (Intercept)   4.12   0.000207\n 2 bedrooms     -0.0174 0.000207\n 3 bathrooms     0.0355 0.000207\n 4 sqft_living   0.307  0.000207\n 5 sqft_lot     -0.0376 0.000207\n 6 floors        0.0210 0.000207\n 7 waterfront    0.191  0.000207\n 8 view         -0.0615 0.000207\n 9 sqft_above    0.139  0.000207\n10 basement     -0.0405 0.000207\n# … with 21 more rows\n\nWe kunnen het belang van de variabele visualiseren\n\n\n\nEvalueren op testgegevens\nTen slotte passen we het model toe op de testgegevens en onderzoeken we enkele definitieve metrieken. We tonen ook de metriek van het gewone lineaire model. Het lijkt erop dat de prestaties van het LASSO-model iets beter zijn, maar het scheelt niet veel.\n\n# A tibble: 2 x 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard       0.135 Preprocessor1_Model1\n2 rsq     standard       0.655 Preprocessor1_Model1\n# A tibble: 2 x 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard       0.135 Preprocessor1_Model1\n2 rsq     standard       0.655 Preprocessor1_Model1\n\nBronnen\nDank gaat uit naar verschillende mensen voor het delen van materiaal over tidymodels, waaronder\n En natuurlijk Lisa zelf, haar voeg ik hier zelf aan toe\n\nDit zijn de bronnen die bij deze blog ondersteuning boden:\nRebecca Barter’s blog\ntidymodels website (Alison Hill, Max Kuhn, Desirée De Leon, Julia Silge)\nJulia Silge’s tidymodels example\nUiteraard vooral Lisa Lendway via:\nLisa Lendway/2020_north_tidymodels\n\n\n\n",
    "preview": "posts/2021-03-10-machine-learning/images/house_prices_variables.png",
    "last_modified": "2021-04-20T21:16:52+02:00",
    "input_file": "machine-learning.utf8.md"
  },
  {
    "path": "posts/2021-03-10-github/",
    "title": "GitHub voor samenwerking",
    "description": "Lisa Lendway heeft een aantal interessante repositories op haar GitHub account staan, [zie hier](https://github.com/llendway). Ze zijn vaak kort, maar helder en concreet. Haar stijl en de consistentie daarin bevallen mij zeer. Van haar manier van doen leer ik veel. Zij maakt haar stukken vaak voor haar statistieklessen en deelt zo haar kennis met haar studenten en anderen buiten haar klas. Ik heb mij voorgenomen om er een aantal goed te lezen, te vertalen en te bewerken waar nodig, en deze op mijn website over te nemen. Vorige maand deed ik dat al met een blof over Distill en nu een over GitHub.",
    "author": [
      {
        "name": "Lisa Lendway, vertaling Harrie Jonkman",
        "url": {}
      }
    ],
    "date": "2021-03-10",
    "categories": [],
    "contents": "\nGitHub\nIk was al vaker van plan hier een stukje over te schrijven. Lisa Lendways tekst hierover vind ik heel duidelijk. Lisa, ik hoop dat je het goed vindt dat ik mij aan jou op trek zo. Dank je wel.\nMijn eigen GitHub accountLisa Lendway heeft veel van haar materiaal weghaald uit Happy git with R by Jenny Bryan. Dat is inderdaad een uitstekende bron, maar bevat ook veel informatie die we niet altijd nodig hebben. Als je Git en GitHub op meer geavanceerde manieren wilt gebruiken of als dit stuk onduidelijk is voor je, dan moet je het zeker bekijken. Het is trouwens überhaupt een goede bron.\nVideo uitleg\n\n\nVoicethread tutorial\nGit en GitHub\nGit is een versie controle systeem. Het is net zoiets als Googledocs, maar het biedt ruimte aan veel soorten bestanden, ook bestanden waar Google docs niets mee kan … zoals .rmd bestanden! GitHub is een online interface om met Git te werken.\nWaarom leren we deze dingen?!\nGitHub is goed geïntegreerd met R Studio. Dus, we zullen geen command-line functies hoeven te gebruiken, tenminste niet nadat we alles hebben ingesteld.\nJe bent verplicht om R te gebruiken voor je eindproject. De presentatie of paper moet worden opgeslagen als een .rmd document dat kan worden ‘geknit’ tot een html document. Door GitHub te gebruiken, kun je gemakkelijk met je groep samenwerken, ook als je niet bij elkaar bent.\nGitHub leert je een aantal goede gewoontes aan. Je wordt gedwongen om na te denken over wanneer je ieets opslaat en om notities te maken over welke wijzigingen je hebt gemaakt, bijvoorbeeld.\nMaak eerst een GitHub account aan\nGa naar http://github.com\nGebruik een username … zie Jenny Bryan’s tips. Incorporeer jouw eigen naam, maar gebruik een andere usernaam die je verder gebrukkt, neem iets waar jouw toekomstige baas zich prettig bij voelt. De username van de universiteit is misschien een goede optie.\nInstalleer Git\n1. Controleer of je Git al geïnstalleerd hebt. Dit zal alleen het geval zijn als je het ergens anders gebruikt hebt. Om dit te doen, open je de commandoregel of, in R Studio, vouw je de Console uit. Er zou een tabblad moeten zijn dat Terminal zegt. In dat gebied type je\nwhich git\nHet geeft iets terug als\n/usr/bin/git\ndan ben je klaar en hoef je Git niet meer te installeren. Op een Windows machine kun je misschien niet eens het which git commando succesvol intypen. Dit zou verholpen moeten zijn door git te installeren. Of je zult de shell moeten gebruiken.\nAls je Git niet geïnstalleerd hebt, moet je het installeren. De instructies zijn iets anders voor Windows en Macs.\nVoor een Windows machine:\nInstalleer Git for Windows. Als er gevraagd wordt naar “Aanpassen van uw PATH omgeving”, zorg er dan voor dat u “Git vanaf de commandoregel en ook van software van derden” selecteert. Anders denken we dat het goed is om de standaardinstellingen te accepteren.\nR Studio voor Windows geeft er de voorkeur aan dat Git geïnstalleerd wordt onder C:/Program Files en dit lijkt de standaard te zijn. Dit houdt bijvoorbeeld in dat de Git executable op mijn Windows systeem te vinden is in C:/Program Files/Git/bin/git.exe. Tenzij je specifieke redenen hebt om anders te doen, volg deze conventie.\nVoor een Mac machine:\nGa naar jouw shell/terminal en voer één van deze commando’s in om een aanbod te krijgen om developer command line tools te installeren. Accepteer het aanbod … klik op installeren.\ngit --version\ngit config\nSommigen van jullie die op een Mac werken moeten misschien eerst het volgende doen in de terminal als je een project zonder succes probeert te openen.\nxcode-select --install\nJe komt er zo achter of dit het geval is.\nGa nu terug naar de Console in R Studio en installeer het usethis pakket in R Studio. Sluit vervolgens R Studio en open het opnieuw.\nLaad de usethis bibliotheek door het volgende stukje code in de console uit te voeren:\nlibrary(usethis)\nVoer de volgende code uit in de console met enkele kleine wijzigingen. De user.name is je Git gebruikersnaam. Dit kan anders zijn dan je GitHub gebruikersnaam, hoewel het misschien een goed idee is om het gewoon hetzelfde te houden. De user.email MOET hetzelfde zijn als je GitHub gebruikers email.\nuse_git_config(user.name = \"Jane Doe\", user.email =       \"jane@example.org\")\nMaak een eerste repo (repository) en gebruik RStudio daarbij\nHet woord “repo” is een afkorting van “repository”, en dat is precies wat het is: een plaats waar dingen (onze bestanden, in dit geval) worden opgeslagen. Het is als de map die je gemaakt hebt om al je werk voor deze les in op te slaan.\nLaten we naar GitHub gaan en inloggen. Nadat je ingelogd bent, zou je een klein icoontje in de rechter bovenhoek moeten zien. Het mijne is een afbeelding van mij. Als ik daar op klik verschijnt er een drop-down en kan ik “Your repositories” kiezen. Doe dat. Je zou nu zoiets als dit moeten zien:\n\nKlik op de “New” knop. Geef jouw repository een naam, bv NAME_test_repo, waar NAME eigenlijk jouw naam is. Kies Public en klik de README file aan. Klik dan op Create repository.\n\nEr zijn dingen die je direct binnen GitHub kunt doen, maar we zullen ons richten op de integratie met R Studio.\nKlonen van een repo\nDenk aan het klonen van een repo als het “kopiëren” van de repository naar je computer. Maar als met het kopiëren doet, houdt het de verbinding met de online repo.\nLaten we dit doen. Op je mijn_test_repo pagina, kies je de groene knop met Code en kopieer je het pad door het icoontje met een pijl erop te selecteren en erop te klikken.\nGa nu naar R Studio. Klik op Bestand –> Nieuw Project … Je zou nu een venster moeten zien dat er als volgt uitziet:\n\nKies Version Control. Dan zie je een scherm dat er zo’n beetje zo uitziet:\n\nKies Git. Dan zou je een scherm moeten zien dat er uitziet als dit, zonder alle details ingevuld. De Repository URL is waar je de repo URL moet plakken die je gekloond hebt van github. Het zal ook de Project mapnaam invullen. Laat die gewoon staan. Let op waar de project directory zich bevindt en verander het naar een betere directory indien nodig. Klik op Create Project.\n\nAls je in de Bestanden tab kijkt in het rechter ondervenster van R Studio, dan zou je het .gitignore bestand moeten zien, het project bestand (eindigt op .Rproj), en het README.md bestand. Je zou ook een Git tab moeten zien in het rechter bovenvenster van R Studio. Als je nu op de Git tab klikt, zul je daar niets zien.\nMet de Git tab open, laten we het README.md bestand in R Studio openen. Maak een kleine wijziging in het bestand door de zin “Ik verander iets in dit bestand.” toe te voegen. Klik dan op het save icoon. Als je dit doet, zul je README.md zien verschijnen in de Git tab.\nKlik nu op de Commit knop in de Git tab. Zet een vinkje in het vakje naast het README.md bestand onder het woord Staged (in de toekomst kun je meerdere bestanden tegelijk stagen door de vakjes naast meerdere bestanden aan te vinken) en voeg een commentaar toe aan het commit vakje.\nHet zou er ongeveer zo uit moeten zien:\n\nKlik tenslotte op commit. Je krijgt dan een bericht dat het voltooid is. Het bericht kan cryptisch overkomen als je er niet aan gewend bent. Het ziet er ongeveer zo uit:\n\nDe wijziging die je hebt gemaakt is nu gecommit in het lokale geheugen. Het gewijzigde bestand is alleen gewijzigd op je computer, NIET online als je op GitHub kijkt … ga maar eens kijken. Klik op de Diff knop in de Git tab en je kunt de geschiedenis van je commits zien.\nVervolgens gaan we die wijzigingen naar GitHub pushen door op de groene pijl omhoog in de Git tab te klikken. Dit zal je een bericht geven dat er ongeveer zo uitziet:\n\nWerd je gevraagd om een gebruikersnaam en wachtwoord? Probeer een andere wijziging te maken, vast te leggen en te pushen. Wordt er nog steeds om een gebruikersnaam en wachtwoord gevraagd? Zo ja, dan kun je hier zien hoe je dat doet Jenny Bryans bron.\nPROBEER HET EENS!!\nVoeg een .rmd bestand toe aan je project. Doe dit door te gaan naar Bestand –> Nieuw bestand –> R Markdown … Voeg wat woorden en een R code chunk toe aan het .rmd bestand. Sla het op, commit het (vergeet het bericht niet!), en push het. Controleer GitHub online om er zeker van te zijn dat je het .rmd bestand daar ziet.\nNu, knit je het bestand lokaal. Commit de wijzigingen (zorg ervoor dat je een vinkje zet naast alles wat je ge-staged wilt hebben - .rmd, .html, etc.) en push ze naar GitHub. Controleer GitHub online om er zeker van te zijn dat je alles ziet wat je verwacht.\nPartners toevoegen\nTot nu toe hebben we eigenlijk alleen technieken geleerd om GitHub te gebruiken om onze eigen bestanden te beheren, maar het coolste eraan zijn de samenwerkingsmogelijkheden. De manier waarop we dit gaan leren is door medewerkers aan de repo toe te voegen.\nZoek iemand om mee samen te werken. Als er een oneven aantal is, maak dan een groepje van drie. In je groepje, voeg elkaar toe als medewerkers aan je project. In GitHub, op de repo pagina, ga naar Instellingen. Een van de opties aan de linkerkant is Collaborators. Klik daarop en doe wat er staat.\nDe persoon die is uitgenodigd om samen te werken zal een email ontvangen en zou ook in staat moeten zijn om de uitnodiging op GitHub te zien. Ze moeten deze accepteren. Eenmaal geaccepteerd, zouden jullie beiden (of alle drie) toegang moeten hebben om wijzigingen in het bestand vast te leggen.\nCommit –> Push –> Pull –> … (en Communicatie)\nZodra je medewerkers hebt toegevoegd, kunnen alle medewerkers committen en pushen. Maar, wat gebeurt er als iemand iets commit en terugzet en jij gaat er dan aan werken op je computer… hoe krijg je dan die wijzigingen? … PULL!\nProbeer in jullie groepen het volgende. Jullie moeten allemaal meewerken aan elkaars projecten, dus je kunt van rol wisselen nadat je het één keer gedaan hebt.\nDe medewerker moet eerst de repo klonen waaraan hij gevraagd is om mee te werken. Als ze een ander project open hebben, sla dan op, commit, en push alle wijzigingen. Sluit dan dat project en open het project waar ze om gevraagd is om aan mee te werken door de GitHub repo te klonen. De medewerker moet het project open hebben in R Studio.\nDe medewerker moet proberen te trekken (pullen) door op de aqua pijl omlaag te klikken in de Git tab. Je zou een bericht moeten krijgen dat er als volgt uitziet:\n\nDe persoon die de repo heeft aangemaakt, maakt een wijziging in zijn .rmd bestand. Het kan een kleine wijziging zijn, zoals het toevoegen van een zin. Diezelfde persoon slaat het bestand op, commit (staged en schrijft een commit boodschap), en pushed het naar GitHub. Controleer online om er zeker van te zijn dat de meest recente wijzigingen zijn gepushed.\nDe medewerker haalt nu die wijzigingen naar zijn lokale map (naar zijn computer). Klik op het pull icoon. Je zou een bericht moeten zien dat er ongeveer zo uitziet:\n\nEn controleer het bestand waarin een wijziging is aangebracht om er zeker van te zijn dat de wijziging wordt weerspiegeld in het bestand op uw computer.\nGa nog een paar keer heen en weer en breng kleine wijzigingen aan. Degene die eigenaar is van de repo zou de wijziging moeten maken en de medewerker zou het moeten binnenhalen. Wissel dan van rol. Als je wisselt, wees er dan zeker van dat je aan het juiste project werkt.\nConflicten samenvoegen\nAls je samen aan een project werkt, is de kans groot dat je tegen een moment aanloopt waarop twee van jullie hetzelfde bestand tegelijkertijd aan het bewerken zijn. Soms, als je allebei je wijzigingen probeert te pushen, zul je wat genoemd wordt een “merge conflict” krijgen. GitHub zal niet weten welke te gebruiken. Dus, zal het je dwingen om te beslissen.\nAls je probeert je wijzigingen naar GitHub te pushen en iemand anders heeft zijn wijzigingen met betrekking tot hetzelfde bestand al gepushed, dan zul je een bericht als dit krijgen:\n\nDan, wanneer je de wijzigingen binnenhaalt, krijg je een bericht zoals dit:\n\nMerk op dat het je vertelt in welk bestand het samenvoegconflict zich voordeed. Je moet dat bestand openen en beslissen hoe de conflicterende informatie samengevoegd moet worden. In het begin zal het er ongeveer zo uitzien:\n\nHet deel na het woord HEAD is wat in je lokale bestand staat. Alles na de ====== is wat in het bestand op afstand staat (d.w.z. de wijzigingen die je medewerker heeft gemaakt). Je kunt besluiten om dit op te lossen op elke manier die je wilt: combineer de twee ideeën, verwijder ze allebei, houd er maar een over, etc. Als je klaar bent, zorg er dan voor dat je de <<<<<<< HEAD en >>>>>>> verwijdert, gevolgd door de alfanumerieke string, plus alle andere vreemde tekens.\nSla het bestand dan op en doe de gebruikelijke commit en push. Je zou de wijzigingen naar GitHub gepushed moeten zien worden.\nLaten we dit eens proberen!\nIn groepjes van 3-4, oefen je GitHub vaardigheden.\nKies iemand om een nieuwe repo aan te maken op GitHub genaamd our_collaborative_graph.\nDe maker voegt de anderen toe als collaborators.\nDe medewerkers moeten hun e-mail controleren en accepteren dat ze medewerkers zijn.\nDe maker en de medewerkers klonen de repo lokaal.\nEen medewerker voegt lokaal een .rmd bestand aan het project toe. De titel moet zijn “Onze grafiek” en voeg alle groepsleden toe als auteurs. Voeg een R code stuk toe dat de tidyverse bibliotheek laadt. Sla het bestand op, commit met bericht, en push naar GitHub. Controleer online om er zeker van te zijn dat het goed gepushed is.\nAlle andere groepsleden halen de wijzigingen lokaal op.\nEen andere medewerker voegt een ander R code stuk toe. Maak met de mpg dataset een scatterplot met hwy op de y-as, displ op de x-as en kleur de punten met drv. Sla de wijzigingen op. Brei het bestand. commit dan met bericht en push naar GitHub. Zorg ervoor dat je alle bestanden in de commit staged. Controleer online om er zeker van te zijn dat je de wijzigingen ziet.\nAlle andere groepsleden halen de wijzigingen lokaal op.\nEen ander groepslid (medewerker of maker als je maar 3 groepsleden hebt) wijzigt de R code chunk die de grafiek maakt, door mooie x en y labels toe te voegen en te veranderen naar theme_minimal(). Sla de wijzigingen op. Brei het bestand. commit dan met bericht en push naar GitHub. Zorg ervoor dat je alle bestanden in de commit staged. Controleer online om er zeker van te zijn dat je de veranderingen ziet.\nAlle grop leden trekken. Degene die net gepushed heeft zou moeten zien dat ze al up to date zijn. Alle anderen zouden de wijzigingen lokaal terug moeten zien.\nNu moeten alle groepsleden iets toevoegen aan het .rmd bestand. Vertel elkaar niet wat je toevoegt. Als je klaar bent, sla op, brei, commit, en push naar GitHub. Ten minste één van jullie zal een samenvoeg conflict krijgen, dus zal het je vragen om wijzigingen van GitHub binnen te halen en het conflict op te lossen. Doe dat. Deze keer zul je het .rmd bestand moeten aanpassen in plaats van de README zoals ik eerder liet zien.\nAls je klaar bent, moeten 112 leerlingen een project opzetten met hun eigenlijke groepsprojectleden. Neem een .rmd-bestand op met de naam “ideas.rmd” waarin je ideeën kunt uitwisselen, inclusief onderwerpen en gegevens die je misschien zou willen analyseren. 155 leerlingen moeten de enquête over het groepsproject op de Moodle-pagina invullen.\nBron\nHappy git with R door Jenny Bryan. Leer meer over Distill via https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-04-20T21:09:01+02:00",
    "input_file": "github.utf8.md"
  },
  {
    "path": "posts/2021-02-19-website-met-distill/",
    "title": "Website met distill",
    "description": "Website met blog maken",
    "author": [
      {
        "name": "Lisa Lendway, vertaling Harrie Jonkman",
        "url": {}
      }
    ],
    "date": "2021-02-19",
    "categories": [],
    "contents": "\nDistill\nMijn eigen Harrie’s Hoekje blog, over een aantal ontwikkelingen in de dataanalyse, maak ik ook met het gebruik van het pakket Distill. Met Distill kun je wetenschappelijke websites maken, een blog en artikelen schrijven. Over hoe je dat doet schreef Lisa Lendway een kort en krachtige blog. Dat kan ik niet beter. Dank je, Lisa, hiervoor. Haar blog staat hier\nWaarom een website?\nNou, eindelijk heb ik het gedaan!, zo begint zij haar blog dat ik (Harrie) hier verder volg.\nIk (Lisa) heb een website gemaakt. En om dat te vieren, ga ik met jullie delen hoe ik het gedaan heb. En waarom heb ik dat gedaan? Twee belangrijke redenen zijn er: 1. om materiaal te delen dat nuttig kan zijn voor anderen, 2. om wat dingen voor mezelf te documenteren, allemaal op één plek.\nIk koos voor een {distill} site omdat het me genoeg vrijheid leek te geven om mijn site aan te passen en ook weer niet zo veel vrijheid dat ik zou verzanden in details (bv. kleuren kiezen … oeps, daar heb ik toch nog veel tijd aan besteed).\nBronnen\nVoordat ik begin, zal ik wat bronnen delen die ik heb gebruikt.\nAlison Hill en Desirée De Leon’s webinar over Sharing on Short Notice. KIJK HIERNAAR voordat je verder gaat. Hier werd ik voor het eerst geïntroduceerd op netlify en toen zag ik pas hoe makkelijk het is om html-files tot een website om te vormen website. Je zou daar zelfs eerst mee kunnen beginnen voordat jij je op een website springt. Misschien spreken sommige van de andere opties die ze bespreken jou meer aan dan {distill}.\nDe distill documentatie, ook al in de vorm van een … distill website!\nDistill websites van anderen: Ijeamaka Anyene, Shannon Pileggi(aka Piping Hot Data), Miles McBain, Tom Mock, en meer!\nAlison Hill’s website voor hoog niveau inhoud en design inspiratie. Iedere keer vind ik wel een nieuw bron als ik haar website bezoek. Bijvoorbeeld, bekijk eens haar praatje op ‘Recent updates in the R markdown family’.\nEn meer! Ik zal proberen in dit blog op enkele bronnen terug te komen.\nKijk ook naar de video die Lisa maakte en die je hier vindt.\nBouwen van de site\nLaten we nu verder gaan met het maken van de site. Onderweg kom ik terug op de YouTube-video. Ik kom steeds terug op dezelfde YouTube-video, maar ik zal ze daar zetten waar ik het op dat moment over heb. Zo is het makkelijker voor je om delen over te slaan als je dat wilt.\nEen GitHub repo opzetten & het project starten\nKijk naar Tom Mock’s post hier. Ik denk dat zijn manier om dit te doen logischer is dan de mijne. Helaas, zag ik het toen ik mijn ding had gedaan :(\nIk probeer er een gewoonte van te maken om al mijn projecten met een GitHub repo te beginnen. Dus, dat is wat ik hier ook heb gedaan. Hier zijn alle stappen:\nMaak een repo\nCreëer project in R Studio door de repo te klonen * Laad de {distill} bibliotheek\nMaak een “starter” site met de create_website() functie. Ik heb dit gebruikt in plaats van create_blog() omdat ik van mijn hoofdpagina een About pagina wilde maken in plaats van een blog. Ik zal het blog gedeelte later toevoegen. Lees de {distill} documentatie om je te helpen bij het beslissingsproces. Omdat ik eerst mijn GitHub repo heb gemaakt, moest ik wat rare dingen doen om de mappenstructuur te fixen. Het werkt, maar het is een beetje lelijk.\nVerplaats alle bestanden behalve het .Rproj bestand van de zojuist gemaakte map naar de hoofdmap van het archief.\nVerwijder de website map (zou leeg moeten zijn, behalve het .Rproj bestand).\nVerwijder het README.md bestand in de hoofdmap van het archief (als ik dat niet deed, bouwde de site later niet).\n\nOf kijk naar dit deel van de video (tot minuut 8:04):\n\n\nDe site voor de eerste keer bouwen\nVervolgens willen we de site bouwen. Om dit op een eenvoudige manier te doen, sla je jouw bestanden op, sluit je RStudio en open je het opnieuw, waarbij jij ervoor zorgt dat je je in het project van jouw distill-site bevindt. Wanneer je dit doet, zou er een Build tab moeten verschijnen in jouw paneel aan de rechterbovenhoek (of waar u gewoonlijk jouw Environment, History, enz. hebt). Klik op het Build Website-icoon en je zou je site moeten zien! (8:25 in de video, als je het mij wilt zien doen).\nOp dit punt zijn er veel verschillende richtingen die je op kunt gaan. Ik zal je vertellen wat ik gedaan heb. Als je niet veel meer wilt aanpassen, kun je naar ?? gaan om een eenvoudige manier te vinden om je website te publiceren.\nAanpassen van de home page\nIk wilde dat mijn “Home” pagina mijn “About” pagina zou worden. Om dit te doen, heb ik eerst wat veranderingen aangebracht in het _site.yml bestand, het “About” gedeelte van de navigatiebalk verwijderd en de tekst voor de homepage hernoemd naar “About”.\nDan, om te beginnen met het aanpassen van mijn “About” pagina, voeg ik een foto van mezelf toe aan het index.Rmd bestand en plaats ik wat plaatshouders voor plaatsen waar ik wat informatie zal schrijven.\nBekijk dit in de video (tot minuut 17:35):\n\n\nVoeg het blog toe en maak jouw eerste post\nAls je de blog route vanaf het begin hebt gevolgd, hoef je dit deel niet te doen. Merk op dat ik in de video de dingen in de verkeerde volgorde deed\nVoeg een post toe met create_post(\"mijnpost\"). Dit genereert een R Markdown bestand met de naam mypost.Rmd (tenzij je de slug verandert), een _posts map, en een map die de datum en de naam van het bericht heeft. Door te beginnen met de datum, houdt het je berichten in een mooie volgorde :)\nBewerk jouuw blog post-Rmarkdownbestand naar believen. Zorg ervoor dat je dit bestand knit zodat het op de blog verschijnt. Deze bestanden worden niet automatisch gebreid. Dat is met opzet.\nMaak een nieuw R Markdown bestand met ALLEEN een yaml kop met een titel en listing. Sla het op in de hoofd repository.\nWijzig het _site.yml bestand om de listing pagina te linken. De tekst kan zijn wat je maar wilt - dit is wat er op de navigatiebalk komt te staan. De href waarde is de .html van het listing .Rmd bestand.\nVoeg een aangepaste blog preview afbeelding toe. Zet de afbeelding die je hiervoor wilt gebruiken in de map voor de blog post. In de yaml kop van het R Markdown bestand van uw blog, voeg je preview: image.png toe, waar image.png de naam van jouw afbeelding is. Standaard zal de preview de eerste plot zijn die gegenereerd wordt in uw R code.\nBekijk dit in de video (tot minuut 33:27):\n\n\nPas_site.yml aan\nIn dit deel voeg ik enkele aangepaste iconen toe aan de bovenste navigatiebalk van de site. Deze bevatten een persoonlijke favicon aan de linkerkant (die ik uiteindelijk toch weer weghaal) en links naar mijn GitHub, LinkedIn en Twitter pagina’s (en later voeg ik er een toe aan mijn YouTube kanaal).\nVoeg het volgende toe aan het _site.yml bestand na de navbar koptekst. Wees voorzichtig met inspringen. Je kunt mijn bestand hier bekijken (ik heb meer bewerkt sinds het maken van de video, dat wel).\n- icon: fa fa-github\n  href: https://github.com/YOUR_USERNAME\n- icon: fa fa-linkedin\n  href: https://www.linkedin.com/in/YOUR_LINKEDIN/\n- icon: fa fa-twitter\n  href: https://twitter.com/YOUR_TWITTER\nOm een gepersonaliseerde favicon toe te voegen, voeg het volgende toe na navbar:, waar ll.png de persoonlijke favicon is. Je kunt ook een link naar een website toevoegen waar hij naartoe gaat als je er op klikt. Nogmaals, wees voorzichtig met inspringen.\n  logo:\n    image: ll.png\nVolg de video hieronder (tot minuut 44:22). Toen ik dit de eerste keer deed, maakte ik wat fouten, dus ik laat je dat deel van de video overslaan.\n\n\nPubliseer de site via netlify\nNu je een website hebt, kun je die gemakkelijk publiceren via netlify. Ik zal je laten zien hoe je deze aan je GitHub repo kunt koppelen, zodat iedere keer dat je wijzigingen naar GitHub stuurt, je website die wijzigingen zal weergeven. Ik raad aan om eerst een account op netlify aan te maken.\nBekijk de video om te zien hoe ik het doe (tot minuut 48:22):\n\n\nMaak het je eigen!\nHet laatste stuk is om wat aanpassingen te doen. Dankzij de geweldige {distill} auteurs, kunnen we de create_theme() functie gebruiken om ons door het aanpassen van wat css te leiden. Ik ben een echte beginner als het op css aankomt, dus er is van een makkelijkere manier. Ik raad ten zeerste aan om de documentatie over theming en de recente updates door te lezen. En lees grondig de tekst van de website (misschien heb ik dat de eerste keer niet gedaan)!\nVoegtheme: \"my_theme.css\" aan de bodem van de _site.yml file toe.\nJe kunt de video tot het einde bekijken:\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-04-20T21:04:31+02:00",
    "input_file": "website-met-distill.utf8.md"
  },
  {
    "path": "posts/2020-11-17-testen-met-bayes/",
    "title": "Testen met Bayes",
    "description": "Resultaten testen met Bayesiaanse onderzoekstechnieken.",
    "author": [
      {
        "name": "Makowski en anderen, vertaling Harrie Jonkman",
        "url": "https://easystats.github.io/bayestestR/"
      }
    ],
    "date": "2021-02-14",
    "categories": [],
    "contents": "\nKorte inleiding\nDe laatste weken lees ik weer regelmatig over de achtergronden, de principes en de voordelen van bayesiaanse onderzoekstechnieken. De update van Statistical Rethinking. A Bayesian Course with Examples in R and Stan (McElreath, 2020) en het nieuwe boek Regression and other stories (Gelman, Hill & Vehtari, 2020) geven veel inspiratie. Daarover later meer. Ondertussen verscheen vorig jaar het R-pakket bayestestR met een hele duidelijke bijbehorende website waarin een aantal uitgangspunten heel duidelijk worden uitgelegd en de voordelen van deze manier van onderzoek doen worden vergeleken met de klassieke onderzoekstechniek. Ik kon het niet laten om een aantal lessen te vertalen om dit goed in mijn vingers te krijgen. Mogelijk dat ik hier later nog een keer aandacht aan besteed. De website is gebaseerd op twee artikelen waar de wetenschappers naar refereren. Natuurlijk moet ik deze artikelen hier aan het begin noemen.\nMakowski, D., Ben-Shachar, M. S., & Lüdecke, D. (2019). bayestestR: Describing Effects and their Uncertainty, Existence and Significance within the Bayesian Framework. Journal of Open Source Software, 4(40), 1541. 10.21105/joss.01541\nMakowski, D., Ben-Shachar, M. S., Chen, S. H. A., & Lüdecke, D. (2019). Indices of Effect Existence and Significance in the Bayesian Framework. Frontiers in Psychology 2019;10:2767. 10.3389/fpsyg.2019.02767\nWaarom zou je het Bayesiaanse kader gebruiken?\nHet Bayesiaanse statistische raamwerk wint snel aan populariteit onder wetenschappers, wat samenhangt met de algemene verschuiving naar open en eerlijke wetenschap. Redenen om de voorkeur te geven aan deze aanpak zijn betrouwbaarheid, nauwkeurigheid (in rommelige data en kleine steekproeven), de mogelijkheid om prior kennis in de analyse te introduceren en, kritisch gezien, de intuïtiviteit van de resultaten en hun rechtstreekse interpretatie (Andrews & Baguley, 2013; Etz & Vandekerckhove, 2016; Kruschke, 2010; Kruschke, Aguinis, & Joo, 2012; Wagenmakers et al., 2018).\nIn het algemeen wordt de frequentisttische aanpak geassocieerd met de focus op null hypothesetests, en het misbruik van p-waarden blijkt kritisch bij te dragen aan de reproduceerbaarheidscrisis van psychologische wetenschap (Chambers, Feredoes, Muthukumaraswamy, & Etchells, 2014; Szucs & Ioannidis, 2016). Men is het er algemeen over eens dat de veralgemening van de Bayesiaanse aanpak een manier is om deze problemen te overwinnen (Benjamin et al., 2018; Etz & Vandekerckhove, 2016).\nAls we het er eenmaal over eens zijn dat het Bayesiaanse raamwerk de juiste weg is, kun je je vervolgens afvragen wat het Bayesiaanse raamwerk is.\nWaar gaat al dat gedoe over?\nWat is het Bayesiaanse kader?\nHet aannemen van het Bayesiaanse raamwerk is meer een verschuiving in het paradigma dan een verandering in de methodologie. Inderdaad, alle gemeenschappelijke statistische procedures (t-tests, correlaties, ANOVA’s, regressies, …) kunnen nog steeds worden uitgevoerd met behulp van het Bayesiaanse raamwerk. Een van de kernverschillen is dat in het frequentische perspectief (de “klassieke” statistiek, met p- en t-waarden, evenals met die rare vrijheidsgraden), de effecten vastliggen (maar onbekend zijn) en data random zijn. Aan de andere kant wordt in het Bayesiaanse inferentieproces, in plaats van schattingen van het “ware effect”, de waarschijnlijkheid van verschillende effecten berekend gegeven de waargenomen gegevens. Dat resulteert in een verdeling van mogelijke waarden voor de parameters, de zogenaamde posterior-distributie.\nDe onzekerheid in de Bayesiaanse inferentie kan bijvoorbeeld worden samengevat door de mediaan van de verdeling, evenals een reeks waarden van de posterior distributie die de 95% meest waarschijnlijke waarden omvat (het 95% waarschijnlijke interval). Cum grano salis, deze worden beschouwd als de tegenhangers van de punt-schatting en het betrouwbaarheidsinterval in een frequentistisch kader. Om het verschil in interpretatie te illustreren, laat het Bayesiaanse raamwerk toe om te zeggen “gezien de geobserveerde gegevens, heeft het effect een 95% kans om binnen dit bereik te vallen”, terwijl het minder eenvoudige alternatief voor de frequentist zou zijn “wanneer herhaaldelijk betrouwbaarheidsintervallen uit deze reeks gegevens worden berekend, is er een 95% kans dat het effect binnen een bepaald bereik valt”. In wezen geven de Bayesiaanse sampling algoritmen (zoals MCMC-bemonstering) een waarschijnlijkheidsverdeling (de posterior) van een effect dat compatibel is met de waargenomen gegevens. Zo kan een effect worden beschreven door de posterior verdeling te karakteriseren in relatie tot de centraliteit (punt-schattingen), de onzekerheid, en het bestaan en de betekenis ervan.\nMet andere woorden, als we de wiskunde achterwege laten, kunnen we dat zeggen:\nDe frequentist probeert “het reële effect” in te schatten, bijvoorbeeld, de “echte” waarde van de correlatie tussen x en y. Vandaar dat de modellen van frequentisten een “punt-schatting” opleveren. (d.w.z. één enkele waarde) van de “echte” correlatie (bv. r = 0,42) die wordt geschat op basis van een aantal onduidelijke veronderstellingen (minimaal, aangezien de gegevens willekeurig worden onttrokken van een “ouder”, meestal een normale verdeling).\nDe Bayesiaan gaat niet van zoiets uit. De gegevens zijn wat ze zijn. Op basis van deze geobserveerde gegevens (en een eerdere overtuiging over het resultaat) geeft het Bayesiaanse samplingsalgoritme (soms ook wel MCMC sampling genoemd) een waarschijnlijkheidsverdeling (de zogenaamde posterior) van het effect dat compatibel is met de geobserveerde gegevens. Voor de correlatie tussen x en y geeft het een verdeling, die bijvoorbeeld zegt: “het meest waarschijnlijke effect is 0,42, maar deze gegevens zijn ook compatibel met correlaties tussen 0,12 en 0,74”.\nOm onze effecten te karakteriseren is geen behoefte aan p-waarden of andere cryptische indices. We beschrijven gewoon de posterior verdeling van het effect. We kunnen bijvoorbeeld de mediaan, de 89% Credible Interval of andere indices rapporteren.\nMet andere woorden, als we de wiskunde even achterwege laten, kunnen we zeggen dat:\n\nHoewel het doel van dit pakket is het gebruik van Bayesiaanse statistieken te verdedigen, zijn er serieuze argumenten die de frequentie-indexen ondersteunen (zie bijvoorbeeld hier). Zoals altijd is de wereld niet zwart-wit (p < .001).\n\nNou… hoe werkt het?\nEen eenvoudig voorbeeld\nInstallatie van BayestestR\nU kunt bayestestR samen met de hele easystats suite installeren (of alleen bayestestR omdat de suite installeren bij mij niet werkte) door het volgende uit te voeren: ## A simple example\n\n\n\nLaten we ook het pakket rstanarm installeren en laden, die het mogelijk maakt om de Bayesiaanse modellen, evenals de bayestestR, te werken.\n\n\n\nTraditionele lineaire regressie\nLaten we beginnen met het aanbrengen van een eenvoudige frequentistische lineaire regressie (de lm() functie staat voor lineair model) tussen twee numerieke variabelen, Sepal.Length en Petal.Length uit de beroemde iris-dataset, standaard opgenomen in R.\n\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24675 -0.29657 -0.01515  0.27676  1.00269 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   4.30660    0.07839   54.94   <2e-16 ***\nPetal.Length  0.40892    0.01889   21.65   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4071 on 148 degrees of freedom\nMultiple R-squared:   0.76, Adjusted R-squared:  0.7583 \nF-statistic: 468.6 on 1 and 148 DF,  p-value: < 2.2e-16\n\nDeze analyse suggereert dat er een significante (wat dat ook moge betekenen) en een *positieve** (met een coëfficiënt van 0,41) lineaire relatie bestaat tussen de twee variabelen.\nHet aanpassen en interpreteren van frequentiemodellen is zo eenvoudig dat het duidelijk is dat mensen het gebruiken in plaats van het Bayesiaanse kader… toch?\nNiet meer.\nBayesiaanse lineaire regressie\n\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000416 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 4.16 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.042514 seconds (Warm-up)\nChain 1:                0.06525 seconds (Sampling)\nChain 1:                0.107764 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2.1e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.045785 seconds (Warm-up)\nChain 2:                0.065693 seconds (Sampling)\nChain 2:                0.111478 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1.9e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.051297 seconds (Warm-up)\nChain 3:                0.068238 seconds (Sampling)\nChain 3:                0.119535 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1.6e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.045173 seconds (Warm-up)\nChain 4:                0.059105 seconds (Sampling)\nChain 4:                0.104278 seconds (Total)\nChain 4: \n# Description of Posterior Distributions\n\nParameter    | Median |         89% CI |      pd |        89% ROPE | % in ROPE |  Rhat |      ESS\n-------------------------------------------------------------------------------------------------\n(Intercept)  |  4.306 | [4.183, 4.424] | 100.00% | [-0.083, 0.083] |         0 | 1.000 | 4051.872\nPetal.Length |  0.409 | [0.379, 0.437] | 100.00% | [-0.083, 0.083] |         0 | 1.000 | 3934.690\n\nDat is het! Je hebt een Bayesiaanse versie van het model gedraaid door eenvoudigweg stan_glm() te gebruiken in plaats van lm() en hebt de posterior distributie van de parameters beschreven. De conclusie die we kunnen trekken, voor dit voorbeeld, zijn zeer vergelijkbaar. Het effect (de mediaan van de posterior verdeling van het effect) is ongeveer 0,41, en het kan ook als significant worden beschouwd in de Bayesiaanse zin (meer daarover later).\nDus, klaar om meer te leren?\n1. Initiatie tot Bayesiaanse modellen\nNu je de beginsectie hebt gelezen, laten we een duik nemen in de subtiliteiten van Bayesiaanse modellering met behulp van R.\nLaden van pakketten\nAls je een keer de benodigde pakketten hebt geïnstalleerd, kun je rstanarm laden (om de modellen te draaien) en ook bayestestR (om bruikbare indices te berekenen) en insight (om toegang te krijgen tot de parameters).\n\n\n\nEenvoudig lineair model (ook wel regressie genoemd)\nWe beginnen met het uitvoeren van een eenvoudige lineaire regressie om het verband tussen Petal.Length (onze voorspeller, of onafhankelijke, variabele) en Sepal.Length (onze respons-, of afhankelijke-variabele) te testen vanuit de irisdataset die standaard is opgenomen in R.\nPassend bij het model\nLaten we beginnen met het draaien van de frequentistische versie van het model, gewoon om een referentiepunt te hebben:\n\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24675 -0.29657 -0.01515  0.27676  1.00269 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   4.30660    0.07839   54.94   <2e-16 ***\nPetal.Length  0.40892    0.01889   21.65   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4071 on 148 degrees of freedom\nMultiple R-squared:   0.76, Adjusted R-squared:  0.7583 \nF-statistic: 468.6 on 1 and 148 DF,  p-value: < 2.2e-16\n\nIn dit model is de lineaire relatie tussen Petal.Length en Sepal.Length positief en significant (beta = 0,41, t(148) = 21,6, p < .001). Dit betekent dat je voor elke toename van Petal.Length (de voorspeller) met één eenheid kunt verwachten dat de Sepal.Length (het antwoord) met 0,41 zal toenemen. Dit effect kan worden gevisualiseerd door de voorspellingswaarden op de x-as en de responswaarden als y te plotten met behulp van het ggplot2 pakket:\n\n\n\nLaten we nu een Bayesiaanse versie van het model draaien door gebruik te maken van de stan_glm-functie dat in het rstanarmpakket zit:\n\n\n\nJe ziet dat het samplingsalgoritme draait.\nDe posterior eruit halen\nLaten we, als het bovenstaande eenmaal gedaan is, de parameters (d.w.z. de coëfficiënten) van het model extraheren.\n\n  (Intercept) Petal.Length\n1    4.350261    0.3945665\n2    4.217188    0.4308909\n3    4.270616    0.4095938\n4    4.341964    0.3950089\n5    4.276013    0.4220744\n6    4.347153    0.3964028\n\nZoals we kunnen zien, hebben de parameters de vorm van een lange dataframe met twee kolommen, die overeenkomen met de intercept en het effect van Petal.Length. Deze kolommen bevatten de posterior distributies van deze twee parameters. Eenvoudig gezegd is de posterior distributie een set van verschillende plausibele waarden voor elke parameter.\nOver de posterior trekkingen\nLaten we eerst eens kijken naar de lengtes van de posteriors.\n\n[1] 4000\n\n\nWaarom zijn dit er 4000, en niet meer of minder?\n\nIn de eerste plaats worden deze waarnemingen (de rijen) meestal aangeduid als posterior ‘draws’ (trekkingen). De achterliggende gedachte is dat het Bayesiaanse samplingsalgoritme (b.v. Monte Carlo Markov Chains - MCMC) zal putten uit de verborgen ware posterior distributie . Het is dus door middel van deze ‘posterior draws’ dat we de onderliggende ware posterior distribution kunnen inschatten. Hoe meer trekkingen je hebt, hoe beter je de posterior distriubtion kunt inschatten. Meer trekkingen betekent echter ook een langere rekentijd.\nAls we kijken naar de documentatie (?sampling) voor het rstanarm“sampling”-algoritme dat standaard in het bovenstaande model wordt gebruikt, kunnen we verschillende parameters zien die het aantal posterior draws beïnvloeden. Standaard zijn er 4 ketens (je kunt het zien als aparte sampling runs), die elk 2000 iter (trekkingen, iteraties) aanmaken. Echter, slechts de helft van deze iteraties wordt behouden, aangezien de helft wordt gebruikt voor de opwarming (het convergeren van het algoritme). Het totaal is dus 4 ketens * (2000 iteraties - 1000 warming-up) = 4000 posterior trekkingen. Dat kunnen we aanpassen, bijvoorbeeld:\n\n\n\nIn dit geval hebben we, zoals verwacht, 2 ketens * (1000 iteraties - 250 warming-up) = 1500 posterior trekkingen. Maar laten we ons eerste model de standaard instelling aanhouden (omdat het meer trekkingen heeft).\nHet visualiseren van de posterieure verdeling\nNu we hebben begrepen waar deze waarden vandaan komen, laten we er eens naar kijken. We zullen beginnen met het visualiseren van de posterieure distributie van de parameter waarin we geïnteresseerd zijn, het effect van Petal.Length.\n\n\n\nDeze verdeling vertegenwoordigt de waarschijnlijkheid (de y-as) van verschillende effecten (de x-as). De centrale waarden zijn waarschijnlijker dan de extreme waarden. Zoals u ziet varieert deze verdeling van ongeveer 0,35 tot 0,50, waarbij het grootste deel rond 0,41 ligt.\n\nGefeliciteerd! Je hebt zojuist je posterior distribution beschreven.\n\nEn dit is het hart van de Bayesiaanse analyse. We hebben geen p-waarden, t-waarden of vrijheidsgraden nodig: Alles is aanwezig, binnen deze posterior verdeling.\nOnze beschrijving hierboven is consistent met de waarden verkregen uit de frequentistische regressie (die resulteerde in een bèta van 0,41). Dit is geruststellend! Inderdaad, in de meeste gevallen verandert een Bayesiaanse analyse de resultaten niet drastisch of hun interpretatie. Het maakt de resultaten wel beter interpreteerbaar en intuïtief, en uiteindelijk gemakkelijker te begrijpen en te beschrijven.\nWe kunnen nu doorgaan en deze posterior verdeling nauwkeurig karakteriseren.\nDe Posterior beschrijven\nHelaas, het is vaak niet praktisch om de hele posterieure verdelingen als grafiek te rapporteren. We moeten een beknopte manier vinden om het samen te vatten. We raden aan om de posterior verdeling te beschrijven op basis van 3 elementen:\nEen puntschatting die een samenvatting is van één waarde (vergelijkbaar met de bèta in frequente regressies).\nEen credible interval die de bijbehorende onzekerheid weergeeft.\nSommige indices van betekenis, die informatie geven over het relatieve belang van dit effect.\nPuntschatting\nWelke ene waarde kan het beste mijn posterior distributie representeren?\nCentrum indices, zoals het gemiddelde, de mediaan of de modus worden meestal gebruikt als puntschatting - maar wat is het verschil tussen het frequentische en Bayesiaanse raamwerk? Laten we dit beantwoorden door eerst het gemiddelde te inspecteren:\n\n[1] 0.4085763\n\nDit ligt dicht bij de frequentistische beta. Maar zoals we weten, is het gemiddelde vrij gevoelig voor uitschieters of extremen. Misschien is de mediaan robuuster?\n\n[1] 0.408726\n\nNou, dit is zeer dicht bij het gemiddelde (en identiek als de waarden worden afgerond). Misschien kunnen we de modus nemen, dat wil zeggen, de piek van de posterior verdeling? In het Bayesiaanse kader wordt deze waarde de Maximum A Posteriori (MAP) genoemd. Laten we daar eens kijken:\n\nMAP = 0.41\n\nZe zitten allemaal heel dichtbij elkaar! Laten we deze waarden visualiseren op de posterior distributie:\n\n\n\nNou, al deze waarden geven zeer gelijkaardige resultaten. Dus we zullen de mediaan kiezen, omdat deze waarde een directe betekenis heeft vanuit een probabilistisch perspectief: er is 50% kans dat het werkelijke effect hoger is en 50% kans dat het effect lager is (omdat het de verdeling in twee gelijke delen verdeelt).\nOnzekerheid\nNu we een puntschatting hebben, moeten we de onzekerheid beschrijven. We zouden het bereik kunnen berekenen:\n\n[1] 0.3420445 0.4783965\n\nMaar heeft het zin om al deze extreme waarden op te nemen? Waarschijnlijk niet. Dus, we zullen een credible interval berekenen. Lang verhaal kort, het lijkt een beetje op een frequentistische confidence interval, maar is makkelijker te interpreteren en gemakkelijker te berekenen - en het is logischer.\nWe zullen dit credible interval berekenen op basis van het Highest Density Interval (HDI). Het geeft ons het bereik dat de 89% meest waarschijnlijke effectwaarden bevat. We zullen 89% CIs gebruiken in plaats van 95% CIs (zoals in het frequentistische kader), omdat het 89%-niveau stabielere resultaten geeft (Kruschke, 2014) en ons herinnert aan de willekeur van dergelijke conventies (McElreath, 2020).\n\n# Highest Density Interval\n\n89% HDI     \n------------\n[0.38, 0.44]\n\nMooi, dus we kunnen concluderen dat het effect 89% kans heeft om binnen het [0,38, 0,44] bereik te vallen. We hebben zojuist de twee belangrijkste stukken informatie berekend om onze effecten te beschrijven.\nEffect significantie\nOp veel wetenschappelijke gebieden is het echter niet voldoende om alleen de effecten te beschrijven. Wetenschappers willen ook weten of dit effect betekenis heeft in praktische of statistische termen. Of, om het met andere woorden te zeggen, of het effect belangrijk is. Wijkt het effect af van 0? Dus hoe berekenen we de significantie van een effect. Hoe kunnen we dit doen?\nWel, in dit specifieke geval is het zeer welsprekend: Alle mogelijke effectwaarden (d.w.z. de hele posterior distributie) zijn positief en meer dan 0,35, wat al een substantieel bewijs is dat het effect niet nul is.\nMaar toch willen we een objectief beslissingscriterium, om te zeggen of het effect ja of nee ‘significant’ is. Een benadering, vergelijkbaar met het frequentistisch kader, zou zijn om te kijken of het Credible Interval een 0 bevat. Als dat niet het geval is, zou dat betekenen dat ons effect ‘significant’ is.\nMaar deze index is toch niet erg fijnmazig? Kunnen we het beter doen? Ja.\nEen lineair model met een categorische voorspeller\nStel je voor dat je geïnteresseerd bent in hoe het gewicht van de kippen varieert, afhankelijk van twee verschillende voedersoorten. Voor dit examen zullen we beginnen met het selecteren van twee voor ons interessante voersoorten uit de chickwts-dataset (zit ook in basis R) (we hebben wel bijzondere interesses): vleesmaaltijden (‘meat meals’) en zonnebloemen (‘sunflowers’).\nData voorbereiden en model draaien\n\n\n\nLaten we nog een Bayesiaanse regressie uitvoeren om het gewicht te voorspellen met de twee voertypesoorten.\n\n\n\nPosterior beschrijving\n\n\n\nDit representeert de posterior distributie van het verschil tussen ‘meatmeal’ en ‘sunflowers’. Het lijkt erop dat het verschil eerder positief is (de waarden lijken geconcentreerd aan de rechterkant van 0)… Het eten van zonnebloemen maakt je dikker (tenminste, als je een kip bent). Maar, door hoeveel?  Laten we de mediaan en de CI berekenen:\n\n[1] 51.56878\n\n\n# Highest Density Interval\n\n89% HDI       \n--------------\n[11.09, 90.35]\n\nHet maakt je met ongeveer 51 gram (de mediaan) dikker. De onzekerheid is echter vrij groot: er is 89% kans dat het verschil tussen de twee voersoorten tussen 14 en 91 ligt.\n\nVerschilt dit effect van 0?\n\nROPE Percentage\nTesten of deze verdeling anders is dan 0 heeft geen zin, omdat 0 een enkele waarde is (en de kans dat een verdeling anders is dan een enkele waarde is oneindig).\nEen manier om significantie te beoordelen kan echter zijn om een gebied rond 0 te definiëren, wat als praktisch equivalent van nul zal worden beschouwd (d.w.z. afwezigheid van, of verwaarloosbaar, effect). Dit wordt de ‘Region of Practical Equivalence’ (ROPE) genoemd en is een manier om de betekenis van de parameters te testen.\nHoe definiëren we dit gebied?\n\nTringgg Tringgg\n\n– U spreekt met het easystatsteam. Hoe kunnen we u helpen?\n– Ja met Prof. Sanders. Ik ben kippenexpert. Ik bel u vanwegen mijn expertkennis. Een effect tussen -20 en 20 is verwaarloosbaar. Tot ziens.\nNou, dat komt goed uit. Nu weten we dat we de ROPE kunnen definiëren als het [-20, 20] bereik. Alle effecten binnen dit bereik worden als nihil (te verwaarlozen) beschouwd. We kunnen nu het aandeel van de 89% meest waarschijnlijke waarden (de 89% CI) berekenen die niet nul zijn, d.w.z., die buiten dit bereik liggen.\n\n# Proportion of samples inside the ROPE [-20.00, 20.00]:\n\ninside ROPE\n-----------\n4.80 %     \n\n5% van de 89% CI kan als nihil worden beschouwd. Is dat veel? Gebaseerd op onze richtlijnen, ja, het is te veel. Op basis van deze specifieke definitie van ROPE concluderen we dat dit effect niet significant is (de kans dat het verwaarloosbaar is, is te groot).\nHoewel, om eerlijk te zijn, heb ik een aantal twijfels over deze Prof. Sanders. Ik vertrouw zijn definitie van ROPE** niet echt. Is er een meer objectieve manier om het te definiëren?\nJa. Een betrouwbare manier is bijvoorbeeld het gebruik van een tiende (1/10 = 0,1) van de standaardafwijking (SD) van de responsvariabele, die als een “verwaarloosbare” effectomvang kan worden beschouwd (Cohen, 1988).\n\n[1] -6.17469  6.17469\n\nLaten we onze ROPE opnieuw definiëren als de regio binnen het [-6.2, 6.2] bereik. Merk op dat dit direct kan worden verkregen met de rope_range functie :)\n\n[1] -6.17469  6.17469\n\nLaten we nu het percentage in ROPE opnieuw berekenen:\n\n# Proportion of samples inside the ROPE [-6.17, 6.17]:\n\ninside ROPE\n-----------\n0.00 %     \n\nMet deze redelijke definitie van ROPE stellen we vast dat de 89% van de posterior distributie van het effect niet overlapt met de ROPE. We kunnen dus concluderen dat het effect significant is (in de zin van belangrijk genoeg om op te merken).\nWaarschijnlijkheid van Richting (Probability of Direction (pd))\nMisschien zijn we niet geïnteresseerd in de vraag of het effect niet te verwaarlozen is. Misschien willen we alleen weten of dit effect positief of negatief is. In dit geval kunnen we eenvoudigweg berekenen welk deel van de posterior distributie positief is, ongeacht de “grootte” van het effect.\n\n[1] 98.05\n\nWe kunnen concluderen dat het effect positief is met een waarschijnlijkheid van 98%. We noemen deze index de Waarschijnlijkheid van Richting (pd). Het kan in feite gemakkelijker worden berekend met het volgende:\n\npd = 98.05%\n\nInteressant is dat deze index meestal sterk gecorreleerd is met de meest frequente p-waarde. We kunnen de overeenkomstige p-waarde bijna ruwweg afleiden met een eenvoudige transformatie:\nInterestingly, it so happens that this index is usually highly correlated with the frequentist p-value. We could almost roughly infer the corresponding p-value with a simple transformation:\n\n[1] 0.0436\n\nAls we ons model in het frequentistisch kader hebben uitgevoerd, zouden we ongeveer een effect moeten waarnemen met een p-waarde van 0.04. Is dat waar?\nVergelijking met frequentisten\n\n\nCall:\nlm(formula = weight ~ feed, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-123.909  -25.913   -6.917   32.091  103.091 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     276.91      17.20  16.097 2.74e-13 ***\nfeedsunflower    52.01      23.82   2.184   0.0405 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 57.05 on 21 degrees of freedom\nMultiple R-squared:  0.1851,    Adjusted R-squared:  0.1463 \nF-statistic: 4.769 on 1 and 21 DF,  p-value: 0.04047\n\nHet frequentistische model vertelt ons dat het verschil positief en significant (beta = 52, p = 0.04) is.\nAlhoewel we tot een gelijkaardige conclusie kwamen, liet het Bayesiaanse kader ons toe om een meer diepgaand en intuïtief begrip te ontwikkelen van ons effect en van de onzekerheid van de inschatting ervan.\nAlles met één functie\nEn toch, ik ben het ermee eens, het was een beetje omslachtig om alle indices eruit te halen en te berekenen. Maar wat als ik je vertel dat we dit allemaal kunnen doen, en meer, met slechts één functie?\n\nZie, beschrijf_posterior!\n\nDeze functie berekent alle genoemde indexen, en kan direct op het model worden uitgevoerd:\n\n# Description of Posterior Distributions\n\nParameter     |  Median |             89% CI |      pd |        89% ROPE | % in ROPE |        BF |  Rhat |      ESS\n-------------------------------------------------------------------------------------------------------------------\n(Intercept)   | 277.410 | [249.059, 305.796] | 100.00% | [-6.175, 6.175] |         0 | 5.121e+11 | 1.000 | 3071.333\nfeedsunflower |  51.569 | [ 11.086,  90.349] |  98.05% | [-6.175, 6.175] |         0 |     0.764 | 1.000 | 3260.635\n\nTada! Daar hebben we het! De mediaan, de CI, de pd en het ROPE percentage!\nHet begrijpen en beschrijven van posterior distributies is slechts één aspect van Bayesiaanse modellering… Ben je klaar voor meer? \nBevestiging van Bayesiaanse vaardigheden\nNu het beschrijven en begrijpen van posterior distributies van lineaire regressies voor jou geen geheimen meer heeft, zullen we een stap terug doen en wat eenvoudigere modellen bestuderen: correlaties en t-testen.\nMaar laten we eerst even stilstaan bij het feit dat alle statistische basisprocedures zoals correlaties, t-testen, ANOVA’s of Chisquare-testen ** lineaire regressies** zijn (we raden deze uitstekende demonstratie ten zeerste aan). Op basis van deze eenvoudige modellen introduceren we een complexere index, zoals de Bayes-factor.\nCorrelaties\nFrequentistische versie\nLaten we opnieuw beginnen met een frequentistische correlatie tussen twee continue variabelen, de breedte en de lengte van de kelkbladen van sommige bloemen (‘sepals’). De gegevens zijn beschikbaar in R als de iris dataset (dezelfde die we hierboven hebben gebruikt).\nWe zullen een Pearson’s correlatietest berekenen, de resultaten opslaan in een object met de naam resultaat en vervolgens deze resultaten weergeven:\n\n\n    Pearson's product-moment correlation\n\ndata:  iris$Sepal.Width and iris$Sepal.Length\nt = -1.4403, df = 148, p-value = 0.1519\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.27269325  0.04351158\nsample estimates:\n       cor \n-0.1175698 \n\nZoals je in de output kunt zien, heeft de test die we hebben gedaan eigenlijk twee hypothesen vergeleken: de nul-hypothese (h0; geen correlatie) met de alternatieve hypothese (h1; een niet-nul-correlatie). Op basis van de p-waarde kan de nulhypothese niet worden verworpen: de correlatie tussen de twee variabelen is negatief maar niet significant (r = -.12, p > .05).\nBayesiaanse correlatie\nOm een Bayesiaanse correlatietest te berekenen, hebben we het BayesFactor-pakket nodig (u kunt het installeren door install.packages (“BayesFactor”) uit te voeren). We kunnen dan dit pakket laden, de correlatie berekenen met behulp van de correlatieBF() functie en de resultaten op een vergelijkbare manier opslaan.\n\n\n\nLaten we nu eens onze describe_posterior()-functie hierop los:\n\n  Parameter     Median CI     CI_low    CI_high    pd ROPE_CI\n1       rho -0.1102375 89 -0.2294536 0.02167853 0.922      89\n  ROPE_low ROPE_high ROPE_Percentage        BF Prior_Distribution\n1     -0.1       0.1       0.4509969 0.5090175             cauchy\n  Prior_Location Prior_Scale\n1              0   0.3333333\n\nWe zien hier weer veel dingen, maar de belangrijke indices voor nu zijn de mediaan van de posterior distributie, -.11. Dit komt (weer) dicht in de buurt van de frequentistische correlatie. We zouden, zoals eerder, het credible interval, de pd of het ROPE-percentage kunnen beschrijven, maar we zullen ons hier richten op een andere index die door het Bayesiaanse kader wordt geboden, de Bayes-factor (BF).\nBayes-factor (BF)\nWe zeiden eerder dat een correlatietest eigenlijk twee hypothesen vergelijkt, een nul (afwezigheid van effect) met een alarmerende (aanwezigheid van een effect). De Bayes-factor (BF) laat dezelfde vergelijking toe en bepaalt onder welke van twee modellen de geobserveerde gegevens waarschijnlijker zijn: een model met het effect waarin we geinteresseerd zijn, en een nulmodel zonder het effect daarvan. We kunnen de bayes-factor() gebruiken om de Bayes-factor specifiek te berekenen bij het vergelijken van die modellen:\n\n# Bayes Factors for Model Comparison\n\n  Model             BF\n  [2] (rho != 0) 0.509\n\n* Against Denominator: [1] (rho = 0)\n*   Bayes Factor Type: JZS (BayesFactor)\n\nWe hebben een BF van 0,51. Wat betekent dat?\nBayes-factoren zijn continue metingen van het relatieve bewijs, waarbij een Bayes-factor groter dan 1 bewijs geeft ten gunste van één van de modellen (vaak de teller genoemd), en een Bayes-factor kleiner dan 1 die bewijs geeft ten gunste van het andere model (de noemer).\n\nJa, je hebt het goed gehoord, bewijs ten gunste van de nul!\n\nDat is een van de redenen waarom het Bayesiaanse kader soms als superieur wordt beschouwd aan het frequentistische kader. Onthoud uit je statistiekenlessen, dat de p waarde alleen gebruikt kan worden om h0 af te wijzen, maar niet om het te accepteren. Met de Bayes-factor kunt je -evidentie meten tegen - en ook ten gunste van - de nul.\nBF’s die het bewijs voor het alternatief tegen de null vertegenwoordigen kunnen worden teruggedraaid met 𝐵𝐹01=1/𝐵𝐹10 (de 01 en 10 komen respectievelijk overeen met h0 tegen h1 en h1 tegen h0) om het bewijs voor de null weer te geven. Dit verbetert de leesbaarheid in gevallen waarin het BF van het alternatief tegen de nul kleiner is dan 1 (d.w.z. ter ondersteuning van de nul).\nIn ons geval, BF = 1/0,51 = 2, geeft aan dat de gegevens 2 keer meer waarschijnlijk zijn onder de null in vergelijking met de alternatieve hypothese. Die weliswaar de voorkeur geeft aan de nul-hypothese, maar slechts als anekdotisch bewijs moet wordt beschouwd.\nWe kunnen dus concluderen dat er anecdotisch bewijs is ten gunste van de hypothese ‘gebrek aan correlatie tussen de twee variabelen’ (mediaan = 0,11, BF = 0,51), wat veel meer informatie geeft dan wat we kunnen doen met de frequentistische statistiek.\nEn dat is nog niet alles!\nVisualiseren van de Bayes-factor\nIn het algemeen zijn taartgrafieken een absolute ‘no-go’ in datavisualisatie, omdat het waarnemingssysteem van onze hersenen de gepresenteerde informatie op deze manier sterk vervormt. Toch is er één uitzondering: pizzagrafieken.\nHet is een intuïtieve manier om de bewijskracht van BFs te interpreteren als een soort verrassing\nDergelijke “pizzapercelen” kunnen direct worden aangemaakt via het zie visualisatiepakket voor easystats (u kunt het installeren door het uitvoeren van\nDergelijke ‘pizzagrafieken’ kunnen direct worden aangemaakt met het visualisatiepakket voor easystats (u kunt het installeren door install.packages(\"see\")) uit te voeren):\n\n\n\nDus, na het zien van deze pizza, ben je dan nog verrast door de uitkomst?\nt-testen\n\n“Ik weet dat ik niets weet, en vooral niet als versicolor en virginica verschillen in termen van Sepal.Width”, zei de beroemde Socrates.\n\nTijd om eindelijk een antwoord te geven op deze cruciale vraag!\nVersicolor vs. virginica\nBayesiaanse t-testen kunnen worden uitgevoerd op een zeer vergelijkbare manier als correlaties. We zijn met name geïnteresseerd in twee niveaus van de Specie factor, versicolor en virginica. We zullen beginnen met het uit iris uitfilteren van de niet-relevante waarnemingen die overeenkomen met de setosa specie, en we zullen dan de waarnemingen en de distributie van de Sepal.Width variabele visualiseren.\n\n\n\nBereken de Bayesiaanse t-test\nHet lijkt er (visueel) op dat virgnica bloemen gemiddeld een iets grotere kelkbladbreedte hebben. Laten we dit verschil statistisch beoordelen met behulp van de ttestBF in het BayesFactor pakket.\n\n   Parameter    Median CI    CI_low   CI_high    pd ROPE_CI\n1 Difference 0.1871487 89 0.0946914 0.2936964 0.998      89\n    ROPE_low ROPE_high ROPE_Percentage       BF Prior_Distribution\n1 -0.0332751 0.0332751               0 17.71872             cauchy\n  Prior_Location Prior_Scale\n1              0   0.7071068\n\nOp basis van de indexen kunnen we zeggen dat het verschil tussen virginica en versicolor (van Sepal.Width) een kans heeft van 100% om negatief te zijn [van de pd en het teken van de mediaan] (mediaan = -0,19, 89% CI [-0,29, -0,092]). De gegevens leveren een sterk bewijs tegen de nulhypothese (BF = 18).\nHoud dat in gedachten, want we zullen een andere manier zien om deze vraag te onderzoeken.\nLogistisch Model\nEen hypothese waarvoor men een t-test gebruikt, kan ook getest worden met een binomiaal model (bv. een logistisch model). Het is inderdaad mogelijk om de volgende hypothese te herformuleren, “er is een belangrijk verschil in deze variabele tussen de twee groepen” door “deze variabele in staat te stellen om te discrimineren tussen (of te classificeren in) de twee groepen”. Deze modellen zijn echter veel krachtiger dan een gewone t-test.\nIn het geval van het verschil van Sepal.Width tussen virginica en versicolor wordt de vraag, hoe goed kunnen we de twee soorten classificeren met alleen Sepal.Width.\nHet model fitten\n\n\n\nPrestatie en parameters\nEerst prestatie van het model in kaart brengen.\n\nCan't calculate log-loss.\n# Indices of model performance\n\nELPD   | ELPD_SE |  LOOIC | LOOIC_SE |   WAIC |   R2 | RMSE | Sigma | Score_log | Score_spherical\n-------------------------------------------------------------------------------------------------\n-66.25 |    3.04 | 132.51 |     6.08 | 132.50 | 0.10 | 1.11 |  1.00 |   -105.55 |            0.01\n\nVervolgens de resultaten van enkele indices presenteren.\n\n# Description of Posterior Distributions\n\nParameter   | Median |           89% CI |      pd |        89% ROPE | % in ROPE |     BF |  Rhat |      ESS\n-----------------------------------------------------------------------------------------------------------\n(Intercept) | -6.081 | [-9.268, -2.676] | 100.00% | [-0.181, 0.181] |         0 | 12.135 | 1.000 | 2931.465\nSepal.Width |  2.118 | [ 0.916,  3.198] | 100.00% | [-0.181, 0.181] |         0 | 17.399 | 1.001 | 2912.719\n\nReferenties\nAndrews, M., & Baguley, T. (2013). Prior approval: The growth of bayesian methods in psychology. British Journal of Mathematical and Statistical Psychology, 66(1), 1–7.\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., … others. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6.\nChambers, C. D., Feredoes, E., Muthukumaraswamy, S. D., & Etchells, P. (2014). Instead of ’playing the game’ it is time to change the rules: Registered reports at aims neuroscience and beyond. AIMS Neuroscience, 1(1), 4–17.\nEtz, A., & Vandekerckhove, J. (2016). A bayesian perspective on the reproducibility project: Psychology. PloS One, 11(2), e0149794.\nKruschke, J. K. (2010). What to believe: Bayesian methods for data analysis. Trends in Cognitive Sciences, 14(7), 293–300.\nKruschke, J. K., Aguinis, H., & Joo, H. (2012). The time has come: Bayesian methods for data analysis in the organizational sciences. Organizational Research Methods, 15(4), 722–752.\nSzucs, D., & Ioannidis, J. P. (2016). Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology literature. BioRxiv, 071530.\nWagenmakers, E.-J., Marsman, M., Jamil, T., Ly, A., Verhagen, J., Love, J., … others. (2018). Bayesian inference for psychology. Part i: Theoretical advantages and practical ramifications. Psychonomic Bulletin & Review, 25(1), 35–57.\n\n\n\n",
    "preview": "posts/2020-11-17-testen-met-bayes/testen-met-bayes_files/figure-html5/unnamed-chunk-7-1.png",
    "last_modified": "2021-02-14T12:26:03+01:00",
    "input_file": "testen-met-bayes.utf8.md"
  },
  {
    "path": "posts/2020-11-01-nogmaals-grafieken/",
    "title": "Het Goede, het Slechte en het Lelijke: Data effectief visualiseren en communiceren",
    "description": "Shirin Elsinghorst schreef deze blog onlangs op [Codecentric](https://blog.codecentric.de/2020/10/goodbadugly/). Omdat ze op mijn werk de vormgeving van de uitgaven hebben aangepast, wilde ik het maken van figuren aan de nieuwe kleursetting van mijn werk aanpassen. Shirin's blog was een mooie oefenplaats voor mij. Tegelijk is het een mooie introductie op datavisualisatie en daarom de moeite waard het in het Nederlands te bewerken.    [Hier](https://docs.google.com/presentation/d/e/2PACX-1vR4pD2EmW9Gzxr1Q3qwgjEYkU64o2-ThlX1mXqfNQ2EKteVUVt6Qg2ImEKKi9XLv-Iutb3lD8esLyU7/pub?start=false&loop=false&delayms=3000&slide=id.g58b36409ef_0_0) vind je de presentatie die zij zelf hierover op 20 oktober 2020 in Duitsland gaf.",
    "author": [
      {
        "name": "Shirin Elsinghorst, vertaling Harrie Jonkman",
        "url": "https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/"
      }
    ],
    "date": "2020-11-01",
    "categories": [],
    "contents": "\nEnkele handelingen vooraf\nEerst maar eens de pakketten laden die gebruikt worden:\n\n\n\nVervolgens de kleuren instellen.\nDe dataset\n\n# A tibble: 6 x 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm\n  <fct>   <fct>              <dbl>         <dbl>             <int>\n1 Adelie  Torgersen           39.1          18.7               181\n2 Adelie  Torgersen           39.5          17.4               186\n3 Adelie  Torgersen           40.3          18                 195\n4 Adelie  Torgersen           NA            NA                  NA\n5 Adelie  Torgersen           36.7          19.3               193\n6 Adelie  Torgersen           39.3          20.6               190\n# … with 3 more variables: body_mass_g <int>, sex <fct>, year <int>\n\n\n\n[1] 0.3926991 1.1780972 1.9634954 2.7488936 3.5342917 4.3196899\n[7] 5.1050881 5.8904862\n\n\n\n\n\n\n\n\n\n\n0. Datavisualisatie, cruciaal voor begrip en communicatie\nDatavisualisatie is een cruciaal onderdeel van elke analyse. Of het nu “voor jezelf” is om verbanden en resultaten beter te begrijpen of om resultaten te presenteren en te “verkopen” aan anderen. Omdat goede grafieken de gegevens intuïtief toegankelijk maken, vertellen ze een verhaal en laten ze duidelijk patronen, trends of uitschieters zien. Daarom is Explorative Data Analyse (EDA) meestal de eerste stap van elke gegevensanalyse en -modellering. Alleen als we onze gegevens begrijpen, kunnen we de juiste voorbewerkingsstappen en analysemethoden, statistieken of ’deep learning’technieken toepassen. En aangezien mensen veel beter zijn in het visueel begrijpen van getallen in een grafiek dan in tabellen, moeten we de kracht van datavisualisatie gebruiken! Vooral bij het maken van visualisaties voor rapporten of publicaties is het cruciaal dat deze zowel feitelijk correct als visueel aantrekkelijk zijn.\n\nDatavisualisatie is deels kunst en deels wetenschap. De uitdaging is om de kunst goed te krijgen zonder dat de wetenschap het bij het verkeerde eind heeft en vice versa. (Wilke 2019)\n\nHet doel van een goede illustratie is dat het in één oogopslag begrijpelijk is en een duidelijke uitspraak doet. Slechte grafieken variëren van eenvoudigweg lelijk tot (opzettelijk?) misleidend of zelfs verkeerd. In dit artikel leg ik uit wat goede grafieken zijn (en wat niet) en hoe we ze kunnen maken met behulp van de Grammatica van Grafieken. En ik introduceer enkele van de meest gebruikte soorten grafieken, samen met negatieve voorbeelden “uit de vrije natuur”.\nWat maakt een goede grafiek?\n1. Data\nHet belangrijkste aspect en de basis van elke grafiek zijn de gebruikte gegevens! Ze moeten correct zijn en we moeten altijd controleren op mogelijke (meet)fouten. Zoals bijvoorbeeld in deze afbeelding:\n\nHet is duidelijk dat er een fout in de voorspelling zit, want temperaturen van -100°C, zelfs op een hele speciale dag, zijn echt heel onwaarschijnlijk! En niet alleen toont deze grafiek duidelijk verkeerde gegevens; deze uitschietwaarde comprimeert de rest van de gegevens in de grafiek zodanig dat de curven niet meer duidelijk zichtbaar zijn en de waarden van verschillende dagen moeilijk te vergelijken zijn.\nTot goede praktijk van datavisualisatie behoort tevens het specificeren van de gegevensbron.\n2. Overzichtelijkheid & kleuren\nEen goede grafiek is juist zo complex omdat ze haar boodschap in één oogopslag moet overbrengen; ze moet duidelijk zijn en geen “chart junk” bevatten. Edward Tufte beschouwde alle visuele elementen in een grafiek die ofwel niet nodig zijn om de grafiek te begrijpen, ofwel zelfs afleiden van de centrale informatie als grafiektroep (Tufte 1983). Drie voorbeelden daarvan zijn in deze figuur te zien:\n\nIedereen die regelmatig kranten leest zal merken dat “chart junk” extreem vaak voorkomt en vooral populair is bij populaire media om een chart te kruiden. In veel gevallen kan een onschuldige chartjunk worden afgedaan als “artistieke vrijheid”, maar hoe ernstiger jouw grafiek wilt maken, hoe meer je die moet vermijden.\nDuidelijkheid omvat ook de keuze van geschikte kleuren en duidelijke contrasten. Te veel, felle of grillige kleuren maken een plot visueel weerzinwekkend en zorgen ervoor dat het er overbeladen en verwarrend uitziet. Daarnaast moet je er bij de keuze van de kleuren ook op letten dat het voor kleurenblinden mogelijk is om de grafiek te lezen. Dit moet worden gedaan met behulp van een geschikt kleurenpalet, evenals redundante functies zoals verschillende vormen, patronen of lijntypes die het mogelijk maken om de grafiek te lezen, zelfs zonder kleurinformatie.\nKleuren\n3. etikettering & assen\nEen goede grafiek is in één oogopslag te begrijpen, wat betekent dat ze voor zichzelf spreken. Essentieel hiervoor is de juiste etikettering met titel, aslabels (met eenheden!), legenda’s en bijschriften! Ook het aantal assentikken moet op de juiste manier worden gekozen. En vooral: de afstanden tussen de assen moeten voor de numerieke waarden regelmatig zijn, d.w.z. dat de afstand tussen de teken in geen geval mag variëren, zoals te zien is op de y-as in deze vreselijke illustratie:\n\nDe grammatica van de grafiek\nWe kennen nu de belangrijkste aspecten van goede grafieken. Maar wat is de beste manier om goede grafieken te maken? Er zijn vele manieren om grafieken te genereren: met de hand tekenen, met Excel of met verschillende programmeertalen zoals R, Python, Java, enz. De beste manier, hoewel met een hogere instapdrempel, is het gebruik van programmeertalen. Dit is de eenvoudigste manier om ervoor te zorgen dat de gegevens schoon zijn en op een traceerbare manier kunnen worden verwerkt. Excel kan ook gebruikt worden om grafieken te maken, maar het programma heeft een paar valkuilen: Excel-format kan makkelijk leiden tot fouten in de gegevens. En het maakt het erg moeilijk om grafieken te reproduceren, omdat het niet documenteert welke stappen handmatig werden uitgevoerd en in welke volgorde.\nR en Python zijn bijzonder geschikt omdat ze de meest gebruikte programmeertalen zijn voor het genereren van grafieken en omdat ze pakketten aanbieden die het analyseren van gegevens en het maken van grafieken zeer efficiënt maken. Hier presenteer ik de (naar mijn mening) beste manier om op een gestructureerde manier grafieken te genereren: met de pakketten ggplot2 voor R of plotnine voor Python (gebaseerd op ggplot2).\nMet ggplot2 heeft Hadley Wickham een implementatie gemaakt van de 1999 Grammatica van Graphics voor de door Leland Wilkinson beschreven R-programmeertaal, die ik hieronder introduceer met codevoorbeelden (Wilkinson et al. 1999; Wickham 2010). Deze Grammatica van Graphics beschrijft een raamwerk voor het gestructureerd maken van grafieken die bestaan uit lagen die op elkaar voortbouwen (Wickham en Grolemund 2017). Hieronder laat ik een paar voorbeelden zien. Een overzicht van alle mogelijke opties is te vinden in het ggplot2-cheatsheet.\n1. Data\nOok voor de Grammatica van Graphics zijn data het belangrijkste en meest fundamentele element. Hier gebruik ik een voorbeelddataset met verschillende groottes van drie pinguïnsoorten (Gorman, 2014). De centrale functie van het ggplot2-pakket wordt ggplot() genoemd en neemt een dataset als invoer. Deze functie creëert eerst een leeg coördinatensysteem waarop we met de volgende lagen kunnen bouwen en zo onze grafiek stap voor stap kunnen creëren, aanpassen en uitbreiden.\n2. Esthetiek\nHet tweede argument dat we definiëren in de ggplot() functie is de esthetiek (aes()). Esthetiek beschrijft grafische elementen zoals X- en Y-waarden, grootte, kleuren, vormen, enz. Voor een eenvoudige scatterplot moeten we ten minste de X- en Y-posities specificeren. Hiervoor moeten we eerst beslissen welke gegevens (variabelen) we in kaart willen brengen. Bijvoorbeeld hier de snavellengte van de pinguïn op de X-as tegen de vinlengte op de Y-as:\n\n\n\nZelfs met een bepaalde esthetiek krijgen we nog steeds geen echte grafiek te zien, maar we hebben de volgende laag nodig, de zogenaamde geometrie. Omdat esthetiek en geometrie zeer nauw met elkaar verbonden zijn en deels van elkaar afhankelijk zijn, laat ik hieronder extra esthetiek zien.\n3. Geometriek\nGeometrische objecten of geometrieën beschrijven hoe de gegevens die we in de esthetiek hebben gedefinieerd, moeten worden weergegeven. Dit kan bijvoorbeeld een puntgrafiek (geom_point()) of een lijngrafiek (geom_line()) zijn, die nu ook als grafiek in deze laag wordt weergegeven:\n\n\n\nEen lijngrafiek is echter niet nuttig voor de gegevens hier; meer hierover in de sectie Grafiektypen - Lijngrafieken. Andere geometrieën zijn staafdiagrammen (geom_bar()) of boxplots (geom_boxplot()). Geometrie en esthetiek zijn onderling afhankelijk in die zin dat het gegevenstype van de esthetische variabelen alleen bepaalde geometrieën toelaat of zinvol is. Zo zijn strooi- en lijndiagrammen geschikt voor doorlopende X- en Y-assen (rationele getallen, tijden of datum). Voor staafdiagrammen moeten de X-as gegevens categorisch zijn. Voordat ik in de loop van latere lagen meer in detail zal ingaan op geometrieën en esthetiek, zal ik eerst facetten introduceren.\n4. Facetten\nFacetten betekent het splitsen van een grafiek in verschillende subplots. In onze voorbeelddataset worden de meetwaarden van drie verschillende pinguïnsoorten verzameld. Het bovenstaande strooiplot laat echter niet toe om een onderscheid te maken tussen de drie soorten, wat natuurlijk een belangrijke bijkomende informatie is in de gegevens. Daarom moeten we dit in onze grafiek weergeven. Een manier om dit te doen is door gebruik te maken van facetten:\n\n\n\nNu zien we de punten voor elke soort pinguïn in een aparte subplot. Facetten kunnen worden gecreëerd voor één of meer categorische variabelen, maar meer dan twee facetten zullen in het algemeen verwarrend zijn. Standaard gebruikt ggplot2 dezelfde X- en Y-asafmetingen om de subplots vergelijkbaar te maken. Met facetten is het in dit geval echter niet zo eenvoudig om de drie typen te vergelijken. Als alternatief kunnen we de drie pinguïnsoorten zichtbaar maken met behulp van verschillende kleuren. Deze mogelijkheid valt onder schaalvergroting.\n5. Schaalvergroting\nMet schaalvergroting kunnen we naast de twee X- en Y-dimensies nog extra dimensies tonen, vergelijkbaar met wat we al gedaan hebben voor de pinguïnsoorten met facetten. Zo kunnen we bijvoorbeeld een kleurenschaal kiezen. In ggplot2 worden schalen gegeven door extra variabelen in de esthetiek:\n\n\n\nDe bijbehorende legende wordt automatisch aangemaakt. Andere schalen zijn maatschalen, punt- of lijntypes. Niet alle schalen zijn geschikt voor elk datatype. Terwijl kleuren ook continue getallen kunnen vertegenwoordigen, zijn punt- en lijntypes slechts voor een beperkt aantal categorieën beschikbaar.\n\n\n\nIn principe kan elk aantal dimensies van de gegevens in een grafiek worden weergegeven, ook al kunnen meer dan vier dimensies de grafiek meestal te chaotisch en verwarrend maken.\nEen ander type schaling is de asschaalverdeling. Zo kunnen we bijvoorbeeld de assen omdraaien zodat de waarden niet van links/naar beneden = laag naar rechts/boven = hoog worden weergegeven, maar de hoge waarden wel links/naar beneden worden weergegeven:\n\n\n\n6. Statistische Transformaties\nStats, afkorting voor statistische transformaties, worden gebruikt om statistische waarden of berekeningen toe te voegen aan een plot of om deze te definiëren. Dit kunnen bijvoorbeeld gemiddelde waarden zijn, mediaan, betrouwbaarheidsintervallen, standaardafwijkingen, enz.\nIn deze figuur is een staafdiagram weergegeven met een numerieke waarde:\n\n\n\nOmdat de standaardstatistiek voor staafdiagrammen in ggplot2 „Aantal (count)“ ist, kunnen deze verhoudingen mit de stat „identity“ worden veranderd.\nEen van de meest gebruikte statistieken zijn ‘Smoothed Conditional Means’, om bijvoorbeeld de samenhang van de X- en Y-Variabelen met gladde lijnen en bijbehorende foutmarges aan te tonen:\n\n\n\n7. Coördinatensystemen\nDe laatste laag in de Grammatica van Graphics zijn coördinatensystemen. Coördinatensystemen bepalen hoe de assen van onze grafiek moeten worden gerangschikt. Meestal is de X-as horizontaal en de Y-as verticaal (cartesiaans coördinatenstelsel); maar er zijn ook gevallen waarin we radiale of gebogen assen hebben, bijvoorbeeld in een taartdiagram of kaartweergave. Een taartdiagram is dus niets meer dan een staafdiagram waarin we het coördinatensysteem hebben veranderd:\n\n\n\nDiagramtypen Met deze Grammatica van Graphics kunnen nu alle gangbare diagramtypen eenvoudig en flexibel worden gegenereerd en uitgebreid. De meest gebruikte diagramtypen zijn:\nPuntdiagrammen\n\n\n\nPuntdiagrammen worden vaak gebruikt wanneer we numerieke X-waarden tegen numerieke Y-waarden willen weergeven en dus hun correlatie willen laten zien. Plots kunnen verschillende kleuren, vormen en maten hebben. Meestal zijn puntdiagrammen gemakkelijk te begrijpen, maar ze kunnen ook verwarrend worden als er te veel overlappende punten zijn.\nLijndiagrammen\n\n\n\nLijndiagrammen zijn meestal vergelijkbaar met puntdiagramma, met dat verschil dat de (denkbeeldige) punten met elkaar verbonden zijn door lijnen. Deze verbonden lijnen vertegenwoordigen de denkbeeldige tussenliggende waarden tussen twee meetpunten; punten moeten dus alleen verbonden worden als deze veronderstelling wordt gemaakt! Om deze reden is een lijngrafiek niet bruikbaar voor het bovenstaande voorbeeld, omdat we onafhankelijke metingen van individuele personen laten zien. Lijndiagrammen zijn vooral nuttig voor tijdreeksen.\nStaafdiagrammen\n\n\n\nStaafdiagrammen tonen ofwel het aantal gebeurtenissen of ze tonen een numerieke waarde Y ter vergelijking tussen verschillende categorieën. Vooral bij staafdiagrammen vinden we veel negatieve voorbeelden met misleidende voorstellingen (waarschijnlijk omdat ze zo gemakkelijk te maken zijn met de eenvoudigste tekenprogramma’s zonder enige gegevensbasis). Hier zijn twee zeer opvallende negatieve voorbeelden van de coronavirus situatie: in beide voorbeelden komen de staafhoogtes niet overeen met de waarden op de (niet getoonde) Y-as!\n\n\nEen verzameling van andere veelgebruikte diagramtypen met illustraties en negatieve voorbeelden is te vinden in de dia’s bij deze lezing.\nReferenties\nGorman, Tony D. AND Fraser, Kristen B. AND Williams. 2014. “Ecological Sexual Dimorphism and Environmental Variability Within a Community of Antarctic Penguins (Genus Pygoscelis).” PLOS ONE 9 (3): 1–14. https://doi.org/10.1371/journal.pone.0090081.\nTufte, Edward R. 1983. The Visual Display of Quantitative Information. Graphics Press.\nWickham, Hadley. 2010. “A Layered Grammar of Graphics.” Journal of Computational and Graphical Statistics 19 (1): 3–28. https://doi.org/10.1198/jcgs.2009.07098. Wickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1st ed. O’Reilly Media, Inc. https://r4ds.had.co.nz/.\nWilke, C. O. 2019. Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures. O’Reilly Media. https://books.google.de/books?id=L3ajtgEACAAJ.\nWilkinson, L., D. Wills, J. Chambers, R. Dubbs, W. Eddy, A. Norton, and W. Haerdie. 1999. The Grammar of Graphics. Statistics and Computing. Springer New York. https://books.google.de/books?id=5boZAQAAIAAJ.\n\n\n\n",
    "preview": "posts/2020-11-01-nogmaals-grafieken/nogmaals-grafieken_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-07-11T15:28:56+02:00",
    "input_file": "nogmaals-grafieken.utf8.md"
  },
  {
    "path": "posts/2020-10-17-een-eenvoudige-introductie-op-machine-learning/",
    "title": "Een eenvoudige introductie op `tidymodels`",
    "description": "Edgar Ruiz' eenvoudige introductie op machine learning met de inzet van het pakket `tidymodels`.",
    "author": [
      {
        "name": "Edgar Ruiz, vertaling Harrie Jonkman",
        "url": "https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/"
      }
    ],
    "date": "2020-10-17",
    "categories": [],
    "contents": "\nIntroductie Harrie\nIk heb me voorgenomen om wat machine learning te leren. Het komt mij allemaal nog wat onbekend voor. Door soms tutorials van anderen over te zetten en te kijken wat er gebeurt, wil ik hierin verder komen. Edgar Ruiz schreef een korte inleiding en zijn tutorial heb ik, brutaal als ik ben, naar het Nederlands overgezet. Edgar Ruiz, ik hoop dat je dit goed vindt. Onderaan vermeld ik waar de lezer jouw oorspronkelijke tutorial kan vinden.\nEen rustige introductie op tidymodels\nThe WorkflowOnlangs had Edgar Ruiz de gelegenheid om tidymodels te laten zien in workshops en gesprekken. Omdat hij zichzelf meer ziet als gebruiker dan ontwikkelaar, zou het wel eens waardevol en interessant kunnen zijn, zo dacht hij, om te delen wat hij tot nu toe had geleerd. Laten we eerst eens bekijken wat tidymodels in onze analyseprojecten kan betekenen, dat was het doel van zijn korte en duidelijke introductie tidymodels.\nHet figuur hierboven is gebaseerd op een figuur uit R voor Data Science boek, het boek van Wickham en Grolemund en wordt heel vaak gebruikt. Alleen wordt hier het onderdeel modeleren met tidymodels uitgevoerd en dat is nieuw. In de introductie laat hij zien welke stappen hier gezet moeten worden. Modeleren kan baat hebben bij een ‘nette’ interface, dat is waar tidymodels een rol speelt.\nHet is belangrijk om te verduidelijken dat de groep van pakketten die deel uitmaken van tidymodels niet zelf statistische modellen implementeren. In plaats daarvan richten ze zich vooral op het makkelijker maken van alle taken die te maken hebben met modeleren. Deze taken omvatten het voorbewerken van gegevens tot en met het valideren van resultaten.\nIn zekere zin kent het modeleren enkele substappen. Voor deze substappen levert tidymodels één of meerdere pakketten. Dit artikel toont functies uit vier tidymodels pakketten, die alle vier in de suite tidymodels zijn opgesloten:\nrsample - Verschillende types van re-samples recipes - Transformaties om data voor te bewerken voor modeleren parnip - Een algemene interface voor modelcreatie yardstick - Meten hoe het model het doet\nHet volgend figuur illustrates elkw modelleerstapt, en laat de tidymodels pakketten zien die we in dit artikel zullen gebruiken:\nThe WorkflowIn een bepaalde analyse kan al dan niet het tidyverse pakket worden gebruikt. Niet alle projecten hoeven te werken met tijdsvariabelen, dus het is niet altijd nodig om functies uit het hms pakket te gebruiken. Hetzelfde idee geldt voor tidymodels. Afhankelijk van wat voor soort modelering er gedaan gaat worden, zullen alleen functies uit sommige van de pakketten gebruikt worden.\nEen voorbeeld\nWe zullen de iris dataset hiervoor gebruiken. De data zijn al binnen gehaald en voldoende opgeschoond om direct te modeleren.\nLaad alleen de tidymodels bibliotheek\nDit is mogelijk het eerste artikel dat hij heeft geschreven waarbij hij slechts één pakket heeft aangeroepen via de bibliotheek(). Naast het laden van de kernpakketten voor het modelleren, laadt tidymodels, ook handig, een aantal tidyverse pakketten, waaronder dplyr en ggplot2. Gedurende deze oefening zullen we enkele functies uit die pakketten gebruiken, maar we hoeven ze dus niet expliciet in onze R-sessie te laden.\n\n\n\nHet voorwerk\nDeze eerstestap richt zich op het geschikt maken van data voor modellering. Daarbij wordt gebruik gemaakt van datatransformaties. Alle transformaties kunnen worden uitgevoerd met dplyr, of andere tidyverse pakketten Overweeg het gebruik van tidymodels pakketten wanneer dit deel zwaarder en complexer is.\nData Sampling\nDe initial_split() functie is vooral gebouwd om de dataset op te splitsen in een trainings en test set. Standaard wordt 3/4 van de data voor training en de rest voor testen gebruikt. Dat kan aangepast worden door het prop functie te gebruiken. Dit genereert een rplit object, geen dataframe. De geprinte output laat het aantal rijen voor testen, trainen en het totaal zien.\n\n<Analysis/Assess/Total>\n<90/60/150>\n\nOm toegang te krijgen tot de observaties van de trainingsset, gebruik je de training() functie. Hetzelfde voor testset waar je toegang toe krijgt via testing().\n\nRows: 90\nColumns: 5\n$ Sepal.Length <dbl> 4.7, 5.4, 5.0, 4.4, 4.9, 4.8, 4.3, 5.8, 5.1, 5…\n$ Sepal.Width  <dbl> 3.2, 3.9, 3.4, 2.9, 3.1, 3.0, 3.0, 4.0, 3.8, 3…\n$ Petal.Length <dbl> 1.3, 1.7, 1.5, 1.4, 1.5, 1.4, 1.1, 1.2, 1.5, 1…\n$ Petal.Width  <dbl> 0.2, 0.4, 0.2, 0.2, 0.1, 0.1, 0.1, 0.2, 0.3, 0…\n$ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa…\n\nDeze samplingfuncties zijn mogelijk met behulp van het rsample pakket, dat deel uitmaakt van tidymodels.\nPre-proces interface\nIn tidymodels biedt het recipes pakket een interface dat gespecialiseerd is in het voorbewerken van gegevens. Binnen het pakket worden de functies die de gegevenstransformaties starten, of uitvoeren, vernoemd naar kookacties. Dat maakt de interface gebruiksvriendelijker. Bijvoorbeeld:\nrecipe() - start een nieuwe set van toe te passen transformaties, vergelijkbaar met het ggplot() commando. Het belangrijkste argument is de formule van het model.\nprep() - Voert de transformaties uit bovenop de geleverde gegevens (meestal de trainingsgegevens).\nElke datatransformatie is een stap. Functies komen overeen met specifieke soorten stappen, die elk een voorvoegsel van step_ hebben. Er zijn verschillende step_ functies; in dit voorbeeld gebruiken we er drie:\nstep_corr() - Verwijdert variabelen die sterk correleren met andere variabelen\nstep_center() - Normaliseert numerieke data die een gemiddelde van nul krijgen\nstep_scale() - Normaliseert numerieke data die een standard deviatie van één krijgen\nEen ander aardig kenmerk van deze step is dat deze kan worden toegepast op een specifieke variabele, groepen variabelen of alle variabelen. De all_outocomes() en all_predictors() functie bieden een hele prettige manier om specifieke groepen variabelen te specificeren. Bijvoorbeeld, als we de step_corr() willen gebruiken om alleen de predictorvariabelen te analyseren, gebruiken we step_corr(all_predictors()). Zo hoeven we niet elke variabele op te sommen.\nIn het volgende voorbeeld, brengen we de recipe(), prep() en step-functies om een recipe object te creëren. De training() functie wordt gebruikt om de dataset uit de eerder aangemaakte gesplitste dataset te halen.\n\n\n\nAls we het iris_recipe object oproepen, zal het details hierover afdrukken. De Operations sectie beschrijft wat er met de gegevens is gedaan. Een van de bewerkingen in het voorbeeld legt uit dat de correlatiestap de Petal.Length variabele heeft verwijderd.\n\nData Recipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor          4\n\nTraining data contained 90 data points and no missing data.\n\nOperations:\n\nCorrelation filter removed Petal.Length [trained]\nCentering for Sepal.Length, ... [trained]\nScaling for Sepal.Length, ... [trained]\n\nUitvoeren van het pre-proces\nDe testgegevens kunnen nu worden getransformeerd met behulp van precies dezelfde stappen, gewichten en categorisatie als bij de voorbewerking van de trainingsgegevens. Hiervoor wordt een andere functie met een kookterm gebruikt: bake(). Merk op dat de functie testing() wordt gebruikt om de juiste dataset te extraheren.\nThe testing data can now be transformed using the exact same steps, weights, and categorization used to pre-process the training data. To do this, another function with a cooking term is used: bake(). Notice that the testing() function is used in order to extract the appropriate data set.\n\nRows: 60\nColumns: 4\n$ Sepal.Length <dbl> -0.9090229, -1.1427716, -1.4933947, -1.0258972…\n$ Sepal.Width  <dbl> 1.0457854, -0.1076544, 0.1230336, 1.2764734, 0…\n$ Petal.Width  <dbl> -1.3566929, -1.3566929, -1.3566929, -1.3566929…\n$ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa…\n\nHet uitvoeren van dezelfde operatie over de trainingsgegevens is overbodig, omdat die gegevens al zijn voorgeprogrammeerd. Om de voorbereide trainingsgegevens in een variabele te laden, gebruiken we juice(). Het zal de gegevens uit het iris_recipe object halen.\n\nRows: 90\nColumns: 4\n$ Sepal.Length <dbl> -1.37652034, -0.55839976, -1.02589723, -1.7271…\n$ Sepal.Width  <dbl> 0.3537215, 1.9685372, 0.8150974, -0.3383423, 0…\n$ Petal.Width  <dbl> -1.3566929, -1.0918288, -1.3566929, -1.3566929…\n$ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa…\n\nModel training\nIn R zijn er meerdere pakketten die op hetzelfde type model passen. Het is gebruikelijk dat elk pakket een unieke interface biedt. Met andere woorden, zaken als een argument voor hetzelfde modelattribuut wordt voor elk pakket anders gedefinieerd. Bijvoorbeeld, de ranger en randomForest-pakketten passen bij Random Forest-modellen. In de ranger() functie gebruiken we num.trees om het aantal bomen te definiëren. In randomForest wordt dat argument dan weer ntree genoemd. Het is niet gemakkelijk om te wisselen tussen pakketten om hetzelfde model te draaien.\nIn plaats van het modelleerpakket te vervangen, vervangt tidymodels de interface. Beter gezegd, tidymodels biedt een enkele set functies en argumenten om een model te definiëren. Een specifiek pakket wordt dan aangepast in het model en algemeen gemaakt.\nIn het onderstaande voorbeeld wordt de rand_forest() functie gebruikt om een Random Forest model te initialiseren. Om het aantal bomen te definiëren wordt het treesargument gebruikt. Om de ranger versie van Random Forest te gebruiken, wordt de set_engine() functie gebruikt. Tenslotte wordt de fit() functie gebruikt om het model uit te voeren. De verwachte argumenten zijn de formule en de gegevens. Merk op dat het model boven op de gesausde getrainde gegevens draait.\n\n\n\nAls we nu hetzelfde model niet met ranger maar met randomForest willen draaien, hoeven we alleen maar de waarde in set_engine() te veranderen in randomForest.\n\n\n\nHet is ook het vermelden waard dat het model niet in een enkele, grote functie met veel argumenten is gedefinieerd. De definitie van het model is gescheiden in kleinere functies zoals fit() en set_engine(). zo krijgen we een flexibelere - en gemakkelijker te leren - interface.\nVoorspellingen\nIn plaats van een vector geeft de predictfunctie tibble terug. Standaard wordt de voorspellingsvariabele .pred_class genoemd. Merk op dat in het voorbeeld de ’kook’testgegevens worden gebruikt.\n\n# A tibble: 60 x 1\n   .pred_class\n   <fct>      \n 1 setosa     \n 2 setosa     \n 3 setosa     \n 4 setosa     \n 5 setosa     \n 6 setosa     \n 7 setosa     \n 8 setosa     \n 9 setosa     \n10 setosa     \n# … with 50 more rows\n\nHet is eenvoudig om de voorspellingen toe te voegen aan de ’kook’testgegevens door gebruik te maken van dplyr’s bind_cols() functie.\n\nRows: 60\nColumns: 5\n$ .pred_class  <fct> setosa, setosa, setosa, setosa, setosa, setosa…\n$ Sepal.Length <dbl> -0.9090229, -1.1427716, -1.4933947, -1.0258972…\n$ Sepal.Width  <dbl> 1.0457854, -0.1076544, 0.1230336, 1.2764734, 0…\n$ Petal.Width  <dbl> -1.3566929, -1.3566929, -1.3566929, -1.3566929…\n$ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa…\n\nModel validatie\nGebruik de metrics() functie om de prestaties van het model te meten. Het zal automatisch metrieken kiezen die geschikt zijn voor een bepaald type model. De functie verwacht een tibble dat de werkelijke resultaten bevat (waarheid) en wat het model heeft voorspeld (schatting).\n\n# A tibble: 2 x 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy multiclass     0.983\n2 kap      multiclass     0.975\n\nDoor de consistentie van de nieuwe interface is het meten van de resultaten voor het randomForest-model eenvoudig omdat je alleen maar de modelvariabele aan de bovenkant van de code hoeft te vervangen (nu iris_rf ipv iris_ranger.\n\n# A tibble: 2 x 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy multiclass     0.983\n2 kap      multiclass     0.975\n\nPer classificator metriek\nHet is eenvoudig om de waarschijnlijkheid voor elke mogelijke voorspelde waarde te verkrijgen door het type-argument op prob te zetten. Dat levert een tibble op met zoveel mogelijk variabelen als er mogelijke voorspelde waarden zijn. Hun naam zal standaard op de oorspronkelijke waarde worden gezet, voorafgegaan door .pred_.\n\nRows: 60\nColumns: 7\n$ .pred_setosa     <dbl> 0.99800000, 0.90737302, 0.97193651, 0.9780…\n$ .pred_versicolor <dbl> 0.000000000, 0.062146825, 0.006666667, 0.0…\n$ .pred_virginica  <dbl> 0.002000000, 0.030480159, 0.021396825, 0.0…\n$ Sepal.Length     <dbl> -0.9090229, -1.1427716, -1.4933947, -1.025…\n$ Sepal.Width      <dbl> 1.0457854, -0.1076544, 0.1230336, 1.276473…\n$ Petal.Width      <dbl> -1.3566929, -1.3566929, -1.3566929, -1.356…\n$ Species          <fct> setosa, setosa, setosa, setosa, setosa, se…\n\nOok hier, gebruik bind_cols() om de voorspellingen toe te voegen aan de test dataset die je hiervoor hebt voorbereid.\n\nRows: 148\nColumns: 5\n$ .level          <chr> \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"se…\n$ .n              <dbl> 0, 2, 3, 6, 7, 8, 10, 11, 12, 13, 14, 15, 1…\n$ .n_events       <dbl> 0, 2, 3, 6, 7, 8, 10, 11, 12, 13, 14, 15, 1…\n$ .percent_tested <dbl> 0.000000, 3.333333, 5.000000, 10.000000, 11…\n$ .percent_found  <dbl> 0.00000, 9.52381, 14.28571, 28.57143, 33.33…\n\nNu alles in een tibble zit, is het eenvoudig om curve-methoden te berekenen. In dit geval gebruiken we de gain_curve().\n\n\n\nIn de curve-methoden zit ook een autoplot() functie dat makkelijk kan worden omgezet naar een ggplot2 visualizatie.\n\n\n\nDit is een voorbeeld van een roc_curve(). Nogmaals, vanwege de consistentie van de interface, hoeft maar een functienaam te worden omgezet; zelfs de argument waarden blijven hetzelfde.\n\n\n\nOm de gecombineerde enkelvoudige voorspelde waarde en de waarschijnlijkheid van elke mogelijke waarde te meten, combineer je de twee voorspellingsmodi (met en zonder prop type). In dit voorbeeld is met het gebruik van dplyr’s select() de resulterende tibble makkelijker af te lezen.\n\nRows: 60\nColumns: 5\n$ .pred_setosa     <dbl> 0.99800000, 0.90737302, 0.97193651, 0.9780…\n$ .pred_versicolor <dbl> 0.000000000, 0.062146825, 0.006666667, 0.0…\n$ .pred_virginica  <dbl> 0.002000000, 0.030480159, 0.021396825, 0.0…\n$ .pred_class      <fct> setosa, setosa, setosa, setosa, setosa, se…\n$ Species          <fct> setosa, setosa, setosa, setosa, setosa, se…\n\nPipe de resultatentabel in metrics(). In dit geval, specificeer de .pred_class als de schatting.\n\n# A tibble: 4 x 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    multiclass     0.983\n2 kap         multiclass     0.975\n3 mn_log_loss multiclass     0.167\n4 roc_auc     hand_till      0.990\n\nSlotopmerkingen van Edgar Ruiz\nDit voorbeeld is bedoeld als een hele voorzichtige kennismaking met tidymodels. Het aantal functies en de mogelijkheden van dergelijke functies zijn voor deze demonstratie tot een minimum beperkt, maar er kan nog veel meer worden gedaan met deze prachtige suite van pakketten. Hopelijk helpt dit artikel jou op weg en moedigt het u misschien zelfs aan om uw kennis verder uit te breiden.\nDank je wel!\nEdgar Ruiz wil graag Max Kuhn en Davis Vaughan, de ontwikkelaars van tidymodels, bedanken. Ze waren hem genadig in het geven van instructie, feedback en begeleiding tijdens zijn reis om tidymodels te leren.\nSlotopmerkingen van Harrie Jonkman\nVoor mij was dit inderdaad een van de eerste kennismakingen met tidymodels. Ik kende het pakket caret en ook het mlr. tidymodels is een modernisering van deze eerste interfaces en moet net zo’n RStudio succes worden als tidyverse. Ondertussen het ik de website van tidymodels gelezen, de interactieve cursus van Julia Silge en de introducties van Alison Hill. Ook het nieuwe boek van Max Kuhn en Julia Silge ben ik op dit moment aan het lezen. Hieronder vind je die literatuur die ik op dit moment wat bij elkaar aan het zoeken ben. Voor mij is er nog een lange weg te gaan maar het artikel van Edgar Ruiz was voor mij een eerste uitstapje. Ik wil hem hartelijk dank voor zijn uitnodiging.\nLiteratuur en verwijzingen\nEdgar Ruiz (A Gentle introduction to tidymodels)[https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/]\nTidymodels (website)[https://www.tidymodels.org/]\nHefin Rhys (Machine learning with R)[https://education.rstudio.com/blog/2020/02/conf20-intro-ml/]\nJulia Silge (Supervised learning course)[https://juliasilge.com/blog/supervised-ml-course/]\nMax Kuhn and Julia Silge (Tidy modeling with R)[https://www.tmwr.org/]\nAlison Hill (Introduction to machine learning)[https://education.rstudio.com/blog/2020/02/conf20-intro-ml/]\nRebecca Barter (Tidymodels: tidy machine learning in R)[http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/]\n\n\n\n",
    "preview": "posts/2020-10-17-een-eenvoudige-introductie-op-machine-learning/een-eenvoudige-introductie-op-machine-learning_files/figure-html5/unnamed-chunk-16-1.png",
    "last_modified": "2020-11-01T20:31:54+01:00",
    "input_file": "een-eenvoudige-introductie-op-machine-learning.utf8.md"
  },
  {
    "path": "posts/2020-08-21-survival-analyse-met-r/",
    "title": "Survival analyse met R",
    "description": "Dit is een deel van een tutorial die Emily Zabore schreef over survival analyse met R.",
    "author": [
      {
        "name": "Emily Zabore, bewerking Harrie Jonkman",
        "url": "www.harriejonkman.nl"
      }
    ],
    "date": "2020-08-21",
    "categories": [],
    "preview": "posts/2020-08-21-survival-analyse-met-r/img/trial_anatomy.png",
    "last_modified": "2020-08-21T11:07:13+02:00"
  },
  {
    "path": "posts/2020-05-31-grafieken/",
    "title": "Grafieken",
    "description": "Hier een serie grafieken die je kunt maken. Dit is gebaseerd op blog van het Urban Institute in de Verenigde Staten. Zij maken hun grafieken altijd op eenzelfde manier. Hoe ze dat doen kan je hierlezen",
    "author": [
      {
        "name": "Urban Institute, bewerking Harrie Jonkman",
        "url": "www.harriejonkman.nl"
      }
    ],
    "date": "2020-05-31",
    "categories": [],
    "contents": "\nR is een krachtige, open-source programmeertaal en -omgeving. R blinkt uit in databeheer en bewerking, traditionele statistische analyse, machine learning en reproduceerbaar onderzoek. Maar is waarschijnlijk nog het meest bekend om zijn grafieken. In deze blog staan voorbeelden en instructies voor populaire en minder bekende plottechnieken in R. Het bevat ook instructies voor het gebruik van urbnthemes, het R-pakket van het Urban Institute voor het maken van bijna-publicatie-klare plots met ggplot2. Als u vragen heeft, zo staat op hun site, aarzel dan niet om contact op te nemen met Aaron Williams of Kyle Ueyama.\nAchtergrond\nHet R-pakket (library(urbnthemes)) maakt ggplot2 output dat verbonden is met Urban Institute’s Data Visualisatie stijl gids. Tzijn pakket produceert ** geen publicatieklare grafieken**. Visuele stijlen moeten nog steeds worden bewerkt met behulp van de normale bewerkingsworkflow van het project. Door grafieken te exporteren als pdf kunnen ze gemakkelijker worden bewerkt. Zie de sectie Plots opslaan voor meer informatie.\nHet vaste thema dat hier gebruikt wordt is getest met ggplot2 versie 3.0.0. Het zal niet goed functioneren met oudere versies van ggplot2.\nGebruik library(urbnthemes)\nJe moet in ieder geval de volgende code gebruiken om urbnthemes te installeren of te updaten:\n# install.packages(\"devtools\")\n# devtools::install_github(\"UrbanInstitute/urbnthemes\")\nVoer de volgende code bovenaan elk script uit. Als je dit hebt gedaan, kun je aan de slag:\n\n\nlibrary(tidyverse)\nlibrary(urbnthemes)\nlibrary(ggrepel)\nlibrary(extrafont)\n\nset_urbn_defaults(style = \"print\")\n\n\n\nIAls het nog niet is geïnstalleerd, installeer dan het gratis Lato-lettertype van Google-lettertypen. Als je op een Mac werkt sla je Lato op in je font-book. Als je op Windows werkt, moet je eerst Ghostscript installeren. Vertel dan in R waar uw ghostscript-bestand zich bevindt. Bewerk het bestandspad als het uwe zich op een andere plaats bevindt.\nSys.setenv(R_GSCMD=\"C:/Program Files/gs/gs9.05/bin/gswin32c.exe\")\nVoer dit script één keer uit om Lato te importeren en te registreren:\n# install.packages(c(\"ggplot2\", \"ggrepel\", \"extrafont\"))\n# urbnthemes::lato_install()\nHet laden en importeren van dit lettertype kan enkele minuten duren.\nGrammar of Graphics en de conventies\nHadley Wickham’s ggplot2 is gebaseerd op Leland Wilkinsons The Grammar of Graphics en Wickhams A Layered Grammar of Graphics. De gelaagde Grammer of Graphics is een gestructureerde manier van denken over de componenten van een plot, die zich vervolgens lenen voor de eenvoudige structuur van ggplot2.\nData zijn wat in een plot wordt gevisualiseerd en mappings zijn aanwijzingen voor hoe gegevens in een plot in kaart worden gebracht op een manier die door de mens kan worden waargenomen.\nGegevens zijn weergaven van de werkelijke gegevens zoals punten, lijnen en balken.\nStatistieken zijn statistische transformaties die samenvattingen van de gegevens weergeven, zoals histogrammen.\nScales kaartwaarden in de dataruimte naar waarden in de esthetische ruimte. Schalen tekenen legendes en assen.\nCoördinatensystemen beschrijven hoe geomen in het vlak van de grafiek in kaart worden gebracht.\nFacetten splitsen de gegevens op in betekenisvolle deelverzamelingen zoals kleine veelvouden. *Thema’s** controleren de fijnere punten van een plot zoals lettertypes, lettergroottes en achtergrondkleuren.\nMeer informatie vind je hier: ggplot2: Elegant Graphics for Data Analysis\nTips en trucs\nggplot2 verwacht dat de gegevens in dataframes of tibbles zitten. Het heeft de voorkeur dat de dataframes “netjes” zijn met elke variabele als een kolom, elke obseravtion als een rij, en elke observatie-eenheid als een aparte tabel. De dplyr en tidyr bevatten beknopte en effectieve hulpmiddelen voor het “opruimen” van gegevens.\nR staat toe dat functie-argumenten expliciet bij naam en impliciet bij positie worden aangeroepen. De codeervoorbeelden in deze handleiding bevatten alleen benoemde argumenten voor de duidelijkheid.\nGrafieken zullen soms verschillend worden weergeven op verschillende besturingssystemen. Dit zal geen probleem zijn als de afbeeldingen eenmaal zijn opgeslagen.\nDoorlopende x-assen hebben tikken. Discrete x-assen hebben geen teken. Gebruik remove_ticks() om teken te verwijderen.\nStaaf grafieken\nEen kleur\n\n\nmtcars %>%\n  count(cyl) %>%\n  ggplot(mapping = aes(x = factor(cyl), y = n)) +\n  geom_col() +\n  geom_text(mapping = aes(label = n), vjust = -1) +    \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.1))) +\n  labs(x = \"Cilinders\",\n       y = NULL) +\n  remove_ticks() +\n  remove_axis() \n\n\n\n\nEen kleur (Geroteerd)\nDit introduceert coord_flip() en remove_axis(axis = \"x\", flip = TRUE). remove_axis() komt van library(urbnthemes) en creëert een aangepast thema voor geroteerde staafgrafieken.\n\n\nmtcars %>%\n  count(cyl) %>%\n  ggplot(mapping = aes(x = factor(cyl), y = n)) +\n  geom_col() +\n  geom_text(mapping = aes(label = n), hjust = -1) +  \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.1))) +\n  labs(x = \"Cilinders\",\n       y = NULL) +  \n  coord_flip() +\n  remove_axis(axis = \"x\", flip = TRUE)\n\n\n\n\nDrie kleuren\nDit is identiek aan de vorige grafiek, behalve dat kleuren en een legenda zijn toegevoegd met fill = cyl. Door x om te zetten in een factor met factor(cyl) worden 5 en 7 op de x-as overgeslagen. Het toevoegen van fill = cyl zonder factor() zou een doorlopend kleurenschema en een legenda hebben gecreëerd.\n\n\nmtcars %>%\n  mutate(cyl = factor(cyl)) %>%\n  count(cyl) %>%\n  ggplot(mapping = aes(x = cyl, y = n, fill = cyl)) +\n  geom_col() +\n  geom_text(mapping = aes(label = n), vjust = -1) +    \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.1))) +\n  labs(x = \"Cylinders\",\n       y = NULL) +\n  remove_ticks() +\n  remove_axis()\n\n\n\n\nGestapelde staafgrafiek\nEen extra esthetiek kan eenvoudig worden toegevoegd aan de staafgrafiek door fill = categorical variable toe te voegen aan de mapping. Hier toont elk onderdeel een subset van een aantal auto’s met verschillende aantallen cilinders.\n\n\nmtcars %>%\n  mutate(am = factor(am, labels = c(\"Automatic\", \"Manual\")),\n         cyl = factor(cyl)) %>%  \n  group_by(am) %>%\n  count(cyl) %>%\n  group_by(cyl) %>%\n  arrange(desc(am)) %>%\n  mutate(label_height = cumsum(n)) %>%\n  ggplot() +\n  geom_col(mapping = aes(x = cyl, y = n, fill = am)) +\n  geom_text(aes(x = cyl, y = label_height - 0.5, label = n, color = am)) +\n  scale_color_manual(values = c(\"white\", \"black\")) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.1))) +\n  labs(x = \"Cylinders\",\n       y = NULL) +  \n  remove_ticks() +\n  remove_axis() +\n  guides(color = FALSE)\n\n\n\n\nGestapelde staafgrafiek met Position = Fill\nDe vorige voorbeelden gebruiken geom_col(), die een y-waarde voor de staafhoogte neemt. Dit voorbeeld gebruikt geom_bar() die de waarden opsomt en een waarde voor de staafhoogte genereert. In dit voorbeeld verandert position = \"fill\" in geom_bar() de y-as van de telling naar de verhouding van elke staaf.\n\n\nmtcars %>%\n  mutate(am = factor(am, labels = c(\"Automatic\", \"Manual\")),\n         cyl = factor(cyl)) %>%  \n  ggplot() +\n  geom_bar(mapping = aes(x = cyl, fill = am), position = \"fill\") +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.1)), labels = scales::percent) +\n  labs(x = \"Cylinders\",\n       y = NULL) +  \n  remove_ticks() +\n  guides(color = FALSE)\n\n\n\n\nOpgedeelde staafgrafiek\nDelen van de staafgrafiek in ggplot2 worden standaard opgestapeld. position = \"dodge\" in geom_col() breidt het staafdiagram uit zodat de subsets naast elkaar verschijnen.\n\n\nmtcars %>%\n  mutate(am = factor(am, labels = c(\"Automatic\", \"Manual\")),\n         cyl = factor(cyl)) %>%\n  group_by(am) %>%\n  count(cyl) %>%\n  ggplot(mapping = aes(cyl, y = n, fill = factor(am))) +\n  geom_col(position = \"dodge\") +\n  geom_text(aes(label = n), position = position_dodge(width = 0.7), vjust = -1) +    \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.1))) +\n  labs(x = \"Cylinders\",\n       y = NULL) +  \n  remove_ticks() +\n  remove_axis()\n\n\n\n\nLolly grafiek/Cleveland puntgrafiek\nLolly en Cleveland puntgrafiek zijn minimalistische alternatieven voor staafgrafieken. De sleutel tot beide grafieken is om de gegevens te ordenen op basis van de continue variabele met behulp van arrange() en dan de discrete variabele om te zetten in een factor met de geordende niveaus van de continue variabele met behulp van mutate(). Deze stap “slaat” de volgorde van de gegevens op.\nLollygrafiek\n\n\nmtcars %>%\n  rownames_to_column(\"model\") %>%\n  arrange(mpg) %>%\n  mutate(model = factor(model, levels = .$model)) %>%\n  ggplot(aes(mpg, model)) +\n    geom_segment(aes(x = 0, xend = mpg, y = model, yend = model)) +  \n    geom_point() +\n    scale_x_continuous(expand = expand_scale(mult = c(0, 0)), limits = c(0, 40)) +\n    labs(x = NULL, \n         y = \"Miles Per Gallon\")\n\n\n\n\nCleveland puntgrafiek\n\n\nmtcars %>%\n  rownames_to_column(\"model\") %>%\n  arrange(mpg) %>%\n  mutate(model = factor(model, levels = .$model)) %>%\n  ggplot(aes(mpg, model)) +\n    geom_point() +\n    scale_x_continuous(expand = expand_scale(mult = c(0, 0)), limits = c(0, 40)) +\n    labs(x = NULL, \n         y = \"Miles Per Gallon\")\n\n\n\n\nDumbellgrafieken\nPuntengrafieken\nEen kleur puntengrafiek\nPuntengrafieken zijn nuttig voor het tonen van relaties tussen twee of meer variabelen. Gebruik scatter_grid() van library(urbnthemes) om eenvoudig verticale rasterlijnen toe te voegen aan de puntengrafieken.\n\n\nmtcars %>%\n  ggplot(mapping = aes(x = wt, y = mpg)) +\n  geom_point() +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 6),\n                     breaks = 0:6) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     limits = c(0, 40),\n                     breaks = 0:8 * 5) +\n  labs(x = \"Gewicht (duizenden ponden)\",\n       y = \"MPG\") +\n  scatter_grid()\n\n\n\n\nPuntengrafiek met hoge dichtheid met transparantie\nGrote aantallen waarnemingen maken soms strooiplekken soms moeilijk om te interpreteren omdat punten elkaar overlappen. Het toevoegen van alpha = met een getal tussen 0 en 1 voegt transparantie toe aan punten en helderheid aan grafieken.\n\n\ndiamonds %>%\n  ggplot(mapping = aes(x = carat, y = price)) +\n  geom_point(alpha = 0.05) +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 6),\n                     breaks = 0:6) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     limits = c(0, 20000),\n                     breaks = 0:4 * 5000,\n                     labels = scales::dollar) +\n  labs(x = \"Carat\",\n       y = \"Price\") +\n  scatter_grid()\n\n\n\n\nHexus puntengrafiek\nSoms is transparantie niet genoeg om duidelijkheid te brengen in een verstrooide grafiek met veel waarnemingen. Als n toeneemt in de honderdduizenden en zelfs miljoenen, kan geom_hex een van de beste manieren zijn om relaties tussen twee variabelen weer te geven.\n\n\ndiamonds %>%\n  ggplot(mapping = aes(x = carat, y = price)) +\n  geom_hex(mapping = aes(fill = ..count..)) +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 6),\n                     breaks = 0:6) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     limits = c(0, 20000),\n                     breaks = 0:4 * 5000,\n                     labels = scales::dollar) +\n  scale_fill_gradientn(labels = scales::comma) +  \n  labs(x = \"Carat\",\n       y = \"Price\") +\n  scatter_grid() +\n  theme(legend.position = \"right\",\n        legend.direction = \"vertical\")\n\n\n\n\nPuntengrafiek met random vervuiling\nSoms hebben puntengrafieken veel overlappende punten, maar een redelijk aantal waarnemingen. Geom_jitter voegt een kleine hoeveelheid willekeurige ruis toe zodat punten minder snel overlappen. De breedte en hoogte bepalen de hoeveelheid ruis die wordt toegevoegd. Merk in het volgende voor- en naschrijven op hoeveel punten er nog zichtbaar zijn na het toevoegen van jitter.\nVoor\n\n\nmpg %>%\n  ggplot(mapping = aes(x = displ, y = cty)) +\n  geom_point() +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 8),\n                     breaks = 0:8) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     limits = c(0, 40),\n                     breaks = 0:4 * 10) +\n  labs(x = \"Uitval\",\n       y = \"MPG\") +\n  scatter_grid()\n\n\n\n\nNa\n\n\nset.seed(2017)\nmpg %>%\n  ggplot(mapping = aes(x = displ, y = cty)) +\n  geom_jitter() +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 8),\n                     breaks = 0:8) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     limits = c(0, 40),\n                     breaks = 0:4 * 10) +\n  labs(x = \"Uitval\",\n       y = \"MPG\") +\n  scatter_grid()\n\n\n\n\nPuntengrafiek met gevarieerde puntenomvang\nGewichten en populaties kunnen in puntengrafieken met de grootte van de punten in kaart worden gebracht. Hier wordt het aantal huishoudens in elke staat in kaart gebracht op de grootte van elk punt met behulp van aes(size = hhpop). Opmerking: ggplot2::geom_point() wordt gebruikt in plaats van geom_point().\nWel eerst dit pakket laden (wel installeren als je dat nog niet hebt gedaan).\n\n\nlibrary(urbnmapr)\n\n\n\n\n\nurbnmapr::statedata %>%\n  ggplot(mapping = aes(x = medhhincome, y = horate)) +\n  ggplot2::geom_point(mapping = aes(size = hhpop), alpha = 0.3) +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(30000, 80000),\n                     breaks = 3:8 * 10000,\n                     labels = scales::dollar) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     limits = c(0, 0.8),\n                     breaks = 0:4 * 0.2) +\n  scale_radius(range = c(3, 15),\n               breaks = c(2500000, 7500000, 12500000), \n               labels = scales::comma) +\n  labs(x = \"Huishoud inkomen\",\n       y = \"Ratio huizenbezit\") +\n  scatter_grid() +\n  theme(plot.margin = margin(r = 20))\n\n\n\n\nPuntengrafieken met vulling\nEen derde esthetiek kan worden toegevoegd aan puntengrafieken. Hier betekent kleur het aantal cilinders in elke auto. Voordat ggplot() wordt aangeroepen, worden de cilinders aangemaakt met behulp van library(dplyr) en de functie %>%.\n\n\nmtcars %>%\n  mutate(cyl = paste(cyl, \"cylinders\")) %>%\n  ggplot(aes(x = wt, y = mpg, color = cyl)) +\n  geom_point() +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 6),\n                     breaks = 0:6) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     limits = c(0, 40),\n                     breaks = 0:8 * 5) +\n  labs(x = \"Gewicht (duizenden ponden)\",\n       y = \"MPG\") +\n  scatter_grid()\n\n\n\n\nLijngrafieken\n\n\neconomics %>%\n  ggplot(mapping = aes(x = date, y = unemploy)) +\n  geom_line() +\n  scale_x_date(expand = expand_scale(mult = c(0.002, 0)), \n               breaks = \"10 years\",\n               limits = c(as.Date(\"1961-01-01\"), as.Date(\"2020-01-01\")),\n               date_labels = \"%Y\") +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     breaks = 0:4 * 4000,\n                     limits = c(0, 16000),\n                     labels = scales::comma) +\n  labs(x = \"Jaar\", \n       y = \"Aantal werklozen (1,000den)\")\n\n\n\n\nLijngrafieken met meerdere lijnen\n\n\nlibrary(gapminder)\n\ngapminder %>%\n  filter(country %in% c(\"Australia\", \"Netherlands\", \"New Zealand\")) %>%\n  mutate(country = factor(country, levels = c(\"Netherlands\", \"Australia\", \"New Zealand\"))) %>%\n  ggplot(aes(year, gdpPercap, color = country)) +\n  geom_line() +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     breaks = c(1952 + 0:12 * 5), \n                     limits = c(1952, 2007)) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     breaks = 0:8 * 5000,\n                     labels = scales::dollar, \n                     limits = c(0, 40000)) +\n  labs(x = \"Jaap\",\n       y = \"BNP per hoofd van de bevolking (US dollars)\")\n\n\n\n\nHet plotten van meer dan één variabele kan nuttig zijn om de relatie van variabelen in de tijd te zien, maar het vergt een kleine hoeveelheid databewerking.\nDit komt omdat ggplot2 gegevens in een “lang” formaat wil hebben in plaats van een “breed” formaat voor lijnplots met meerdere lijnen. gather() en spread() uit het tidyr pakket maakt het wisselen tussen “lang” en “breed” pijnloos. In wezen gaan variabele titels naar “key” en variabele waarden naar “value”. Dan verandert ggplot2, de verschillende niveaus van de sleutelvariabele (bevolking, werkloosheid) in kleuren.\n\n\nas_tibble(EuStockMarkets) %>%\n  mutate(date = time(EuStockMarkets)) %>%\n  gather(key = \"key\", value = \"value\", -date) %>%\n  ggplot(mapping = aes(x = date, y = value, color = key)) +\n  geom_line() +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(1991, 1999), \n                     breaks = c(1991, 1993, 1995, 1997, 1999)) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     breaks = 0:4 * 2500,\n                     labels = scales::dollar, \n                     limits = c(0, 10000)) +  \n  labs(x = \"Tijd\",\n       y = \"Waarde\")\n\n\n\n\nTrapgrafiek\ngeom_line() verbindt coördinaten met de kortst mogelijke rechte lijn. Soms zijn trapgrafieken nodig omdat de y-waarden niet veranderen tussen de coördinaten. Zo wordt bijvoorbeeld de bovengrens van de Federal Funds Rate met regelmatige tussenpozen ingesteld en blijft deze constant totdat deze wordt gewijzigd.\n\n\n# downloaded from FRED on 2018-12-06\n\n# https://fred.stlouisfed.org/series/DFEDTARU\n\nfed_fund_rate <- read_csv(\n  \"date, fed_funds_rate\n   2014-01-01,0.0025\n   2015-12-16,0.0050\n   2016-12-14,0.0075\n   2017-03-16,0.0100\n   2017-06-15,0.0125\n   2017-12-14,0.0150\n   2018-03-22,0.0175\n   2018-06-14,0.0200\n   2018-09-27,0.0225\n   2018-12-06,0.0225\")\n\nfed_fund_rate %>%\n  ggplot(mapping = aes(x = date, y = fed_funds_rate)) + \n  geom_step() +\n  scale_x_date(expand = expand_scale(mult = c(0.002, 0)), \n               breaks = \"1 year\",\n               limits = c(as.Date(\"2014-01-01\"), as.Date(\"2019-01-01\")),\n               date_labels = \"%Y\") +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     breaks = c(0, 0.01, 0.02, 0.03),\n                     limits = c(0, 0.03),\n                     labels = scales::percent) +  \n  labs(x = \"Tijd\",\n       y = \"Bovengrens van de Federal Funds Rate\")\n\n\n\n\nPadgrafiek\nDe Beveridge-curve is een macro-economisch plot dat een verband toont tussen de werkloosheidsgraad en de vacaturegraad. Bewegingen op de curve duiden op veranderingen in de bedrijfscultuur en horizontale verschuivingen van de curve duiden op structurele veranderingen op de arbeidsmarkt.\nLijnen in de Beveridge-curve bewegen niet monotoon van links naar rechts. Daarom is het noodzakelijk om geom_pad() te gebruiken.\n\n\nlibrary(ggrepel)\n\nbeveridge <- read_csv(\n  [1336 chars quoted with '\"'])\n\nlabels <- beveridge %>%\n  filter(lubridate::month(quarter) == 1)\n\nbeveridge %>%\n  ggplot() +\n  geom_path(mapping = aes(x = unempoyment_rate, y = vacanacy_rate), alpha = 0.5) +\n  geom_point(data = labels, mapping = aes(x = unempoyment_rate, y = vacanacy_rate)) +\n  geom_text_repel(data = labels, mapping = aes(x = unempoyment_rate, y = vacanacy_rate, label = lubridate::year(quarter))) +  \n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0.04, 0.1),\n                     labels = scales::percent) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     breaks = c(0, 0.01, 0.02, 0.03, 0.04, 0.05),\n                     limits = c(0, 0.05),\n                     labels = scales::percent) +  \n  labs(x = \"Seizoen gecontroleerd werkloosheidspercentage\",\n       y = \"Seizoen gecontroleerd beschikbare banenpercentage\") +  \n  scatter_grid()\n\n\n\n\nHellingsgrafiek\n\n\n# https://www.bls.gov/lau/\nlibrary(ggrepel)\n\nunemployment <- tibble(\n  time = c(\"October 2009\", \"October 2009\", \"October 2009\", \"August 2017\", \"August 2017\", \"August 2017\"),\n  rate = c(7.4, 7.1, 10.0, 3.9, 3.8, 6.4),\n  state = c(\"Maryland\", \"Virginia\", \"Washington, D.C.\", \"Maryland\", \"Virginia\", \"Washington, D.C.\")\n)\n\nlabel <- tibble(label = c(\"October 2009\", \"August 2017\"))\noctober <- filter(unemployment, time == \"October 2009\")\naugust <- filter(unemployment, time == \"August 2017\")\n\nunemployment %>%\n  mutate(time = factor(time, levels = c(\"October 2009\", \"August 2017\")),\n         state = factor(state, levels = c(\"Washington, D.C.\", \"Maryland\", \"Virginia\"))) %>%\n  ggplot() + \n  geom_line(aes(time, rate, group = state, color = state), show.legend = FALSE) +\n  geom_point(aes(x = time, y = rate, color = state)) +\n  labs(subtitle = \"Werkloosheidspercentage\") +\n  theme(axis.ticks.x = element_blank(),\n        axis.title.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.title.y = element_blank(), \n        axis.text.y = element_blank(),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        axis.line = element_blank()) +\n  geom_text_repel(data = october, mapping = aes(x = time, y = rate, label = as.character(rate)), nudge_x = -0.06) + \n  geom_text_repel(data = august, mapping = aes(x = time, y = rate, label = as.character(rate)), nudge_x = 0.06)\n\n\n\n\nUnivariaat\nEr zijn een aantal manieren om de verdeling van univariate data in R te onderzoeken. Sommige methoden, zoals strookdiagrammen, laten alle datapunten zien. Andere methoden, zoals de box- en whiskerplot, tonen geselecteerde datapunten die belangrijke waarden communiceren zoals de mediaan en het 25e percentiel. Tenslotte tonen sommige methoden geen van de onderliggende data, maar berekenen ze dichtheidsschattingen. Elke methode heeft voor- en nadelen, dus het is de moeite waard om de verschillende vormen te begrijpen. Lees voor meer informatie 40 jaar boxplottem van Hadley Wickham en Lisa Stryjewski.\nStripdiagram\nStripdiagrammen, de eenvoudigste univariate plot, tonen de verdeling van de waarden langs één as. Stripdiagrammen werken het beste met variabelen die veel variatie hebben. Zo niet, dan hebben de punten de neiging om op elkaar te clusteren. Zelfs als de variabele veel variatie heeft, is het vaak belangrijk om transparantie toe te voegen aan de punten met alpha = zodat overlappende waarden zichtbaar zijn.\n\n\nmsleep %>%\n  ggplot(aes(x = sleep_total, y = factor(1))) +\n  geom_point(alpha = 0.2, size = 5) +\n  labs(y = NULL) +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 25), \n                     breaks = 0:5 * 5) +\n  scale_y_discrete(labels = NULL) +\n  labs(title = \"Totale slaaptijd van verschillende zoogdieren\",\n       x = \"Totale slaaptijd (uren)\",\n       y = NULL) +\n  theme(axis.ticks.y = element_blank())\n\n\n\n\nStripdiagram met Highlighting\nOmdat strookdiagrammen alle waarden weergeven, zijn ze nuttig om aan te geven waar de geselecteerde punten in de verdeling van een variabele liggen. De duidelijkste manier om dit te doen is door geom_point() tweemaal toe te voegen met filter() in het gegevensargument. Op deze manier worden de geaccentueerde waarden boven op de niet geaccentueerde waarden getoond.\n\n\nggplot() +\n  geom_point(data = filter(msleep, name != \"Red fox\"), \n                    aes(x = sleep_total, \n                        y = factor(1)),\n             alpha = 0.2, \n             size = 5,\n             color = \"grey50\") +\n  geom_point(data = filter(msleep, name == \"Red fox\"),\n             aes(x = sleep_total, \n                 y = factor(1), \n                 color = name),\n             alpha = 0.8,\n             size = 5) +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 25), \n                     breaks = 0:5 * 5) +  \n  scale_y_discrete(labels = NULL) +\n  labs(title = \"Totale slaaptijd van verschillende zoogdieren\",\n       x = \"Totale slaaptijd (uren)\",\n       y = NULL,\n       legend) +\n  guides(color = guide_legend(title = NULL)) +\n  theme(axis.ticks.y = element_blank())\n\n\n\n\nOndergeschikte Strip Chart\nVoeg een y-variabele toe om de verdelingen van de continue variabele in deelverzamelingen van een categorische variabele te zien.\n\n\nlibrary(forcats)\n\nmsleep %>%\n  filter(!is.na(vore)) %>%\n  mutate(vore = fct_recode(vore, \n                            \"Insectivore\" = \"insecti\",\n                            \"Omnivore\" = \"omni\", \n                            \"Herbivore\" = \"herbi\", \n                            \"Carnivore\" = \"carni\"\n                            )) %>%\n  ggplot(aes(x = sleep_total, y = vore)) +\n  geom_point(alpha = 0.2, size = 5) +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 25), \n                     breaks = 0:5 * 5) +  \n  labs(title = \"Totale slaaptijd van verschillende zoogdieren volgens dieet\",\n       x = \"Totale slaaptijd (uren)\",\n       y = NULL) +\n  theme(axis.ticks.y = element_blank())\n\n\n\n\nHistogrammen\nHistogrammen verdelen de verdeling van een variabele in n staven van gelijke grootte en tellen en tonen vervolgens het aantal waarnemingen in elke staaf. Histogrammen zijn gevoelig voor de breedte van de staven. Zoals ?geom_histogram merkt op, “U moet altijd de waarde van [de standaard staafbreedte] overschrijven, door meerdere breedtes te onderzoeken om het beste te vinden om de verhalen in uw gegevens te illustreren”.\n\n\nggplot(data = diamonds, mapping = aes(x = depth)) + \n  geom_histogram(bins = 100) +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 100)) +  \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.2)), labels = scales::comma) +\n  labs(x = \"Depth\",\n       y = \"Count\")\n\n\n\n\nBoxplots\nBoxplots zijn in de jaren zeventig uitgevonden door John Tukey. In plaats van de onderliggende gegevens te tonen of het aantal blikken van de onderliggende gegevens, richten ze zich op belangrijke waarden zoals het 25e percentiel, de mediaan en het 75e percentiel.\n\n\nInsectSprays %>%\n  ggplot(mapping =  aes(x = spray, y = count)) +\n  geom_boxplot() +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.2))) +\n  labs(x = \"Type of insect spray\",\n       y = \"Number of dead insects\") +\n  remove_ticks()\n\n\n\n\nGladde kernel verdelingsgrafieken\nDoorlopende variabelen met vloeiende verdelingen worden soms beter weergegeven met afgevlakte kerneldichtheidsschattingen dan histogrammen of boxplots. geom_density() berekent en plot een kerneldichtheidsschatting. Let op de klontjes rond gehele en halve getallen in de volgende verdeling vanwege afrondingen.\n\n\ndiamonds %>%\n  ggplot(mapping = aes(carat)) +\n  geom_density(color = NA) +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, NA)) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.2))) +\n  labs(x = \"Carat\",\n       y = \"Density\")\n\n\n\n\n\n\ndiamonds %>%\n  mutate(cost = ifelse(price > 5500, \"More than $5,500 +\", \"$0 to $5,500\")) %>%\n  ggplot(mapping = aes(carat, fill = cost)) +\n  geom_density(alpha = 0.25, color = NA) +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, NA)) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.1))) +\n  labs(x = \"Carat\",\n       y = \"Density\")\n\n\n\n\n‘Ridgeline’ grafieken\nRidgeline plots zijn gedeeltelijk overlappende afgevlakte kerneldichtheid plots gefacetteerd door een categorische variabele die veel informatie verpakken in één elegante plot. Onderstaande maakt duidelijk wat we hiermee bedoelen.\n\n\nlibrary(ggridges)\n\nggplot(diamonds, mapping = aes(x = price, y = cut)) +\n  geom_density_ridges(fill = \"#1696d2\") +\n  labs(x = \"Price\",\n       y = \"Cut\")\n\n\n\n\nViool grafieken\nVioolplots zijn symmetrische weergaven van gladde kerneldichtheidplots.\n\n\nInsectSprays %>%\n  ggplot(mapping = aes(x = spray, y = count, fill = spray)) +\n  geom_violin(color = NA) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.2))) +\n  labs(x = \"Type of insect spray\",\n       y = \"Number of dead insects\") +\n  remove_ticks()\n\n\n\n\nBonenplot\nIndividuele uitschieters en belangrijke samenvattende waarden zijn niet zichtbaar in vioolplots of afgevlakte kerneldichtheidsplots. Bonenplots, gemaakt door Peter Kampstra in 2008, zijn vioolplots met gegevens weergegeven als kleine lijnen in een eendimensionale stripplot en grotere lijnen voor het gemiddelde.\n\n\nmsleep %>%\n  filter(!is.na(vore)) %>%\n  mutate(vore = fct_recode(vore, \n                            \"Insectivore\" = \"insecti\",\n                            \"Omnivore\" = \"omni\", \n                            \"Herbivore\" = \"herbi\", \n                            \"Carnivore\" = \"carni\"\n                            )) %>%\n  ggplot(aes(x = vore, y = sleep_total, fill = vore)) +\n  stat_summary(fun.y = \"mean\",\n               colour = \"black\", \n               size = 30,\n               shape = 95,\n               geom = \"point\") +\n  geom_violin(color = NA) +\n  geom_jitter(width = 0,\n              height = 0.05,\n              alpha = 0.4,\n              shape = \"-\",\n              size = 10,\n              color = \"grey50\") +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.2))) +  \n    labs(x = NULL,\n         y = \"Total sleep time (hours)\") +\n  theme(legend.position = \"none\") +\n  remove_ticks()\n\n\n\n\nGebiedsplot\nGestapeld gebied\n\n\ntxhousing %>%\n  filter(city %in% c(\"Austin\",\"Houston\",\"Dallas\",\"San Antonio\",\"Fort Worth\")) %>%\n  group_by(city, year) %>%\n  summarize(sales = sum(sales)) %>%\n  ggplot(aes(x = year, y = sales, fill = city)) +\n  geom_area(position = \"stack\") +\n  scale_x_continuous(expand = expand_scale(mult = c(0, 0)),\n                     limits = c(2000, 2015),\n                     breaks = 2000 + 0:15) +  \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.2)), \n                     labels = scales::comma) +\n  labs(x = \"Year\",\n       y = \"Home sales\")\n\n\n\n\nGevuld gebied\n\n\ntxhousing %>%\n  filter(city %in% c(\"Austin\",\"Houston\",\"Dallas\",\"San Antonio\",\"Fort Worth\")) %>%\n  group_by(city, year) %>%\n  summarize(sales = sum(sales)) %>%\n  ggplot(aes(x = year, y = sales, fill = city)) +\n  geom_area(position = \"fill\") +\n  scale_x_continuous(expand = expand_scale(mult = c(0, 0)),\n                     limits = c(2000, 2015),\n                     breaks = 2000 + 0:15) +  \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.02)),\n                     breaks = c(0, 0.25, 0.5, 0.75, 1),\n                     labels = scales::percent) +\n  labs(x = \"Year\",\n       y = \"Home sales\")\n\n\n\n\nWafelkaart / Vierkante taartkaart\nHet wafelpakket {CRAN en Github} maakt vierkante taartkaarten. Het kan ook gecombineerd worden met glyphs voor meer elegantere vormen dan vierkanten. Data hiervoor komen hier vandaan: A Vision for an Equitable DC.\nWafelkaarten vereisen een beetje extra knutselen omdat ze worden genoemd vanuit library(waffle) in plaats van library(ggplot2). Het belangrijkste is dat voor wafeldiagrammen theme_urban(text = element_text(family = \"Lato\")) nodig is voor het lettertype Lato.\nEnkele wafelkaart\n\n\nlibrary(waffle)\n\nparts <- c(`Virginia\\nClinics` = (1000 - 208 - 105), `Maryland\\nClinics` = 208, `D.C.\\nClinics` = 105)\nwaffle(parts, rows = 25, size = 1, colors = c(\"#1696d2\", \"#fdbf11\", \"#000000\"), legend_pos = \"bottom\") +\n  labs(title = \"Free Clinics in the D.C.-Maryland-Virginia Area\",\n       subtitle = \"1 Square == 1 Clinic\") +\n  theme(text = element_text(family = \"Lato\"))\n\n\n\n\nMeervoudige wafelkaarten\nlibrary(waffle) allows multiple waffle charts to be ironed together using iron(). maakt het mogelijk om meerdere wafelkaarten in elkaar te strijken met behulp van iron(). Het samen strijken van meerdere wafeldiagrammen vereist wat trial-and-error om de maten en resolutie goed te krijgen, maar de resultaten kunnen de moeite waard zijn. Vergeet niet theme(text = element_text(family = \"Lato\"))!\n\n\nlibrary(waffle)\n\nwhite <- c(`With Degree` = 169300, `Without Degree` = 800)\nblack <- c(`With Degree` = 174900, `Without Degree` = 34700)\nhispanic <- c(`With Degree` = 27700, `Without Degree` = 12400)\n\niron(\n  waffle(white / 83, rows = 40, size = 0.25, colors = c(\"#1696d2\", \"#fdbf11\"), title = \"White\", keep = FALSE, pad = 10) + \n  theme(text = element_text(family = \"Lato\")),\n  waffle(black / 83, rows = 40, size = 0.25, colors = c(\"#1696d2\", \"#fdbf11\"), title = \"Black\", keep = FALSE) + \n  theme(text = element_text(family = \"Lato\")),\n  waffle(hispanic / 83, rows = 40, size = 0.25, colors = c(\"#1696d2\", \"#fdbf11\"), title = \"Hispanic\", keep = FALSE, pad = 59, xlab = \"1 Square == 83 People\") + \n  theme(text = element_text(family = \"Lato\"))\n) \n\n\n\n\nWarmtekaart\n\n\nlibrary(fivethirtyeight)\n\nbad_drivers %>%\n  filter(state %in% c(\"Maine\", \"New Hampshire\", \"Vermont\", \"Massachusetts\", \"Connecticut\", \"New York\")) %>%\n  mutate(`Number of\\nDrivers` = scale(num_drivers),\n         `Percent\\nSpeeding` = scale(perc_speeding),\n         `Percent\\nAlcohol` = scale(perc_alcohol),\n         `Percent Not\\nDistracted` = scale(perc_not_distracted),\n         `Percent No\\nPrevious` = scale(perc_no_previous),\n         state = factor(state, levels = rev(state))\n         ) %>%\n  select(-insurance_premiums, -losses, -(num_drivers:losses)) %>%\n  gather(`Number of\\nDrivers`:`Percent No\\nPrevious`, key = \"variable\", value = \"SD's from Mean\") %>%\n  ggplot(aes(variable, state)) +\n    geom_tile(aes(fill = `SD's from Mean`)) +\n    labs(x = NULL,\n         y = NULL) + \n    scale_fill_gradientn() +\n    theme(legend.position = \"right\",\n          legend.direction = \"vertical\",\n          axis.line.x = element_blank(),\n          panel.grid.major.y = element_blank()) +\n  remove_ticks()\n\n\n\n#https://learnr.wordpress.com/2010/01/26/ggplot2-quick-heatmap-plotting/\n\n\n\nFaceteren en kleine kaartjes\nfacet_wrap()\nR’s faceteersysteem is een krachtige manier om kleinere kaarten te maken.\nSommige bewerkingen aan het thema kunnen nodig zijn, afhankelijk van het aantal rijen en kolommen in de plot.\n\n\ndiamonds %>%\n  ggplot(mapping = aes(x = carat, y = price)) +\n  geom_point(alpha = 0.05) +\n  facet_wrap(~cut, ncol = 5) +\n  scale_x_continuous(expand = expand_scale(mult = c(0, 0)),\n                     limits = c(0, 6)) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0)),\n                     limits = c(0, 20000), \n                     labels = scales::dollar) +\n  labs(x = \"Karaat\",\n       y = \"Prijs\") +\n  scatter_grid()\n\n\n\n\nfacet_grid()\n\n\ndiamonds %>%\n  filter(color %in% c(\"D\", \"E\", \"F\", \"G\")) %>%\n  ggplot(mapping = aes(x = carat, y = price)) +\n  geom_point(alpha = 0.05) +\n  facet_grid(color ~ cut) +\n  scale_x_continuous(expand = expand_scale(mult = c(0, 0)),\n                     limits = c(0, 4)) +  \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0)),\n                     limits = c(0, 20000), \n                     labels = scales::dollar) +\n  labs(x = \"Carat\",\n       y = \"Price\") +\n  theme(panel.spacing = unit(20L, \"pt\")) +\n  scatter_grid()\n\n\n\n\n‘Smoothers’\ngeom_smooth() past en modelleert op gegevens met twee of meer dimensies.\nHet begrijpen en manipuleren van defaults is belangrijker voor geom_smooth() dan andere ‘geoms’ omdat het een aantal aannames bevat. geom_smooth() gebruikt automatisch loess voor datasets met minder dan 1.000 waarnemingen en een algemeen model met formula = y ~ s(x, bs = \"cs\") voor datasets met meer dan 1.000 waarnemingen. Beide zijn standaard ingesteld op een betrouwbaarheidsinterval van 95%.\nModellen worden gekozen met method = en kunnen worden ingesteld op lm(), glm(), gam(), loess(), rlm(), en meer. Formules kunnen worden opgegeven met formule = en y ~ x syntaxis. Het plotten van de standaardfout wordt omgeschakeld met se = TRUE en se = FALSE, en het niveau wordt gespecificeerd met level =. Zoals altijd is er meer informatie te zien in RStudio met ?geom_smooth().\ngeom_point() voegt een scatterplot toe aan geom_smooth(). De volgorde van de functie-aanroepen is belangrijk. De functie die als tweede wordt aangeroepen wordt bovenop de functie die als eerste wordt aangeroepen gelegd.\n\n\ndiamonds %>%\n  ggplot(mapping = aes(x = carat, y = price)) +\n  geom_point(alpha = 0.05) +\n  geom_smooth(color =  \"#ec008b\") +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 5),\n                     breaks = 0:5) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     limits = c(0, 20000), \n                     labels = scales::dollar) +  \n  labs(x = \"Carat\",\n       y = \"Price\") +\n  scatter_grid()\n\n\n\n\ngeom_smooth kan worden onderverdeeld in categorische en factorvariabelen. Dit vereist subgroepen met een behoorlijk aantal waarnemingen en een behoorlijke mate van variabiliteit over de x-as. De betrouwbaarheidsintervallen worden vaak groter aan de uiteinden, zodat speciale zorg nodig is om de grafiek zinvol en leesbaar te maken.\nDit voorbeeld gebruikt Loess met MPG = verplaatsing.\n\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = factor(cyl))) +\n  geom_point(alpha = 0.2) +\n  geom_smooth() +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 7),\n                     breaks = 0:7) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     limits = c(0, 60)) +  \n  labs(x = \"Engine displacement\",\n       y = \"Highway MPG\") +\n  scatter_grid()\n\n\n\n\nDit voorbeeld gebruikt liniaire regressie met MPG = displacement.\n\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = factor(cyl))) +\n  geom_point(alpha = 0.2) +\n  geom_smooth(method = \"lm\") +\n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)), \n                     limits = c(0, 7),\n                     breaks = 0:7) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     limits = c(0, 60)) +  \n  labs(x = \"Engine displacement\",\n       y = \"Highway MPG\") +\n  scatter_grid()\n\n\n\n\nBenadrukken\nlibrary(gghighlight) maakt intuitief benadrukken van ggplot2 plots mogelijk. gghighlight wijzigt bestaande ggplot2-objecten, dus geen enkele andere code mag veranderen. Alle markering wordt afgehandeld door de functie gghighlight(), die alle soorten geomen kan verwerken.\nWaarschuwing:  R zal een fout maken als er te veel kleuren worden gemarkeerd vanwege het ontwerp van urbnthemes. Verlaag gewoon het aantal gemarkeerde geomen om dit probleem op te lossen.\nEr zijn twee belangrijke manieren om de aandacht te vestigen.\nDrempelwaarde\nDe eerste manier om te markeren is met een drempel. Voeg een logische test toe aan gghighlight() om te beschrijven welke lijnen gemarkeerd moeten worden. Hier worden regels met een maximale verandering in het bruto binnenlands product per hoofd van de bevolking van meer dan $35.000 gemarkeerd met gghighlight(max(pcgpd_change) > 35000, use_direct_label = FALSE).\n\n\nlibrary(gghighlight)\nlibrary(gapminder)\n\ndata <- gapminder %>%\n  filter(continent %in% c(\"Europe\")) %>%\n  group_by(country) %>%\n  mutate(pcgpd_change = ifelse(year == 1952, 0, gdpPercap - lag(gdpPercap))) %>%\n  mutate(pcgpd_change = cumsum(pcgpd_change))\n  \ndata %>%\n  ggplot(aes(year, pcgpd_change, group = country, color = country)) +\n  geom_line() +\n  gghighlight(max(pcgpd_change) > 35000, use_direct_label = FALSE) +  \n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)),\n                     breaks = c(seq(1950, 2010, 10)),\n                     limits = c(1950, 2010)) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     breaks = 0:8 * 5000,\n                     labels = scales::dollar,\n                     limits = c(0, 40000)) +\n  labs(x = \"Year\",\n       y = \"Change in per-capita GDP (US dollars)\")\n\n\n\n\nRang\nDe tweede manier om te markeren is door middel van een rangorde. Hier worden de landen met de eerste hoogste waarden voor verandering in het bruto binnenlands product per hoofd van de bevolking benadrukt met gghighlight(max(pcgpd_change), max_highlight = 5, use_direct_label = FALSE).\n\n\ndata %>%\n  ggplot(aes(year, pcgpd_change, group = country, color = country)) +\n  geom_line() +\n  gghighlight(max(pcgpd_change), max_highlight = 5, use_direct_label = FALSE) +  \n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)),\n                     breaks = c(seq(1950, 2010, 10)),\n                     limits = c(1950, 2010)) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     breaks = 0:8 * 5000,\n                     labels = scales::dollar,\n                     limits = c(0, 40000)) +\n  labs(x = \"Year\",\n       y = \"Change in per-capita GDP (US dollars)\")\n\n\n\n\nFaceteren\ngghighlight() werkt goed met ggplot2’s facetsysteem.\n\n\ndata %>%\n  ggplot(aes(year, pcgpd_change, group = country)) +\n  geom_line() +\n  gghighlight(max(pcgpd_change), max_highlight = 4, use_direct_label = FALSE) +  \n  scale_x_continuous(expand = expand_scale(mult = c(0.002, 0)),\n                     breaks = c(seq(1950, 2010, 10)),\n                     limits = c(1950, 2010)) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     breaks = 0:8 * 5000,\n                     labels = scales::dollar,\n                     limits = c(0, 40000)) +\n  labs(x = \"Year\",\n       y = \"Change in per-capita GDP (US dollars)\") +\n  facet_wrap(~ country) +\n  theme(panel.spacing = unit(20L, \"pt\"))\n\n\n\n\nTekst en annotatie\nVerschillende functies kunnen worden gebruikt om verschillende delen van percelen te annoteren, te labelen en te markeren. geom_text() en geom_text_repel() geven beide variabelen uit dataframes weer. annotate(), die verschillende toepassingen heeft, geeft variabelen en waarden weer die zijn opgenomen in de functie-aanroep.\ngeom_text()\ngeom_text() zet tekstvariabelen in datasets om in geometrische objecten. Dit is nuttig voor het labelen van gegevens in plots. Beide functies hebben x waarden en y waarden nodig om de plaatsing op het coördinatenvlak te bepalen en een tekstvector van labels.\nDit kan gebruikt worden voor het labelen van geom_bar().\n\n\ndiamonds %>%\n  group_by(cut) %>%\n  summarize(price = mean(price)) %>%\n  ggplot(aes(cut, price)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = scales::dollar(price)), vjust = -1) +\n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.2)),\n                     labels = scales::dollar) +\n  labs(title = \"Average Diamond Price by Diamond Cut\",\n       x = \"Cut\",\n       y = \"Price\") +\n  remove_ticks()\n\n\n\n\nHet kan ook gebruikt worden om punten in een scatterplot te labelen.\nHet is zelden nuttig om elk punt in een scatter plot te labelen. Gebruik filter() om een tweede dataset te maken die wordt onderverdeeld en deze door te geven aan de labelfunctie.\n\n\nlabels <- mtcars %>%\n  rownames_to_column(\"model\") %>%\n  filter(model %in% c(\"Toyota Corolla\", \"Merc 240D\", \"Datsun 710\"))\n\nmtcars %>%\n  ggplot() +\n  geom_point(mapping = aes(x = wt, y = mpg)) +\n  geom_text(data = labels, mapping = aes(x = wt, y = mpg, label = model), nudge_x = 0.38) +\n  scale_x_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     limits = c(0, 6)) + \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     limits = c(0, 40)) +  \n  labs(x = \"Weight (Tons)\",\n       y = \"Miles per gallon (MPG)\") +\n  scatter_grid()\n\n\n\n\nTekst overlapt te vaak met andere tekst of geomen bij gebruik van geom_text(). library(ggrepel) is een library(ggplot2) add-on die automatisch tekst positioneert zodat deze niet overlapt met geomen of andere tekst. Om deze functionaliteit toe te voegen, installeer en laad je library(ggrepel) en gebruikt je vervolgens geom_text_repel() met dezelfde syntaxis als geom_text().\ngeom_text_repel()\n\n\nlibrary(ggrepel)\n\nlabels <- mtcars %>%\n  rownames_to_column(\"model\") %>%\n  top_n(5, mpg)\n\nmtcars %>%\n  ggplot(mapping = aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_text_repel(data = labels, \n                  mapping = aes(label = model), \n                  nudge_x = 0.38) +\n  scale_x_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     limits = c(0, 6)) + \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     limits = c(0, 40)) +  \n  labs(x = \"Weight (Tons)\",\n       y = \"Miles per gallon (MPG)\") +\n  scatter_grid()\n\n\n\n\nannotate()\nannotate() gebruikt geen dataframes. In plaats daarvan zijn er waarden nodig voor x = en y =. Het kan tekst, rechthoeken, segmenten en puntenreeksen toevoegen.\n\n\nmsleep %>%\n  filter(bodywt <= 1000) %>%\n  ggplot(aes(bodywt, sleep_total)) +\n  geom_point() +\n  scale_x_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     limits = c(-10, 1000),\n                     labels = scales::comma) + \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     limits = c(0, 25)) +  \n  annotate(\"text\", x = 500, y = 12, label = \"These data suggest that heavy \\n animals sleep less than light animals\") +\n  labs(x = \"Body weight (pounds)\",\n       y = \"Sleep time (hours)\") +\n  scatter_grid()  \n\n\n\n\n\n\nlibrary(AmesHousing)\n\names <- make_ames()\n\names %>%\n  mutate(square_footage = Total_Bsmt_SF - Bsmt_Unf_SF + First_Flr_SF + Second_Flr_SF) %>%\n  mutate(Sale_Price = Sale_Price / 1000) %>%  \n  ggplot(aes(square_footage, Sale_Price)) +\n  geom_point(alpha = 0.2) +\n  scale_x_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     limits = c(-10, 12000),\n                     labels = scales::comma) + \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0.002)),\n                     limits = c(0, 800),\n                     labels = scales::dollar) +  \n  annotate(\"rect\", xmin = 6800, xmax = 11500, ymin = 145, ymax = 210, alpha = 0.1) +\n  annotate(\"text\", x = 8750, y = 230, label = \"Unfinished homes\") +\n  labs(x = \"Square footage\", \n       y = \"Sale price (thousands)\") +\n  scatter_grid()   \n\n\n\n\nGelaagde geoms\nGeomen kunnen worden gelaagd in ggplot2. Dit is nuttig voor het ontwerp en de analyse.\nHet is vaak nuttig om punten toe te voegen aan lijngrafieken met een klein aantal waarden over de x-as. Dit voorbeeld uit R voor Data Science laat zien hoe het veranderen van de lijn naar grijs aantrekkelijk kan zijn.\nDesign\nVoor\n\n\ntable1 %>%\n  ggplot(aes(x = year, y = cases)) +\n    geom_line(aes(color = country)) +\n    geom_point(aes(color = country)) +\n    scale_y_continuous(expand = expand_scale(mult = c(0, 0.2)), \n                       labels = scales::comma) +\n    scale_x_continuous(breaks = c(1999, 2000)) +\n    labs(title = \"Changes in Tuberculosis Cases in Three Countries\")\n\n\n\n\nNa\n\n\ntable1 %>%\n  ggplot(aes(year, cases)) +\n    geom_line(aes(group = country), color = \"grey50\") +\n    geom_point(aes(color = country)) +\n    scale_y_continuous(expand = expand_scale(mult = c(0, 0.2)), \n                       labels = scales::comma) +\n    scale_x_continuous(breaks = c(1999, 2000)) +\n    labs(title = \"Changes in Tuberculosis Cases in Three Countries\")\n\n\n\n\nGelaagde geomen zijn ook nuttig voor het toevoegen van trendlijnen en centroïden aan scatterplots.\n\n\n# Simpele lijn\n# Regressie model\n# Centroiden\n\n\n\nCentroiden\n\n\nmpg_summary <- mpg %>%\n  group_by(cyl) %>%\n  summarize(displ = mean(displ), cty = mean(cty))\n\nmpg %>%\n  ggplot() +\n  geom_point(aes(x = displ, y = cty, color = factor(cyl)), alpha = 0.5) +\n  geom_point(data = mpg_summary, aes(x = displ, y = cty), size = 5, color = \"#ec008b\") +\n  geom_text(data = mpg_summary, aes(x = displ, y = cty, label = cyl)) +\n  scale_x_continuous(expand = expand_scale(mult = c(0, 0.002)), \n                     limits = c(0, 8)) +  \n  scale_y_continuous(expand = expand_scale(mult = c(0, 0)), \n                     limits = c(0, 40)) +\n  labs(x = \"Displacement\",\n       y = \"City MPG\") +\n  scatter_grid()\n\n\n\n\nGrafieken opslaan\nggsave() exporteert ggplot2 percelen. De functie kan op twee manieren worden gebruikt. Als plot = niet is gespecificeerd in de functie-aanroep, dan slaat ggsave() automatisch de plot op die het laatst werd weergegeven in het Viewer-venster. Ten tweede, als plot = is gespecificeerd, dan slaat ggsave() het gespecificeerde plot op. ggsave() raadt het type grafische soort dat gebruikt moet worden bij het exporteren (.png, .pdf, .svg, etc.) van de bestandsextensie in de bestandsnaam.\nmtcars %>%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()\n\nggsave(filename = \"cars.png\")\n\nplot2 <- mtcars %>%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()\n\nggsave(filename = \"cars.png\", plot = plot2)\nGeëxporteerde plots zien er zelden identiek uit als de plots die in het Viewervenster in RStudio verschijnen omdat de totale grootte en de beeldverhouding van de Viewer vaak anders is dan de standaardinstellingen voor ggsave(). Specifieke afmetingen, beeldverhoudingen en resoluties kunnen worden gecontroleerd met argumenten in ggsave(). RStudio heeft een nuttig cheatsheet genaamd “How Big is Your Graph?” dat zou moeten helpen bij het kiezen van de beste grootte, beeldverhouding en resolutie.\nLettertypen zijn niet standaard in PDF’s opgenomen. Om lettertypes in te sluiten in PDF’s, neem device = cairo_pdf op in ggsave().\nplot <- mtcars %>%\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()\n\nggsave(filename = \"cars.pdf\", plot = plot2, width = 6.5, height = 4, device = cairo_pdf)\nBibliography and Session Information\nNote: Examples present in this document by Aaron Williams were created during personal time.\nBob Rudis and Dave Gandy (2017). waffle: Create Waffle Chart Visualizations in R. R package version 0.7.0. https://CRAN.R-project.org/package=waffle\nChester Ismay and Jennifer Chunn (2017). fivethirtyeight: Data and Code Behind the Stories and Interactives at ‘FiveThirtyEight’. R package version 0.3.0. https://CRAN.R-project.org/package=fivethirtyeight\nHadley Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2009.\nHadley Wickham (2017). tidyverse: Easily Install and Load the ‘Tidyverse’. R package version 1.2.1. https://CRAN.R-project.org/package=tidyverse\nHadley Wickham (2017). forcats: Tools for Working with Categorical Variables (Factors). R package version 0.2.0. https://CRAN.R-project.org/package=forcats\nJennifer Bryan (2017). gapminder: Data from Gapminder. R package version 0.3.0. https://CRAN.R-project.org/package=gapminder\nKamil Slowikowski (2017). ggrepel: Repulsive Text and Label Geoms for ‘ggplot2’. R package version 0.7.0. https://CRAN.R-project.org/package=ggrepel\nMax Kuhn (2017). AmesHousing: The Ames Iowa Housing Data. R package version 0.0.3. https://CRAN.R-project.org/package=AmesHousing\nPeter Kampstra (2008). Beanplot: A Boxplot Alternative for Visual Comparison of Distributions, Journal of Statistical Software, 2008. https://www.jstatsoft.org/article/view/v028c01\nR Core Team (2017). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.\nWinston Chang, (2014). extrafont: Tools for using fonts. R package version 0.17. https://CRAN.R-project.org/package=extrafont\nYihui Xie (2018). knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version 1.19.\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS High Sierra 10.13.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] AmesHousing_0.0.4     gghighlight_0.3.0     fivethirtyeight_0.6.1\n [4] waffle_0.7.0          ggridges_0.5.2        gapminder_0.3.0      \n [7] urbnmapr_0.0.0.9002   extrafont_0.17        ggrepel_0.8.2        \n[10] urbnthemes_0.0.1      forcats_0.5.0         stringr_1.4.0        \n[13] dplyr_1.0.2           purrr_0.3.4           readr_1.4.0          \n[16] tidyr_1.1.2           tibble_3.0.4          ggplot2_3.3.2        \n[19] tidyverse_1.3.0       knitr_1.30           \n\nloaded via a namespace (and not attached):\n [1] httr_1.4.2         jsonlite_1.7.1     splines_4.0.3     \n [4] modelr_0.1.8       assertthat_0.2.1   blob_1.2.1        \n [7] cellranger_1.1.0   yaml_2.2.1         Rttf2pt1_1.3.8    \n[10] pillar_1.4.6       backports_1.1.10   lattice_0.20-41   \n[13] glue_1.4.2         extrafontdb_1.0    digest_0.6.27     \n[16] RColorBrewer_1.1-2 rvest_0.3.6        colorspace_1.4-1  \n[19] Matrix_1.2-18      htmltools_0.5.0    plyr_1.8.6        \n[22] pkgconfig_2.0.3    broom_0.7.2        haven_2.3.1       \n[25] scales_1.1.1       distill_1.0        downlit_0.2.0     \n[28] mgcv_1.8-33        generics_0.0.2     farver_2.0.3      \n[31] ellipsis_0.3.1     withr_2.3.0        hexbin_1.28.1     \n[34] cli_2.1.0          magrittr_1.5       crayon_1.3.4      \n[37] readxl_1.3.1       evaluate_0.14      fs_1.5.0          \n[40] fansi_0.4.1        nlme_3.1-149       xml2_1.3.2        \n[43] tools_4.0.3        hms_0.5.3          lifecycle_0.2.0   \n[46] munsell_0.5.0      reprex_0.3.0       compiler_4.0.3    \n[49] rlang_0.4.8        grid_4.0.3         rstudioapi_0.11   \n[52] labeling_0.4.2     rmarkdown_2.5      gtable_0.3.0      \n[55] DBI_1.1.0          R6_2.4.1           gridExtra_2.3     \n[58] lubridate_1.7.9    stringi_1.5.3      Rcpp_1.0.5        \n[61] vctrs_0.3.4        dbplyr_1.4.4       tidyselect_1.1.0  \n[64] xfun_0.18         \n\n\n\n\n",
    "preview": "posts/2020-05-31-grafieken/grafieken_files/figure-html5/staafgrafiek-1.png",
    "last_modified": "2020-11-02T20:56:54+01:00",
    "input_file": "grafieken.utf8.md"
  },
  {
    "path": "posts/2020-05-31-dslabs/",
    "title": "dslabs",
    "description": "Een aantal mooie grafieken uit het goede data-analyseboek van Rafa Irizarri (Harvard University)",
    "author": [
      {
        "name": "Rafa Irizarri en Amy Hill, bewerking Harrie Jonkman",
        "url": "www.harriejonkman.nl"
      }
    ],
    "date": "2020-04-22",
    "categories": [],
    "preview": "posts/2020-05-31-dslabs/dslabs_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2020-08-21T10:38:38+02:00"
  },
  {
    "path": "posts/2019-12-15-beste-boeken-2019/",
    "title": "Beste Boeken 2019",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Harrie Jonkman",
        "url": "www.harriejonkman.nl"
      }
    ],
    "date": "2019-12-15",
    "categories": [],
    "preview": {},
    "last_modified": "2020-03-13T23:28:58+01:00"
  },
  {
    "path": "posts/2019-12-15-r-als-een-gis/",
    "title": "R als een Gis",
    "description": "Over ruimtelijke data en het gebruik van R als een GIS",
    "author": [
      {
        "name": "Harrie Jonkman",
        "url": "www.harriejonkman.nl"
      }
    ],
    "date": "2019-12-15",
    "categories": [],
    "preview": "posts/2019-12-15-r-als-een-gis/r-als-een-gis_files/figure-html5/unnamed-chunk-19-1.png",
    "last_modified": "2020-03-13T23:28:59+01:00"
  },
  {
    "path": "posts/2019-12-04-bayesbasis/",
    "title": "Bayes'basis",
    "description": "Over statistiek en waarschijnlijkheid op de eenvoudige manier.",
    "author": [
      {
        "name": "Harrie Jonkman",
        "url": "www.harriejonkman.nl"
      }
    ],
    "date": "2019-12-04",
    "categories": [],
    "preview": "posts/2019-12-04-bayesbasis/bayesbasis_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2020-03-13T23:28:58+01:00"
  },
  {
    "path": "posts/2019-09-25-sf-ggplot-en-tmap/",
    "title": "Sf, ggplot en tmap",
    "description": "Over het maken van kaarten van Nederland met nieuwe pakketten en mogelijkheden.",
    "author": [
      {
        "name": "Harrie Jonkman",
        "url": "www.harriejonkman.nl"
      }
    ],
    "date": "2019-09-25",
    "categories": [],
    "preview": "posts/2019-09-25-sf-ggplot-en-tmap/sf-ggplot-en-tmap_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2020-03-13T23:28:58+01:00"
  },
  {
    "path": "posts/2019-08-31-geocomputation/",
    "title": "Geocomputation",
    "description": "Bespreking van het fantastische boek Geocomputation with R",
    "author": [
      {
        "name": "Harrie Jonkman",
        "url": "www.harriejonkman.nl"
      }
    ],
    "date": "2019-08-31",
    "categories": [],
    "preview": "posts/2019-08-31-geocomputation/geocomputation_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2020-03-13T23:28:58+01:00"
  },
  {
    "path": "posts/2019-08-17-xaringan/",
    "title": "Xaringan",
    "description": "Een mooie presentatie geven met het pakket Xaringan",
    "author": [
      {
        "name": "Yuhui Xie, overgezet Harrie Jonkman",
        "url": "www.harriejonkman.nl"
      }
    ],
    "date": "2019-08-17",
    "categories": [],
    "preview": {},
    "last_modified": "2020-03-13T23:28:58+01:00"
  },
  {
    "path": "posts/2019-06-24-bookdown/",
    "title": "Bookdown",
    "description": "Hoe maak je een boek. Bookdown is het pakket van R waar dat mee kan. Hier enkele tips om dat te doen",
    "author": [
      {
        "name": "Jack Dougherty en Ilya Ilyankou, bewerking Harrie Jonkman",
        "url": "www.harriejonkman.nl"
      }
    ],
    "date": "2019-06-24",
    "categories": [],
    "preview": {},
    "last_modified": "2020-03-13T23:28:58+01:00"
  },
  {
    "path": "posts/2019-05-19-website-maken/",
    "title": "Websites maken in R",
    "description": "Met R kun je ook website maken. Maar hoe doe je dat? Emily Zabor schreef hierover een leerzaam blog dat ik hier licht heb bewerkt en aangevuld.",
    "author": [
      {
        "name": "Emily C. Zabor, bewerking Harrie Jonkman",
        "url": "www.harriejonkman.nl"
      }
    ],
    "date": "2019-06-09",
    "categories": [],
    "preview": {},
    "last_modified": "2020-03-13T23:28:58+01:00"
  },
  {
    "path": "posts/2019-04-23-shiny_files/",
    "title": "Shiny lespakket",
    "description": "Met Shiny kun je in R apps maken. Maar hoe doe je dat? Julia Wrobel gaf hierop vorig jaar een interessante inleiding die ik hier licht heb bewerkt.",
    "author": [
      {
        "name": "Julia Wrobel, bewerking Harrie Jonkman",
        "url": "www.harriejonkman.nl"
      }
    ],
    "date": "2019-04-23",
    "categories": [],
    "preview": "posts/2019-04-23-shiny_files/distill-preview.png",
    "last_modified": "2020-03-13T23:28:58+01:00"
  },
  {
    "path": "posts/2019-03-18-interactieve-grafiek/",
    "title": "Interactieve grafiek met plotly",
    "description": "In deze twee maanden wilde ik toch eens kijken naar interactieve mogelijkheden die het programma R/RStudio ons biedt. `Plotly` is zo'n mogelijkheid en daarover gaat dit blog. `Shiny` is de andere mogelijkheid en daar zal ik een volgende keer aandacht aan besteden. `Plotly` heeft een eigen website waar veel informatie over het programma is te vinden [hier adres website](https://plot.ly/). Er is ook een uitgebreide handleiding over `Plotly` geschreven [hier handleiding](https://plotly-r.com/the-plotly-cookbook.html). Onlangs stond er op de blog van RBloggers een goede introductie van Laura Ellis, die mij veel vertelde over het gebruik van `Plotly`. Haar bijdrage [zie hier](https://www.r-bloggers.com/create-interactive-ggplot2-graphs-with-plotly/) heb ik hier naar het Nederlands overgezet en hier en daar iets bewerkt.",
    "author": [
      {
        "name": "Laura Ellis op R-bloggers (13 maart 2019), bewerking Harrie Jonkman.",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2019-04-03",
    "categories": [],
    "preview": {},
    "last_modified": "2020-03-13T23:28:58+01:00"
  },
  {
    "path": "posts/2019-02-20-bbc-en-data-journalisme/",
    "title": "BBC en data-journalisme",
    "description": "Een blog over hoe de BBC omgaat met visualisatie en data-journalisme",
    "author": [
      {
        "name": "R-bloggers, bewerking Harrie Jonkman.",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2019-02-20",
    "categories": [],
    "preview": "posts/2019-02-20-bbc-en-data-journalisme/bbc-en-data-journalisme_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2020-03-13T23:28:58+01:00"
  },
  {
    "path": "posts/2019-01-23-data-visualization-a-practical-introduction/",
    "title": "Data visualisatie. Een practische introductie",
    "description": "Naar aanleiding van het nieuwe boek van Kieran Healey. Data visualization/A Practical Introduction.",
    "author": [
      {
        "name": "Harrie Jonkman.",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2019-01-23",
    "categories": [],
    "preview": "posts/2019-01-23-data-visualization-a-practical-introduction/data-visualization-a-practical-introduction_files/figure-html5/01-first_plot-1.png",
    "last_modified": "2020-03-13T23:28:58+01:00"
  },
  {
    "path": "posts/2018-12-23-statistisch-omdenken/",
    "title": "Statistisch omdenken",
    "description": "Over 'Statistical rethinking' van Richard McElreath (2016).",
    "author": [
      {
        "name": "Harrie Jonkman met dan aan Solomon Kurz.",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2018-12-23",
    "categories": [],
    "preview": "posts/2018-12-23-statistisch-omdenken/statistisch-omdenken_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-26-communiceren-met-rmarkdown/",
    "title": "Communiceren met RMarkdown",
    "description": "RMarkdown is de nieuwe manier om diverse wetenschappelijke producten te delen met anderen. Het kan op verschillende manieren gereproduceerd worden en het kan de opbrengsten aantrekkelijk communiceren naar de buitenwereld. Hier een introductie op de werkwijze en enkele mogelijke producten.",
    "author": [
      {
        "name": "M. Schmidt en bewerkt door Harrie Jonkman",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2018-11-26",
    "categories": [],
    "preview": "posts/2018-11-26-communiceren-met-rmarkdown/Figures/single-fig-center-1.png",
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-14-simple-features/",
    "title": "Bewerking geografische data in R: Nieuwe ontwikkelingen",
    "description": "Het nieuwe R sf-pakket, dat sp vervangt om met geografische objecten om te gaan, is  ontworpen om makkelijk met Tidyverse om te gaan. Hier laat ik zien hoe sf-objecten als data-frames worden opgeslagen en jou in staat stelt om met  ggplot2, dplyr en tidyr te werken. Ook het R-pakket tmap biedt veel nieuwe mogelijkheden.",
    "author": [
      {
        "name": "Harrie Jonkman",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2018-11-14",
    "categories": [],
    "preview": "posts/2018-11-14-simple-features/simple-features_files/figure-html5/ggplot-1.png",
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-14-visualisatiegapminder/",
    "title": "Visualisatie met inzet van Gapminder",
    "description": "Een voorbeeld van datavisualisatie: Trends op het gebied van de wereldgezondheid\nen de economie",
    "author": [
      {
        "name": "Rafael A. Irizarry, bewerkt H. Jonkman",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2018-08-14",
    "categories": [],
    "preview": "posts/2018-11-14-visualisatiegapminder/visualisatiegapminder_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-14-sem/",
    "title": "SEM",
    "description": "In de sociale wetenschappen kunnen sommige constructen, zoals intelligentie, vertrouwen, motivatie, vervreemding of conservatisme, niet direct worden geobserveerd. Het zijn in essentie constructen of concepten waarvoor geen methode bestaat om ze direct te meten. Onderzoekers gebruiken hiervoor geobserveerde maten die indicatoren zijn voor een latente variabele. Structural equation modeling is een onderzoeks-raamwerk dat rekening kan houden met de meetfouten in de geobserveerde variabelen die in het model zitten. SEM is een flexibel en krachtige methode om tegelijkertijd op een goede manier de kwaliteit van het meten in de gaten te houden als om causale relaties tussen de constructen vast te stellen. In de map vind je een korte presentatie over SEM",
    "author": [
      {
        "name": "Harrie Jonkman",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2018-07-07",
    "categories": [],
    "preview": {},
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-14-rrstudiormarkdown/",
    "title": "RRStudioRmarkdown",
    "description": "Hier een klein boekje om jou te laten wennen aan reproduceerbaar onderzoek. Het introduceert het programma R, de RStudio-schil en de programmeertaal RMarkdown.",
    "author": [
      {
        "name": "Chester Ismay, bewerkt Harrie Jonkman",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2018-06-05",
    "categories": [],
    "preview": {},
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-14-bayes/",
    "title": "Bayes",
    "description": "Over de geschiedenis van de Bayesiaanse statistiek",
    "author": [
      {
        "name": "Harrie Jonkman",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2018-05-14",
    "categories": [],
    "preview": {},
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-14-reproducable-research/",
    "title": "Dynamische documenten maken met RMarkdown en Knitr",
    "description": "RMarkdown en Knitr zijn pakketten die je in staat stellen om reproduceerbare en dynamische documenten te maken. In deze blog wordt uitgelegd hoe je hiermee kunt werken.",
    "author": [
      {
        "name": "Marian L. Schmidt, bewerkt door Harrie Jonkman",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2018-03-15",
    "categories": [],
    "preview": "posts/2018-11-14-reproducable-research/reproducable-research_files/figure-html5/single-fig-center-1.png",
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-14-exploratie/",
    "title": "Data exploratie",
    "description": "Een introductie op data exploratie aan de hand van een boek van Chester Ismay en Albert Y. Kim.",
    "author": [
      {
        "name": "Chester Ismay en Albert Y. Kim, bewerkt door Harrie Jonkman",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2017-10-15",
    "categories": [],
    "preview": {},
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-14-psm/",
    "title": "PSM",
    "description": "Om precies het effect van een aanpak of politieke keuze vast te stellen is een ingewikkelde kwestie. Toch is er dat soort onderzoek nodig om de keuze voor programma's te legitimeren. Tegenwoordig is er een heel spectrum van technieken om de impact van programma's vast te stellen. Dit zijn technieken die kunnen worden gebruikt binnen hele verschillende soorten impactstudies. Het is goed daar kennis van te nemen, zeker nu steeds meer mogelijk is omdat er meer data beschikbaar zijn waarop deze evaluaties gebaseerd kunnen worden. Impactstudies worden uitgevoerd om vast te stellen of programma's de effecten opleveren die ze nastreven, om te begrijpen of en waarom deze programma's werken, om vast te stellen in hoeverre veranderingen zijn toe te schrijven aan de inzet van het programma en ook om vast te stellen of de gelden op een goede manier worden besteed. Op dit terrein is er natuurlijk een enorme hoeveelheid literatuur en enkele uitgaven geven ons hiervan een goed en up-to-date overzicht^[Khandker, S.R., Koolwal, G.B. & Samad, H.A. (2010). *Handbook on Impactevaluation. Quantative Methods and Practices*. Washington D.C: The World Bank; Gertler, P.J., Martinez, S., Prenard, P., Rawlings, L.B. & Vermeersch, C.M. (2011). *Impact Evaluation in Practice*. Washington D.C.: The World Bank; Murnane, R.J. & Willet, J.B.(2011). *Methods Matter. Improving Causal Inference in Educational and Social Science Research*. New York: Oxford University]. Experimentele studies kunnen natuurlijk goede impactstudies zijn, met sterke punten en beperkingen. Maar er zijn ook aanvullende methodes die in quasi-experimentele of observationele studies kunnen worden toegepast. Zo zijn er panel datamethodes die gebruikt kunnen worden, regressie discontinu?teit methodes en instrumentele variabelen methodes. Daarnaast zijn er verschillende matchingsmethodes die in impactstudies worden gebruikt. Hier stellen we zo'n matchingsmethode voor die goed gebruikt kan worden in verschillende soorten impactstudies en laten we zien hoe deze uitgevoerd kan worden.",
    "author": [
      {
        "name": "Harrie Jonkman",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2017-09-14",
    "categories": [],
    "preview": "posts/2018-11-14-psm/psm_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-14-tufte/",
    "title": "Tufte",
    "description": "De Tufte-stijl is een stijl die Edward Tufte gebruikt in zijn boeken en handouts. Tufte's stijl is bekend vanwege zijn veelvuldig gebruik van opmerkingen aan de zijkant (sidenotes), strakke integratie van zijn grafieken met tekst en zijn duidelijk gezette typografie. Deze stijl is geimplementeerd in repectievelijk LaTeX en HTML/CSS^[Zie Github repositories [tufte-latex](https://github.com/tufte-latex/tufte-latex) en [tufte-css](https://github.com/edwardtufte/tufte-css)], respectively. Beide implementaties zitten nu ook in het [**tufte** pakket](https://github.com/rstudio/tufte). Als je een LaTeX/PDF output wilt, gebruik dan `tufte_handout` format voor handouts en `tufte_book` voor boeken. Voor HTML output, gebruik je `tufte_html`. Deze formatten kunnen worden gespecificeerd in de YAML metadata aan het begin van een R Markdown-document (zie het voorbeeld hieronder), of overgebracht via de `rmarkdown::render()` functie. Zie @R-rmarkdown voor meer informatie over **rmarkdown**.",
    "author": [
      {
        "name": "Harrie Jonkman",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2017-09-14",
    "categories": [],
    "preview": {},
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-14-op-weg-naar-infografieken/",
    "title": "Op weg naar infografieken",
    "description": "Hier gaat het om een korte handleiding voor R_gebruikers die omwille van de leesbaarheid en esthetiek hun figuren in het populaire grafische design programma Illustrator willen 'oppoetsen'. Als het op visualisatie aankomt blijven de meeste R-gebruikers binnen dit programma werken. Dat is natuurlijk prima als het gaat om figuren die de analyse moeten ondersteunen en jij degene bent die er alleen naar moet kijken. Dan hoef je ook niets over de context te vermelden, niets verder uit te leggen of ervoor te zorgen dat het er allemaal mooi uitziet. Het doel dan is vooral snel figuren maken zodat je gevoel bij jouw data krijgt. R biedt je ook heel veel mogelijkheden, ook voor goede visualisatie. Echter, als het gaat om het maken van figuren die voor een breder publiek toegankelijk en leesbaar zijn en die zelf een verhaal moeten vertellen, kan het wel eens bruikbaarder en efficiënter zijn om dit R-figuur als PDF op te slaan en aanpassingen door te voeren in een vector georienteerd programma zoals Adobe Illustrator (https://www.adobe.com/nl/) of zijn open-source alternatief Inkscape (https://www.inkscape.org/nl/). Inkscape is vrij toegankelijk maar hier besteden wij enkel aandacht aan het bewerken in Adobe Illustrator.",
    "author": [
      {
        "name": "Harrie Jonkman",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2017-07-14",
    "categories": [],
    "preview": {},
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-14-latex/",
    "title": "Latex",
    "description": "Introductie op Latex.",
    "author": [
      {
        "name": "Harrie Jonkman",
        "url": "https://www.harriejonkman.nl"
      }
    ],
    "date": "2017-04-14",
    "categories": [],
    "preview": {},
    "last_modified": "2020-03-13T23:28:57+01:00"
  },
  {
    "path": "posts/2018-11-14-visualisatie/",
    "title": "Visualisatie",
    "description": "Hoe kun je goed werken aan datavisualisatie met ggplot2 binnen R/RStudio",
    "author": [
      {
        "name": "Zev Ross, bewerkt door Harrie Jonkman",
        "url": "https://Harriejonkman.nl"
      }
    ],
    "date": "2017-02-11",
    "categories": [],
    "preview": "posts/2018-11-14-visualisatie/visualisatie_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2020-03-13T23:28:57+01:00"
  }
]
