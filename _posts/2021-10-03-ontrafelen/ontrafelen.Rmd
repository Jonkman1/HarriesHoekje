---
title: "Opschonen en ontrafelen"
description: |
  Een post over opschonen en ontrafelen van data
author:
  - name: Bewerking Harrie Jonkman
    url: {}
date: 10-03-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

![](Screenshot1.png)

Als je data krijgt is het belangrijk om over enkele technieken te beschikken de data goed te ontrafelen en schoon te maken. De pakketten `janitor` en `tidyverse` leveren het juiste gereedschap hiervoor. Handig om enkele codes goed te leren kennen. Deze commando's wil ik zelf graag uit het hoofd leren. Vandaar deze blog. De Janitor blog verscheen [hier](https://towardsdatascience.com/cleaning-and-exploring-data-with-the-janitor-package-ee4a3edf085e) en dit is de link naar [`tidyverse`](https://linkprotect.cudasvc.com/url?a=https%3a%2f%2fgenomicsclass.github.io%2fbook%2fpages%2fdplyr_tutorial.html&c=E,1,BxPWMDXPJFZT_IwZlVU3PngQD8N9ezJJlvk5B5828ON6jC_VRK3NA3a_mhd8eXCjMwDf_YxMllX_sJT_VNAQb3JOx-K1JhbORJVb9YXV&typo=1).   

# Janitor   
Eerst maar een de pakketten (janitor en tidyverse) laden en ook de data binnenhalen.  

```{r}
library(janitor)
library(tidyverse)
place_names = read.csv("data/GNIS Query Result.csv")
```

 

```{r}
View(place_names)
```

## Create place_names
Let’s work with this a bit. First, we assign the name “columns” to this single column to avoid having to include something as messy and long as the default column name in our code. Next, we use the `separate()` function to separate this one column into all of its component parts. We then filter the data down to Berkshire County, as upon further inspection of the data it becomes clear that a few entries from outside this county were included in our Berkshire County query. We then dirty the data a bit in a `mutate()` step so as to tidy it later. `str_replace()` is used to replace the ID “598673” with “598712,” an ID number that already exists in the dataset, in order to create a duplicate ID. Finally, an extra column called “extra_column” is created with NAs in every row:

```{r place_names}

place_names = read.csv("data/GNIS Query Result.csv")

colnames(place_names) = "columns"

place_names = 
  place_names %>% 
  separate(columns, c("Feature Name", "ID", "Class", "County", "State", "Latitude", "Longitude", "Ele(ft)", "Map", "BGN Date", "Entry Date"), sep = "[|]") %>%
  filter(County == "Berkshire") %>% 
  mutate(
    ID = str_replace(ID, "598673", "598712"),
    extra_column = NA
  )

```

Before moving on, let’s quickly create a second data set called “non_ma_names” containing those entries that were not actually from Berkshire County. Yet again we read in the “GNIS Query Result.csv” file and separate out the column names. We then apply the `clean_names()` function from the janitor package, which we will cover in depth in the following section. Finally, we use `as.numeric()` and `as.factor()` in a mutate step to transform our ele_ft variable to an numeric variable and our map variable to a factor:

## Create non_ma_names

```{r non_ma}

non_ma_names = read.csv("data/GNIS Query Result.csv")

colnames(non_ma_names) = "columns"

non_ma_names = 
  non_ma_names %>% 
  separate(columns, c("Feature Name", "ID", "Class", "County", "State", "Latitude", "Longitude", "Ele(ft)", "Map", "BGN Date", "Entry Date"), sep = "[|]") %>% 
  filter(County != "Berkshire") %>% 
  clean_names() %>% 
  mutate(
    ele_ft = as.numeric(ele_ft),
    map = as.factor(map)
  )

```

Now let’s see what janitor can do!

## Using janitor



```{r janitor}

#1 - row_to_names()
test_names = row_to_names(place_names, 3, remove_row = TRUE, remove_rows_above = TRUE)

#2 - clean_names()

place_names = clean_names(place_names)

#OR

place_names = 
  place_names %>% 
  clean_names()

#3 - remove_constant()

place_names = 
  place_names %>% 
  remove_constant()

#4 - remove_empty()

place_names = 
  place_names %>% 
  remove_empty()

#5 - compare_df_cols()

#full_data = rbind(place_names, non_ma_names) - doesn't work, use compare_df_cols() to see why

compare_df_cols(place_names, non_ma_names)

#6 - get_dupes()

get_dupes(place_names, id)

#7 - tabyl()

place_names %>% 
  filter(class %in% "School") %>% 
  tabyl(map) %>% 
  knitr::kable()

place_names %>% 
  tabyl(map, class) %>% 
  adorn_percentages("col") %>% 
  adorn_pct_formatting(digits = 0) %>% 
  knitr::kable()

place_names %>% 
  tabyl(map, class) %>% 
  adorn_percentages("row") %>% 
  adorn_pct_formatting(digits = 0) %>% 
  knitr::kable()

```



# Tidyverse
The msleep (mammals sleep) data set contains the sleeptimes and weights for a set of mammals and is available in the dagdata repository on github. This data set contains 83 rows and 11 variables.

Download the msleep data set in CSV format from here, and then load into R:

```{r}
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/msleep_ggplot2.csv"
filename <- "msleep_ggplot2.csv"
if (!file.exists(filename)) download(url,filename)
msleep <- read.csv("msleep_ggplot2.csv")
head(msleep)
```
The columns (in order) correspond to the following:   

**column name**	    **Description**   
name common name    
genus	taxonomic rank
vore	carnivore, omnivore or herbivore?
order	taxonomic rank
conservation	the conservation status of the mammal
sleep_total	total amount of sleep, in hours
sleep_rem	rem sleep, in hours
sleep_cycle	length of sleep cycle, in hours
awake	amount of time spent awake, in hours
brainwt	brain weight in kilograms
bodywt	body weight in kilograms


## Important dplyr verbs to remember
dplyr verbs	Description
select()	select columns
filter()	filter rows
arrange()	re-order or arrange rows
mutate()	create new columns
summarise()	summarise values
group_by()	allows for group operations in the “split-apply-combine” concept

## dplyr verbs in action
The two most basic functions are select() and filter() which selects columns and filters rows, respectively.

Selecting columns using `select()`

Select a set of columns: the name and the sleep_total columns.

```{r}
sleepData <- select(msleep, name, sleep_total)
head(sleepData)
```

To select all the columns **except** a specific column, use the “-“ (subtraction) operator (also known as negative indexing)

```{r}
head(select(msleep, -name))
```

To select a range of columns by name, use the “:” (colon) operator

```{r}
head(select(msleep, name:order))
```

To select all columns that start with the character string “sl”, use the function starts_with()

```{r}
head(select(msleep, starts_with("sl")))
```

Some additional options to select columns based on a specific criteria include

1. `ends_with()` = Select columns that end with a character string   
2. `contains()` = Select columns that contain a character string   
3. `matches()` = Select columns that match a regular expression   
4. `one_of()` = Select columns names that are from a group of names

## Selecting rows using `filter()`
Filter the rows for mammals that sleep a total of more than 16 hours.

```{r}
filter(msleep, sleep_total >= 16)
```

Filter the rows for mammals that sleep a total of more than 16 hours and have a body weight of greater than 1 kilogram.

```{r}
filter(msleep, sleep_total >= 16, bodywt >= 1)
```

Filter the rows for mammals in the Perissodactyla and Primates taxonomic order.

```{r}
filter(msleep, order %in% c("Perissodactyla", "Primates"))
```

You can use the boolean operators (e.g. >, <, >=, <=, !=, %in%) to create the logical tests.

## Pipe operator: %>%

Before we go any futher, let’s introduce the pipe operator: %>%. dplyr imports this operator from another package (magrittr). This operator allows you to pipe the output from one function to the input of another function. Instead of nesting functions (reading from the inside to the outside), the idea of of piping is to read the functions from left to right.

Here’s an example you have seen:

```{r}
head(select(msleep, name, sleep_total))
```

Now in this case, we will pipe the msleep data frame to the function that will select two columns (name and sleep_total) and then pipe the new data frame to the function `head()` which will return the head of the new data frame.

```{r}
msleep %>% 
    select(name, sleep_total) %>% 
    head

```

You will soon see how useful the pipe operator is when we start to combine many functions.

## Back to dplyr verbs in action

Now that you know about the pipe operator (%>%), we will use it throughout the rest of this tutorial.

## Arrange or re-order rows using `arrange()`

To arrange (or re-order) rows by a particular column such as the taxonomic order, list the name of the column you want to arrange the rows by

```{r}
msleep %>% 
  arrange(order) %>% 
  head
```

Now, we will select three columns from msleep, arrange the rows by the taxonomic order and then arrange the rows by sleep_total. Finally show the head of the final data frame

```{r}
msleep %>% 
    select(name, order, sleep_total) %>%
    arrange(order, sleep_total) %>% 
    head
```

Same as above, except here we filter the rows for mammals that sleep for 16 or more hours instead of showing the head of the final data frame

```{r}
msleep %>% 
    select(name, order, sleep_total) %>%
    arrange(order, sleep_total) %>% 
    filter(sleep_total >= 16)
```

Something slightly more complicated: same as above, except arrange the rows in the sleep_total column in a descending order. For this, use the function `desc()`

```{r}
msleep %>% 
    select(name, order, sleep_total) %>%
    arrange(order, desc(sleep_total)) %>% 
    filter(sleep_total >= 16)
```

## Crreate new columns using `mutate`
The `mutate()` function will add new columns to the data frame. Create a new column called rem_proportion which is the ratio of rem sleep to total amount of sleep.

```{r}
msleep %>% 
    mutate(rem_proportion = sleep_rem / sleep_total) %>%
    head
```

You can many new columns using mutate (separated by commas). Here we add a second column called bodywt_grams which is the bodywt column in grams.

```{r}
msleep %>% 
    mutate(rem_proportion = sleep_rem / sleep_total, 
           bodywt_grams = bodywt * 1000) %>%
    head
```

## Create summaries of the data frame using `summarise()`
The `summarise()` function will create summary statistics for a given column in the data frame such as finding the mean. For example, to compute the average number of hours of sleep, apply the `mean()` function to the column sleep_total and call the summary value avg_sleep.

```{r}
msleep %>% 
    summarise(avg_sleep = mean(sleep_total))
```

There are many other summary statistics you could consider such `sd()`, `min()`, `max()`, `median()`, `sum()`, `n()` (returns the length of vector), `first()` (returns first value in vector), `last()` (returns last value in vector) and `n_distinct()` (number of distinct values in vector).

```{r}
msleep %>% 
    summarise(avg_sleep = mean(sleep_total), 
              min_sleep = min(sleep_total),
              max_sleep = max(sleep_total),
              total = n())
```

## Group operations using `group_by()`
The `group_by()` verb is an important function in dplyr. As we mentioned before it’s related to concept of “split-apply-combine”. We literally want to split the data frame by some variable (e.g. taxonomic order), apply a function to the individual data frames and then combine the output.

Let’s do that: split the msleep data frame by the taxonomic order, then ask for the same summary statistics as above. We expect a set of summary statistics for each taxonomic order.

```{r}
msleep %>% 
    group_by(order) %>%
    summarise(avg_sleep = mean(sleep_total), 
              min_sleep = min(sleep_total), 
              max_sleep = max(sleep_total),
              total = n())
```

